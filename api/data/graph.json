{"index_struct": {"__type__": "composite", "__data__": {"all_index_structs": {"b49022f6-df1b-4406-a114-305111a6ea76": {"__type__": "list", "__data__": {"index_id": "b49022f6-df1b-4406-a114-305111a6ea76", "summary": "\n\nThis document provides an overview of processes and threads, including types of threads, performance of software on multicore systems, the distinction between resource ownership and execution, management of processes and threads on Windows, Solaris, Linux, Android, and Mac OS X Grand Central Dispatch, the scheduling and execution of processes, their execution state and dispatching priority, and the protection of resources from unwanted interference. It also covers the distinction between process and thread, the basic design issues for threads, the difference between user-level threads and kernel-level threads, the thread management facility in Windows, Solaris, Linux, and Mac OS X Grand Central Dispatch, and the use of multiple processes, each of which may contain multiple threads. Additionally, it discusses multithreading, which refers to the ability of an OS to support multiple, concurrent paths of execution within a single process, with one thread per process and multiple threads per process. The document also covers the use of the term lightweight process, which is used as either (1) equivalent to the term thread, (2) a particular type of thread known as a kernel-level thread, or (3) in the case of Solaris, an entity that maps user-level threads to kernel-level threads. A summary of key", "nodes": ["e04f93a5-99dc-41df-87a9-24a44cffeda3", "edfad337-8a36-4363-bb3b-570cd4f9b223", "411ae8a6-eb98-4661-a305-d16144551236", "93e264f4-ec8b-4c73-85c8-ac1ebf2fbcaa", "b80c5e5f-3aa6-47f0-bab0-ffe40243d201", "7abe8520-7306-4832-b1d4-ebdcd12d3f83"]}}, "ac05f3ea-ca78-4a9f-862a-d99d5fd63cbb": {"__type__": "list", "__data__": {"index_id": "ac05f3ea-ca78-4a9f-862a-d99d5fd63cbb", "summary": "\n\nThis document provides a general description of multithreading, including the associated processes and threads. It explains that a process is the unit of resource allocation and protection, and that it has a virtual address space, protected access to processors, other processes, files, and I/O resources. It also explains that threads have an execution state, a saved thread context, an execution stack, some per-thread static storage, and access to the memory and resources of its process, shared with all other threads in that process. Threads have separate stacks for each thread, as well as a separate control block for each thread containing register values, priority, and other thread-related state information. All of the threads of a process share the state and resources of that process, residing in the same address space and having access to the same data. When a thread is blocked, its user registers, program counter, and stack pointers are saved. When the event for which a thread is blocked occurs, the thread is moved to the Ready queue. When a thread completes, its register context and stacks are deallocated. The key benefits of threads include improved performance, such as faster creation and termination of threads, faster switching between threads, and enhanced efficiency in communication between different executing programs. Additionally", "nodes": ["4ca54d0f-d37a-40eb-a33c-722f37ae3a72", "63d4cba5-7262-410b-b724-f1c162ddc042", "e7861035-fdd0-4fb7-bbea-b4daf0f07927", "10c4e692-69d5-454a-9617-8097e2356118", "82368404-e2ef-4fd9-9ea6-1651eef9fb1e", "9584b44e-3c57-4177-88ef-92a9adcf37e9", "962ed776-1aa6-472f-837f-4ff8875cf0c0", "cade53e7-fbf8-455a-a49d-2ba90df309bf", "09c00c07-b0f5-479c-b423-8be95fd56eb1"]}}, "da538f95-7fa5-4685-a9c6-ab3e0a475f05": {"__type__": "list", "__data__": {"index_id": "da538f95-7fa5-4685-a9c6-ab3e0a475f05", "summary": "\n\nThis document discusses the issue of whether the blocking of a thread results in the blocking of the entire process, and the potential performance benefits of using multiple threads for a program that performs two remote procedure calls (RPCs). It provides an example of how using multiple threads can result in a substantial speedup, even when the program operates on a uniprocessor, as the requests can be generated sequentially and the results processed in sequence while the program waits concurrently for the two replies. On a uniprocessor, multiprogramming enables the interleaving of multiple threads within multiple processes, with execution passing from one thread to another either when the currently running thread is blocked or when its time slice is exhausted. All of the threads of a process share the same address space and other resources, such as open files, and any alteration of a resource by one thread is visible to all other threads. There are two broad types of threads: user-level threads (ULTs) and kernel-level threads (KLTs). The example provided shows how three threads in two processes are interleaved on the processor, with two of the threads being pure user-level threads and one being a pure kernel-level thread. It is necessary to synchronize the", "nodes": ["00df1ced-4913-485c-8665-080e62eb35db", "6d11ee4e-28c7-40d3-9040-ab32083b8857", "a7dacfa1-f0f6-40d7-b9c0-0ee55cff780f", "7e833c1c-7ecc-4b4d-bcd0-173409293f32", "738ed06c-6e9e-4447-a6df-d21c8b18f016", "2dc2b6d1-7689-4d23-904a-f3c8bf03ecaf", "a818d593-98dd-4efb-ab30-af8b6d7bf716", "23091df3-ac3c-4f6d-b146-bff341e76798"]}}, "57e1a633-72fd-483d-a0e5-dedd7997f901": {"__type__": "list", "__data__": {"index_id": "57e1a633-72fd-483d-a0e5-dedd7997f901", "summary": null, "nodes": ["93f92626-ac10-4599-9804-23cefad9f84c", "cb43bb52-6563-4744-ae6e-b55f23449c22", "6d770321-a5d4-4655-90a5-dc5909484b1c"]}}}, "root_id": "57e1a633-72fd-483d-a0e5-dedd7997f901"}}, "docstore": {"docs": {"e04f93a5-99dc-41df-87a9-24a44cffeda3": {"text": "1764.1 Pr ocesses and Threads\nMultithreading\nThread Functionality\n4.2\n T\nypes of Threads\nUser-Level and Kernel-Level ThreadsOther Arrangements\n4.3\n Multicor\ne and Multithreading\nPerformance of Software on MulticoreApplication Example: Valve Game Software\n4.4\n W\nindows Process and Thread Management\nManagement of Background Tasks and Application LifecyclesThe Windows ProcessProcess and Thread ObjectsMultithreadingThread StatesSupport for OS Subsystems\n4.5\n Solaris \nThread and SMP Management\nMultithreaded ArchitectureMotivationProcess StructureThread ExecutionInterrupts as Threads\n4.6\n Linux Pr\nocess and Thread Management\nLinux TasksLinux ThreadsLinux Namespaces\n4.7\n Andr\noid Process and Thread Management\nAndroid ApplicationsActivitiesProcesses and Threads\n4.8\n Mac OS X Grand Central Dispatch\n4.\n9\n Summary\n4.\n10\n K\ney Terms, Review Questions, and ProblemsThreads Chapter \nM04_STAL4290_09_GE_C04.indd", "doc_id": "e04f93a5-99dc-41df-87a9-24a44cffeda3", "embedding": null, "doc_hash": "ade1b60a62a849ecdfdfa74024b14eba4990822396ac3f86da8d2a27a40f4424", "extra_info": null, "node_info": {"start": 0, "end": 908}, "relationships": {"1": "72327b6f-82fb-4d59-b7ba-27f31e743680", "3": "edfad337-8a36-4363-bb3b-570cd4f9b223"}, "__type__": "1"}, "edfad337-8a36-4363-bb3b-570cd4f9b223": {"text": "Chapter \nM04_STAL4290_09_GE_C04.indd   176 5/2/17   4:38 PM\n4.1 / PROCESSES AND THREADS   177\nThis chapter examines some more advanced concepts related to process manage-\nment, which are found in a number of contemporary operating systems. We show that the concept of process is more complex and subtle than presented so far and in fact embodies two separate and potentially independent concepts: one relat-ing to resource ownership, and another relating to execution. This distinction has led to the development, in many operating systems, of a construct known as the thread.\n 4. 1 PR OCESSES AND THREADS\nThe discussion so far has presented the concept of a process as embodying two characteristics:\n1.\n R\nesource ownership: A process includes a virtual address space to hold the \nprocess image;\u00a0recall from Chapter 3 that the process image is the collection of program, data, stack, and attributes defined in the process control block. From time to time, a process may be", "doc_id": "edfad337-8a36-4363-bb3b-570cd4f9b223", "embedding": null, "doc_hash": "a6deca2c0bf8159ea81323b2652e88fade9cd0928ff31caed02fe9ad506c82fc", "extra_info": null, "node_info": {"start": 874, "end": 1847}, "relationships": {"1": "72327b6f-82fb-4d59-b7ba-27f31e743680", "2": "e04f93a5-99dc-41df-87a9-24a44cffeda3", "3": "411ae8a6-eb98-4661-a305-d16144551236"}, "__type__": "1"}, "411ae8a6-eb98-4661-a305-d16144551236": {"text": "and attributes defined in the process control block. From time to time, a process may be allocated control or ownership of resources, such as main memory, I/O channels, I/O devices, and files. The OS performs a protection function to prevent unwanted interference between processes with respect to resources.\n2.\n Scheduling/e\nxecution: The execution of a process follows an execution path \n(trace) through one or more programs \u00a0(e.g., Figure 1.5). This execution may \nbe interleaved with that of other processes. Thus, a process has an execution state (Running, Ready, etc.) and a dispatching priority, and is the entity that is scheduled and dispatched by the OS.\nSome thought should convince the reader that these two characteristics are \nindependent and could be treated independently by the OS. This is done in a number \nof operating systems, particularly recently developed systems. To distinguish the two characteristics, the unit of dispatching is usually referred to as a thread or Learning  Objectives\nAfter studying this chapter, you", "doc_id": "411ae8a6-eb98-4661-a305-d16144551236", "embedding": null, "doc_hash": "ebe2d28ed440ea8ec3c54a473da4cb650f9b45cd406ee8e2843a75458710cb4e", "extra_info": null, "node_info": {"start": 1810, "end": 2853}, "relationships": {"1": "72327b6f-82fb-4d59-b7ba-27f31e743680", "2": "edfad337-8a36-4363-bb3b-570cd4f9b223", "3": "93e264f4-ec8b-4c73-85c8-ac1ebf2fbcaa"}, "__type__": "1"}, "93e264f4-ec8b-4c73-85c8-ac1ebf2fbcaa": {"text": "usually referred to as a thread or Learning  Objectives\nAfter studying this chapter, you should be able to:\n\u2022\tUnderstand the distinction between process and thread.\n\u2022\tDescribe the basic design issues for threads.\n\u2022\tExplain the difference between user-level threads and kernel-level threads.\n\u2022\tDescribe the thread management facility in Windows.\n\u2022\tDescribe the thread management facility in Solaris.\n\u2022\tDescribe the thread management facility in Linux.\nM04_STAL4290_09_GE_C04.indd   177 5/2/17   4:38 PM\n178  CHAPTER  4 / T HREADS\nlightweight\u00a0process, while the unit of resource ownership is usually referred to as a \nprocess or task.1\nMultithreading\nMultithreading refers to the ability of an OS to support multiple, concurrent paths of execution within a single process. The traditional approach of a single thread of execution per process, in which the concept of a thread is not recognized, is referred to as a single-threaded approach. The two", "doc_id": "93e264f4-ec8b-4c73-85c8-ac1ebf2fbcaa", "embedding": null, "doc_hash": "1d1772e35564a22450536981e1f184783ee1b6ae13db3b12ae734454815b8dc9", "extra_info": null, "node_info": {"start": 2852, "end": 3798}, "relationships": {"1": "72327b6f-82fb-4d59-b7ba-27f31e743680", "2": "411ae8a6-eb98-4661-a305-d16144551236", "3": "b80c5e5f-3aa6-47f0-bab0-ffe40243d201"}, "__type__": "1"}, "b80c5e5f-3aa6-47f0-bab0-ffe40243d201": {"text": "is not recognized, is referred to as a single-threaded approach. The two arrangements shown in the left half of Figure 4.1 are single-threaded approaches. MS-DOS is an example of an OS that supports a single-user process and a single thread. Other operating systems, such as some variants of UNIX, support multiple user processes, but only support one thread per process. The right half of Figure 4.1 depicts multithreaded approaches. A\u00a0Java runtime environment is an example of a system of one process with multiple threads. Of interest in this section is the use of multiple processes, each of which supports multiple threads. This approach is taken in Windows, Solaris, and many \n1Alas, even this degree of consistency is not maintained. In IBM\u2019s mainframe operating systems, the con-\ncepts of address space and task, respectively, correspond roughly to the concepts of process and thread that \nwe describe in this section. Also, in the literature, the term lightweight process is used as either (1)\u00a0equiva-lent", "doc_id": "b80c5e5f-3aa6-47f0-bab0-ffe40243d201", "embedding": null, "doc_hash": "278df156cfac333a39418598ec20bd59a5267ef9de51e5a3cea75bbe464e4208", "extra_info": null, "node_info": {"start": 3813, "end": 4827}, "relationships": {"1": "72327b6f-82fb-4d59-b7ba-27f31e743680", "2": "93e264f4-ec8b-4c73-85c8-ac1ebf2fbcaa", "3": "7abe8520-7306-4832-b1d4-ebdcd12d3f83"}, "__type__": "1"}, "7abe8520-7306-4832-b1d4-ebdcd12d3f83": {"text": "the term lightweight process is used as either (1)\u00a0equiva-lent to the term thread, (2) a particular type of thread known as a kernel-level thread, or (3) in the case of Solaris, an entity that maps user-level threads to kernel-level threads.Figure 4.1  Thr eads and ProcessesOne process\nOne threadOne process\nMultiple threads\nMultiple processes\nOne thread per process\n= Instruction traceMultiple processes\nMultiple threads per process\nM04_STAL4290_09_GE_C04.indd   178 5/2/17   4:38 PM", "doc_id": "7abe8520-7306-4832-b1d4-ebdcd12d3f83", "embedding": null, "doc_hash": "ad0bfabd376b3e59137b0ad10cb572a324b49ec7cf0f3649c8b3cd20727d6c8e", "extra_info": null, "node_info": {"start": 4826, "end": 5311}, "relationships": {"1": "72327b6f-82fb-4d59-b7ba-27f31e743680", "2": "b80c5e5f-3aa6-47f0-bab0-ffe40243d201"}, "__type__": "1"}, "4ca54d0f-d37a-40eb-a33c-722f37ae3a72": {"text": "4.1 / PROCESSES AND THREADS   179\nmodern\u00a0versions of UNIX, among others. In this section, we give a general descrip-\ntion of multithreading; the details of the Windows, Solaris, and Linux approaches will be discussed later in this chapter.\nIn a multithreaded environment, a process is defined as the unit of resource \nallocation and a unit of protection. The following are associated with processes:\n\u2022\tA virtual address space that holds the process image\n\u2022\tProtected access to processors, other processes (for interprocess communica-tion), files, and I/O resources (devices and channels)\nWithin a process, there may be one or more threads, each with the following:\n\u2022\tA thread execution state (Running, Ready, etc.)\n\u2022\tA saved thread context when not running; one way to view a thread is as an independent program counter operating within a process\n\u2022\tAn execution stack\n\u2022\tSome per-thread static storage for local variables\n\u2022\tAccess to the memory and resources of its process, shared with all other threads in that", "doc_id": "4ca54d0f-d37a-40eb-a33c-722f37ae3a72", "embedding": null, "doc_hash": "b61bd5d5dcf731ca884fb9121b53cff70b6252f3effac8aa264d86e809fe4a2a", "extra_info": null, "node_info": {"start": 0, "end": 1011}, "relationships": {"1": "62846c31-f686-4440-b352-0689cc3a2e88", "3": "63d4cba5-7262-410b-b724-f1c162ddc042"}, "__type__": "1"}, "63d4cba5-7262-410b-b724-f1c162ddc042": {"text": "to the memory and resources of its process, shared with all other threads in that process\nFigure 4.2 illustrates the distinction between threads and processes from the \npoint of view of process management. In a single-threaded process model (i.e., there \nis no distinct concept of thread), the representation of a process includes its process control block and user address space, as well as user and kernel stacks to manage the call/return behavior of the execution of the process. While the process is running, it controls the processor registers. The contents of these registers are saved when the process is not running. In a multithreaded environment, there is still a single process \nFigure 4.2  Single-Thr eaded and Multithreaded Process ModelsSingle-threaded\nprocess model\nProcess\ncontrol\nblock\nUser\naddress\nspaceUser\nstack\nKernel\nstackMultithreaded\nprocess model\nProcess\ncontrol\nblock\nUser\naddress\nspaceUser\nstack\nKernel\nstackUser\nstack\nKernel\nstackUser\nstack\nKernel\nstackThread\ncontrol\nblockThread Thread", "doc_id": "63d4cba5-7262-410b-b724-f1c162ddc042", "embedding": null, "doc_hash": "09d17977a9bf7671ec5931fea8f00e787a8a76b8d44d74dbb42285d53103b7be", "extra_info": null, "node_info": {"start": 945, "end": 1959}, "relationships": {"1": "62846c31-f686-4440-b352-0689cc3a2e88", "2": "4ca54d0f-d37a-40eb-a33c-722f37ae3a72", "3": "e7861035-fdd0-4fb7-bbea-b4daf0f07927"}, "__type__": "1"}, "e7861035-fdd0-4fb7-bbea-b4daf0f07927": {"text": "Thread Thread\nThread\ncontrol\nblockThread\ncontrol\nblock\nM04_STAL4290_09_GE_C04.indd   179 5/2/17   4:38 PM\n180  CHAPTER  4 / T HREADS\ncontrol block and user address space associated with the process, but now there are \nseparate stacks for each thread, as well as a separate control block for each thread containing register values, priority, and other thread-related state information.\nThus, all of the threads of a process share the state and resources of that process. \nThey reside in the same address space and have access to the same data. When one thread alters an item of data in memory, other threads see the results if and when they access that item. If one thread opens a file with read privileges, other threads in the same process can also read from that file.\nThe key benefits of threads derive from the performance implications:\n1.\n It\n takes far less time to create a new thread in an existing process, than to create \na brand-new process. Studies done by the Mach developers show that thread creation is ten times", "doc_id": "e7861035-fdd0-4fb7-bbea-b4daf0f07927", "embedding": null, "doc_hash": "05d173b4fb9e62f0980bd1863ed7a8c2e06a2cb2e7193baf8239358210b3723e", "extra_info": null, "node_info": {"start": 2021, "end": 3048}, "relationships": {"1": "62846c31-f686-4440-b352-0689cc3a2e88", "2": "63d4cba5-7262-410b-b724-f1c162ddc042", "3": "10c4e692-69d5-454a-9617-8097e2356118"}, "__type__": "1"}, "10c4e692-69d5-454a-9617-8097e2356118": {"text": "brand-new process. Studies done by the Mach developers show that thread creation is ten times faster than process creation in UNIX [TEVA87].\n2.\n It tak\nes less time to terminate a thread than a process.\n3.\n It tak\nes less time to switch between two threads within the same process than \nto switch between processes.\n4.\n T\nhreads enhance efficiency in communication between different executing \nprograms. In most operating systems, communication between independent processes requires the intervention of the kernel to provide protection and the mechanisms needed for communication. However, because threads within the same process share memory and files, they can communicate with each other without invoking the kernel.\nThus, if there is an application or function that should be implemented as a set \nof related units of execution, it is far more efficient to do so as a collection of threads, \nrather than a collection of separate processes.\nAn example of an application that could make use of threads is a file server. As \neach new file request comes in, a new thread can be spawned for the file management program. Because a", "doc_id": "10c4e692-69d5-454a-9617-8097e2356118", "embedding": null, "doc_hash": "253b7f2c4c9447230ab07a1aca4677825330e8819e03a58e5f90c21dabd24be8", "extra_info": null, "node_info": {"start": 2976, "end": 4105}, "relationships": {"1": "62846c31-f686-4440-b352-0689cc3a2e88", "2": "e7861035-fdd0-4fb7-bbea-b4daf0f07927", "3": "82368404-e2ef-4fd9-9ea6-1651eef9fb1e"}, "__type__": "1"}, "82368404-e2ef-4fd9-9ea6-1651eef9fb1e": {"text": "file request comes in, a new thread can be spawned for the file management program. Because a server will handle many requests, many threads will be created and destroyed in a short period. If the server runs on a multiprocessor computer, then multiple threads within the same process can be executing simultaneously on different processors. Further, because processes or threads in a file server must share file data and therefore coordinate their actions, it is faster to use threads and shared memory than processes and message passing for this coordination.\nThe thread construct is also useful on a single processor to simplify the structure \nof a program that is logically doing several different functions.\n[LETW88] gives four examples of the uses of threads in a single-user multipro-\ncessing system:\n1.\n F\noreground and background work: For example, in a spreadsheet program, one \nthread could display menus and read user input, while another thread executes user commands and updates the spreadsheet. This arrangement often increases the perceived speed of the application by allowing the program to prompt", "doc_id": "82368404-e2ef-4fd9-9ea6-1651eef9fb1e", "embedding": null, "doc_hash": "e7f91e9348a16acb7f0b2a057b5ec27c68508c71e3e5ba70adda4c03e26431d7", "extra_info": null, "node_info": {"start": 4108, "end": 5223}, "relationships": {"1": "62846c31-f686-4440-b352-0689cc3a2e88", "2": "10c4e692-69d5-454a-9617-8097e2356118", "3": "9584b44e-3c57-4177-88ef-92a9adcf37e9"}, "__type__": "1"}, "9584b44e-3c57-4177-88ef-92a9adcf37e9": {"text": "often increases the perceived speed of the application by allowing the program to prompt for the next command before the previous command is complete.\n2.\n Asynchr\nonous processing: Asynchronous elements in the program can be \nimplemented as threads. For example, as a protection against power failure, one can design a word processor to write its random access memory (RAM) \nM04_STAL4290_09_GE_C04.indd   180 5/2/17   4:38 PM\n4.1 / PROCESSES AND THREADS   181\nbuffer to disk once every minute. A thread can be created whose sole job is \nperiodic backup and that schedules itself directly with the OS; there is no need for fancy code in the main program to provide for time checks or to coordinate input and output.\n3.\n Speed of e\nxecution: A multithreaded process can compute one batch of data \nwhile reading the next batch from a device. On a multiprocessor system, mul-tiple threads from the same process may be able to execute", "doc_id": "9584b44e-3c57-4177-88ef-92a9adcf37e9", "embedding": null, "doc_hash": "8f1bdc270c8fdaff9a0f2f71cd659718565af1d88ef16ff929187ceb119a4274", "extra_info": null, "node_info": {"start": 5226, "end": 6155}, "relationships": {"1": "62846c31-f686-4440-b352-0689cc3a2e88", "2": "82368404-e2ef-4fd9-9ea6-1651eef9fb1e", "3": "962ed776-1aa6-472f-837f-4ff8875cf0c0"}, "__type__": "1"}, "962ed776-1aa6-472f-837f-4ff8875cf0c0": {"text": "system, mul-tiple threads from the same process may be able to execute simultaneously. Thus, even though one thread may be blocked for an I/O operation to read in a batch of data, another thread may be executing.\n4.\n Modular pr\nogram structure: Programs that involve a variety of activities or a \nvariety of sources and destinations of input and output may be easier to design and implement using threads.\nIn an OS that supports threads, scheduling and dispatching is done on a thread \nbasis; hence, most of the state information dealing with execution is maintained \nin thread-level data structures. There are, however, several actions that affect all of the threads in a process, and that the OS must manage at the process level. For example, suspension involves swapping the address space of one process out of main memory to make room for the address space of another process. Because all threads in a process share the same address space, all threads are suspended at the same time. Similarly, termination of a process terminates all threads within that", "doc_id": "962ed776-1aa6-472f-837f-4ff8875cf0c0", "embedding": null, "doc_hash": "74bcfadb5552cdaee1d51e14ccf19c4a4418463631a09af2c6cbf9ed579df5aa", "extra_info": null, "node_info": {"start": 6172, "end": 7230}, "relationships": {"1": "62846c31-f686-4440-b352-0689cc3a2e88", "2": "9584b44e-3c57-4177-88ef-92a9adcf37e9", "3": "cade53e7-fbf8-455a-a49d-2ba90df309bf"}, "__type__": "1"}, "cade53e7-fbf8-455a-a49d-2ba90df309bf": {"text": "suspended at the same time. Similarly, termination of a process terminates all threads within that process.\nThread Functionality\nLike processes, threads have execution states and may synchronize with one another. We look at these two aspects of thread functionality in turn.\nThread  STaTeS  As with processes, the key states for a thread are Running, Ready, \nand Blocked. Generally, it does not make sense to associate suspend states with threads because such states are process-level concepts. In particular, if a process is swapped out, all of its threads are necessarily swapped out because they all share the address space of the process.\nThere are four basic thread operations associated with a change in thread state \n[ANDE04]:\n1.\n Spa\nwn: Typically, when a new process is spawned, a thread for that process \nis also spawned. Subsequently, a thread within a process may spawn another thread within the same process, providing an instruction pointer and arguments for the new thread. The new thread is provided with its own register context and stack space and placed on the Ready queue.\n2.\n", "doc_id": "cade53e7-fbf8-455a-a49d-2ba90df309bf", "embedding": null, "doc_hash": "5a9384cf8344794c8740b9c86e8f66c8cef08edd32e1224efa7c1d7dfdd3d28a", "extra_info": null, "node_info": {"start": 7206, "end": 8302}, "relationships": {"1": "62846c31-f686-4440-b352-0689cc3a2e88", "2": "962ed776-1aa6-472f-837f-4ff8875cf0c0", "3": "09c00c07-b0f5-479c-b423-8be95fd56eb1"}, "__type__": "1"}, "09c00c07-b0f5-479c-b423-8be95fd56eb1": {"text": "provided with its own register context and stack space and placed on the Ready queue.\n2.\n Block:\n When a thread needs to wait for an event, it will block (saving its user \nregisters, program counter, and stack pointers). The processor may then turn to the execution of another ready thread in the same or a different process.\n3.\n Unblock:\n When the event for which a thread is blocked occurs, the thread is \nmoved to the Ready queue.\n4.\n Finish:\n When a thread completes, its register context and stacks are deallocated.\nM04_STAL4290_09_GE_C04.indd   181 5/2/17   4:38 PM", "doc_id": "09c00c07-b0f5-479c-b423-8be95fd56eb1", "embedding": null, "doc_hash": "7015ea87bcb5afb17bd96a4de3010a6e98d1e6f6b5d80c52c9561eaadecbeb46", "extra_info": null, "node_info": {"start": 8297, "end": 8868}, "relationships": {"1": "62846c31-f686-4440-b352-0689cc3a2e88", "2": "cade53e7-fbf8-455a-a49d-2ba90df309bf"}, "__type__": "1"}, "00df1ced-4913-485c-8665-080e62eb35db": {"text": "182  CHAPTER  4 / T HREADS\nA significant issue is whether the blocking of a thread results in the blocking \nof the entire process. In other words, if one thread in a process is blocked, does this \nprevent the running of any other thread in the same process, even if that other thread is in a ready state? Clearly, some of the flexibility and power of threads is lost if the one blocked thread blocks an entire process.\nWe will return to this issue subsequently in our discussion of user-level versus \nkernel-level threads, but for now, let us consider the performance benefits of threads that do not block an entire process. Figure 4.3 (based on one in [KLEI96]) shows a program that performs two remote procedure calls (RPCs)\n2 to two different hosts to \nobtain a combined result. In a single-threaded program, the results are obtained in sequence, so the program has to wait for a response from each server in turn. Rewrit-ing the program to use a separate thread for each RPC results in a substantial speedup. Note if this program", "doc_id": "00df1ced-4913-485c-8665-080e62eb35db", "embedding": null, "doc_hash": "a59317535c3f33b0749ea7e653a6650dc71a9bb013d79c3a5c0f5ef107e96b2a", "extra_info": null, "node_info": {"start": 0, "end": 1033}, "relationships": {"1": "a7056b97-b339-4cb0-bd70-3b1522ca7941", "3": "6d11ee4e-28c7-40d3-9040-ab32083b8857"}, "__type__": "1"}, "6d11ee4e-28c7-40d3-9040-ab32083b8857": {"text": "a separate thread for each RPC results in a substantial speedup. Note if this program operates on a uniprocessor, the requests must be gener -\nated sequentially and the results processed in sequence; however, the program waits concurrently for the two replies.\n2An RPC is a technique by which two programs, which may execute on different machines, interact using \nprocedure call/return syntax and semantics. Both the called and calling programs behave as if the partner \nprogram were running on the same machine. RPCs are often used for client/server applications\u00a0and will be discussed in Chapter 16 .Figure 4.3  R emote Procedure Call (RPC) Using Threads(a) RPC using single thread\n(b) RPC using one thread per server (on a uniprocessor)Time\nProcess 1\nBlocked, waiting for response to RPC\nBlocked, waiting for processor, which is in use by Thread B\nRunningThread A (Process 1)\nThread B (Process 1)Server", "doc_id": "6d11ee4e-28c7-40d3-9040-ab32083b8857", "embedding": null, "doc_hash": "3b327efd950340365f0e3b84738cf236f6a6a943492b38f27de43adb50497bf5", "extra_info": null, "node_info": {"start": 963, "end": 1867}, "relationships": {"1": "a7056b97-b339-4cb0-bd70-3b1522ca7941", "2": "00df1ced-4913-485c-8665-080e62eb35db", "3": "a7dacfa1-f0f6-40d7-b9c0-0ee55cff780f"}, "__type__": "1"}, "a7dacfa1-f0f6-40d7-b9c0-0ee55cff780f": {"text": "use by Thread B\nRunningThread A (Process 1)\nThread B (Process 1)Server Server\nServer\nServerRPC\nrequest\nRPC\nrequest\nRPC\nrequestRPC\nrequest\nM04_STAL4290_09_GE_C04.indd   182 5/2/17   4:38 PM\n4.2 / TYPES OF THREADS   183\nOn a uniprocessor, multiprogramming enables the interleaving of multiple \nthreads within multiple processes. In the example of Figure 4.4, three threads in two \nprocesses are interleaved on the processor. Execution passes from one thread to another either when the currently running thread is blocked or when its time slice is exhausted.\n3\nThread  SynchronizaTion  All of the threads of a process share the same address \nspace and other resources, such as open files. Any alteration of a resource by one thread affects the environment of the other threads in the same process. It is therefore necessary to synchronize the activities of the various threads so that they do not interfere", "doc_id": "a7dacfa1-f0f6-40d7-b9c0-0ee55cff780f", "embedding": null, "doc_hash": "193e81159367a23d89152c338d2d790cec1f9fdafcb19626607491acdec22a91", "extra_info": null, "node_info": {"start": 1878, "end": 2781}, "relationships": {"1": "a7056b97-b339-4cb0-bd70-3b1522ca7941", "2": "6d11ee4e-28c7-40d3-9040-ab32083b8857", "3": "7e833c1c-7ecc-4b4d-bcd0-173409293f32"}, "__type__": "1"}, "7e833c1c-7ecc-4b4d-bcd0-173409293f32": {"text": "synchronize the activities of the various threads so that they do not interfere with each other or corrupt data structures. For example, if two threads each try to add an element to a doubly linked list at the same time, one element may be lost or the list may end up malformed.\nThe issues raised and the techniques used in the synchronization of threads \nare, in general, the same as for the synchronization of processes.\u00a0These issues and techniques will be the subject of Chapters 5 and 6.\n 4. 2 TYPES OF THREADS\nUser-Level and Kernel-Level Threads\nThere are two broad categories of thread implementation: user-level threads (ULTs) and kernel-level threads (KLTs).\n4 The latter are also referred to in the literature as \nkernel-supported threads or lightweight processes.\nUSer-Leve L Thread S In a pure ULT facility, all of the work of thread management \nis done by the application and the kernel is not aware of the existence of threads. \n3In this example, thread C begins to run", "doc_id": "7e833c1c-7ecc-4b4d-bcd0-173409293f32", "embedding": null, "doc_hash": "f74dd61201c1310de3c4512d1b2591c17b2b8fe19360a2001e6f4f10fbffd9ba", "extra_info": null, "node_info": {"start": 2776, "end": 3758}, "relationships": {"1": "a7056b97-b339-4cb0-bd70-3b1522ca7941", "2": "a7dacfa1-f0f6-40d7-b9c0-0ee55cff780f", "3": "738ed06c-6e9e-4447-a6df-d21c8b18f016"}, "__type__": "1"}, "738ed06c-6e9e-4447-a6df-d21c8b18f016": {"text": "aware of the existence of threads. \n3In this example, thread C begins to run after thread A exhausts its time quantum, even though thread B \nis also ready to run. The choice between B and C is a scheduling decision, a topic covered in Part Four.\n4The acronyms ULT and KLT are not widely used, but are introduced for conciseness.Figure 4.4  Multithr eading Example on a UniprocessorTime\nBlockedI/O\nrequest\nThread A (Process 1)\nThread B (Process 1)\nThread C (Process 2)\nReady RunningRequest\ncompleteTime quantum\nexpires\nTime quantum\nexpires\nProcess\ncreated\nM04_STAL4290_09_GE_C04.indd   183 5/2/17   4:38 PM\n184  CHAPTER  4 / T HREADS\nFigure 4.5a illustrates the pure ULT approach. Any application can be programmed \nto be multithreaded by using a threads library, which is a package of routines for ULT management. The threads library", "doc_id": "738ed06c-6e9e-4447-a6df-d21c8b18f016", "embedding": null, "doc_hash": "1abb317670304ee2cd17d9c565ecb0294a950ce758deb388e81b33c06fdd3bd8", "extra_info": null, "node_info": {"start": 3763, "end": 4596}, "relationships": {"1": "a7056b97-b339-4cb0-bd70-3b1522ca7941", "2": "7e833c1c-7ecc-4b4d-bcd0-173409293f32", "3": "2dc2b6d1-7689-4d23-904a-f3c8bf03ecaf"}, "__type__": "1"}, "2dc2b6d1-7689-4d23-904a-f3c8bf03ecaf": {"text": "threads library, which is a package of routines for ULT management. The threads library contains code for creating and destroying threads, for passing messages and data between threads, for scheduling thread execution, and for saving and restoring thread contexts.\nBy default, an application begins with a single thread and begins running in \nthat thread. This application and its thread are allocated to a single process man-aged by the kernel. At any time that the application is running (the process is in the Running state), the application may spawn a new thread to run within the same process. Spawning is done by invoking the spawn utility in the threads library. Con-trol is passed to that utility by a procedure call. The threads library creates a data structure for the new thread and then passes control to one of the threads within this process that is in the Ready state, using some scheduling algorithm. When control is passed to the library, the context of the current thread is saved, and when control is passed from the library to a thread, the context of that thread is restored. The context essentially", "doc_id": "2dc2b6d1-7689-4d23-904a-f3c8bf03ecaf", "embedding": null, "doc_hash": "ba6e1341762ab742bd0263f9dc45649e4c23f824251c923dd2baf52d40851c3a", "extra_info": null, "node_info": {"start": 4586, "end": 5707}, "relationships": {"1": "a7056b97-b339-4cb0-bd70-3b1522ca7941", "2": "738ed06c-6e9e-4447-a6df-d21c8b18f016", "3": "a818d593-98dd-4efb-ab30-af8b6d7bf716"}, "__type__": "1"}, "a818d593-98dd-4efb-ab30-af8b6d7bf716": {"text": "from the library to a thread, the context of that thread is restored. The context essentially consists of the contents of user registers, the program counter, and stack pointers.\nAll of the activity described in the preceding paragraph takes place in user \nspace and within a single process. The kernel is unaware of this activity. The ker -\nnel continues to schedule the process as a unit and assigns a single execution state (Ready, Running, Blocked, etc.) to that process. The following examples should clarify the relationship between thread scheduling and process scheduling. Suppose process B is executing in its thread 2; the states of the process and two ULTs that are part of the process are shown in Figure 4.6a. Each of the following is a possible occurrence:\n1.\n T\nhe application executing in thread 2 makes a system call that blocks B. For \nexample, an I/O call is made. This causes control to transfer to the kernel. The kernel invokes the I/O action, places process B in the Blocked state, and Figure 4.5  User -Level and", "doc_id": "a818d593-98dd-4efb-ab30-af8b6d7bf716", "embedding": null, "doc_hash": "91cb8a87ac9499afefffbe2dbc52edb1de9445f370c2093dacebf466d9366a19", "extra_info": null, "node_info": {"start": 5704, "end": 6740}, "relationships": {"1": "a7056b97-b339-4cb0-bd70-3b1522ca7941", "2": "2dc2b6d1-7689-4d23-904a-f3c8bf03ecaf", "3": "23091df3-ac3c-4f6d-b146-bff341e76798"}, "__type__": "1"}, "23091df3-ac3c-4f6d-b146-bff341e76798": {"text": "places process B in the Blocked state, and Figure 4.5  User -Level and Kernel-Level ThreadsP PUser\nspaceThreads\nlibrary\nKernel\nspace\nP\nPUser\nspace\nKernel\nspace\nPUser\nspaceThreadslibrary\nKernel\nspace\n(c) Combined (b) Pure kernel\u2013level (a) Pure user\u2013level\nUser-level thread Kernel-level thread Process\nM04_STAL4290_09_GE_C04.indd   184 5/2/17   4:38 PM", "doc_id": "23091df3-ac3c-4f6d-b146-bff341e76798", "embedding": null, "doc_hash": "04debee2fe8439d8fd2e52c093429063f8b53adca6890559e385f36065db39d3", "extra_info": null, "node_info": {"start": 6748, "end": 7098}, "relationships": {"1": "a7056b97-b339-4cb0-bd70-3b1522ca7941", "2": "a818d593-98dd-4efb-ab30-af8b6d7bf716"}, "__type__": "1"}, "93f92626-ac10-4599-9804-23cefad9f84c": {"text": "\n\nThis document provides an overview of processes and threads, including types of threads, performance of software on multicore systems, the distinction between resource ownership and execution, management of processes and threads on Windows, Solaris, Linux, Android, and Mac OS X Grand Central Dispatch, the scheduling and execution of processes, their execution state and dispatching priority, and the protection of resources from unwanted interference. It also covers the distinction between process and thread, the basic design issues for threads, the difference between user-level threads and kernel-level threads, the thread management facility in Windows, Solaris, Linux, and Mac OS X Grand Central Dispatch, and the use of multiple processes, each of which may contain multiple threads. Additionally, it discusses multithreading, which refers to the ability of an OS to support multiple, concurrent paths of execution within a single process, with one thread per process and multiple threads per process. The document also covers the use of the term lightweight process, which is used as either (1) equivalent to the term thread, (2) a particular type of thread known as a kernel-level thread, or (3) in the case of Solaris, an entity that maps user-level threads to kernel-level threads. A summary of key", "doc_id": "93f92626-ac10-4599-9804-23cefad9f84c", "embedding": null, "doc_hash": "d15f3a9857c4f839fcb45575750de8d72f427a2dac8e47f4d9c5c81804a4f765", "extra_info": null, "node_info": null, "relationships": {"1": "b49022f6-df1b-4406-a114-305111a6ea76"}, "index_id": "b49022f6-df1b-4406-a114-305111a6ea76", "__type__": "3"}, "cb43bb52-6563-4744-ae6e-b55f23449c22": {"text": "\n\nThis document provides a general description of multithreading, including the associated processes and threads. It explains that a process is the unit of resource allocation and protection, and that it has a virtual address space, protected access to processors, other processes, files, and I/O resources. It also explains that threads have an execution state, a saved thread context, an execution stack, some per-thread static storage, and access to the memory and resources of its process, shared with all other threads in that process. Threads have separate stacks for each thread, as well as a separate control block for each thread containing register values, priority, and other thread-related state information. All of the threads of a process share the state and resources of that process, residing in the same address space and having access to the same data. When a thread is blocked, its user registers, program counter, and stack pointers are saved. When the event for which a thread is blocked occurs, the thread is moved to the Ready queue. When a thread completes, its register context and stacks are deallocated. The key benefits of threads include improved performance, such as faster creation and termination of threads, faster switching between threads, and enhanced efficiency in communication between different executing programs. Additionally", "doc_id": "cb43bb52-6563-4744-ae6e-b55f23449c22", "embedding": null, "doc_hash": "88697746717becfc59720500923b9a29b599783d85d0ba1a222093cc426a8d26", "extra_info": null, "node_info": null, "relationships": {"1": "ac05f3ea-ca78-4a9f-862a-d99d5fd63cbb"}, "index_id": "ac05f3ea-ca78-4a9f-862a-d99d5fd63cbb", "__type__": "3"}, "6d770321-a5d4-4655-90a5-dc5909484b1c": {"text": "\n\nThis document discusses the issue of whether the blocking of a thread results in the blocking of the entire process, and the potential performance benefits of using multiple threads for a program that performs two remote procedure calls (RPCs). It provides an example of how using multiple threads can result in a substantial speedup, even when the program operates on a uniprocessor, as the requests can be generated sequentially and the results processed in sequence while the program waits concurrently for the two replies. On a uniprocessor, multiprogramming enables the interleaving of multiple threads within multiple processes, with execution passing from one thread to another either when the currently running thread is blocked or when its time slice is exhausted. All of the threads of a process share the same address space and other resources, such as open files, and any alteration of a resource by one thread is visible to all other threads. There are two broad types of threads: user-level threads (ULTs) and kernel-level threads (KLTs). The example provided shows how three threads in two processes are interleaved on the processor, with two of the threads being pure user-level threads and one being a pure kernel-level thread. It is necessary to synchronize the", "doc_id": "6d770321-a5d4-4655-90a5-dc5909484b1c", "embedding": null, "doc_hash": "26ff719ba91cfa6bdd84c52a09755ff8ce2ef36ab07cc663152b00da9e37566f", "extra_info": null, "node_info": null, "relationships": {"1": "da538f95-7fa5-4685-a9c6-ab3e0a475f05"}, "index_id": "da538f95-7fa5-4685-a9c6-ab3e0a475f05", "__type__": "3"}}, "ref_doc_info": {}}, "query_context": {"b49022f6-df1b-4406-a114-305111a6ea76": {}, "ac05f3ea-ca78-4a9f-862a-d99d5fd63cbb": {}, "da538f95-7fa5-4685-a9c6-ab3e0a475f05": {}, "57e1a633-72fd-483d-a0e5-dedd7997f901": {}}}