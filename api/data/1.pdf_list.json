{"index_struct": {"__type__": "list", "__data__": {"index_id": "6ee951d8-c471-4e54-ab97-b26f7386d59b", "summary": null, "nodes": ["1bce21cc-6292-486f-b552-aa583fe1ae6e", "827f06d0-137b-4ddb-9ad8-2ba188209398", "e162b64c-29fa-4a2a-86c9-b6bd3fc7575d", "d635ea55-a1c9-4bb3-84a4-530cf2f92c37", "e16f4b91-966c-4ba7-93c0-2c66dafbaf01", "99adb257-9a82-495e-8767-98455ad07f1f", "ee759e11-d017-46a2-a634-00e5823a9768", "d1a56696-a130-4c57-9765-49e55bb82d77", "42927124-7cd0-46f7-81e2-2e4e6a6093b9", "cb01e739-b50f-4a19-ae93-f5e8f3928ff9", "214e3571-64dd-4b3b-bcf2-bfe87b052dca", "ddda3c00-63d6-444a-accc-6c5829cb8b25", "94a7b568-ce3c-46f2-9fd7-1bb361b5a96f", "e3710436-e0b6-49de-94f3-dc99d687ee29", "dbeb0e92-bf8f-45cc-a403-f75cc856b76b", "66d62401-d2e4-4a91-8852-48a67e463731", "29d3af5c-2481-4742-8354-89641027b9fd", "1956f39b-642b-4791-a2cd-a71e69f9118a", "4e497f64-4b7b-45fd-b7a3-5092d0311430", "371d1e90-3f53-44df-9856-1b02e4f948fe", "c8762864-03ec-4fd8-8cf8-fd5fe9b5c591", "07a4a574-4fea-4c85-83f0-2dbb6e9ff97a", "f627a822-8162-4d90-b3d1-dbc42861a43f", "e704e61b-747f-4863-95dc-17332d8d40c6", "dc45cb06-0d54-4f47-a5f3-0347a42f7e01", "8dd41955-2532-48dd-832a-dff5d755e0ce", "9741174c-6633-4d61-99db-80ed23bf6dc5", "e9f18049-f1ef-4b64-93b3-50575e34cafb", "fde0fbd4-1866-433e-9d7a-a7aa904b038b", "e3e20d8d-48e7-4deb-b194-fe2d8e01a463", "5b8b2298-809f-4c6f-97d8-e6ad1e588be2", "14a17423-13f0-4c7b-b557-141645ae59cf", "09713ad0-2cca-4e8d-a2d2-974cb8e356fe", "e479e673-2a0f-456e-aeb6-dd1cf188203c", "81efe060-3e53-4e1e-bcdb-6b9aff005be7", "5738e669-dbd5-4035-aca1-baeaba4bcec9", "f2da7778-7ac7-48e6-8124-0c298d652330", "6d5169ed-f5e9-43b7-8c75-b56259949947", "c694ab14-5d44-471d-b5ef-97a83fcd5d30", "65fd0866-608c-4e90-96a5-46f4c9120cc2", "b32875b6-44da-419b-b329-acde6729f7fb", "4c94d296-be9d-4882-897b-f1c2e160594f", "262cf7a1-114f-41b9-8605-1de677babe5b", "809a1279-2d99-4487-8e4e-a0b66ac0aa75", "b07b0a20-8c4b-4b10-944f-6d278c3a73d3", "fc793b9c-85bb-4e80-9577-2a9ed02b9487", "8ec91488-f51b-47e5-844e-66ee93580447", "b37a9554-fc95-4c11-a1aa-61375bad250b", "6d30bdfa-f603-4428-be3f-d27fb323be36", "6f112c29-d5ab-4c63-b201-01b9f3a7f354", "2981ef25-c99b-411a-acf0-c94a8ecdc71f", "9fe20c72-4216-4dd9-ad13-d554fb6764dd", "7c82a23b-db71-4f6a-b3d0-e28139fde880", "bc73a9ad-9412-4e11-957f-8b7f34056979", "de5a1729-c464-45ac-80f5-cbd8583f0878", "51baf38e-b5c2-438a-a541-cdf1e36abd24", "bd7e5557-7704-48f1-bcca-193a8c573fd6", "c376ecb7-3ec8-4607-acc4-0599366f85bf", "fbb0bc3a-e161-48b5-8101-a4e6a93a1399", "61e90ff3-a68e-42d9-8470-eb822a05dce3", "0861d760-e8a9-47ea-a2b9-3856c5958f9b", "22632d94-c8cb-4c02-a811-1d0ddbeda6b9", "99ef7f4a-3e1b-4f21-adce-7e9d7b4f1185", "5e7613fe-7d60-401c-a80e-9991dc3e55f6", "943626f0-5f75-4025-ac64-ab4d3e0b240f", "10b7ee5f-2341-40e4-af56-47c6aace71ff", "43f9205c-dfd9-4d3e-81ff-55d3579b0847", "e25e0f29-b1b0-49ae-87ca-0bfd99804aac", "2cb73adf-a6dc-4c31-ac56-3303670570f3", "89095b03-f168-4478-8a18-7c4c4ded862c", "713e9567-730f-464b-9f2a-7ad04f61d5e1", "6b6cf7eb-1b7d-482d-be97-5a9f3fe85b64", "f1f9231a-56af-4079-87e8-e18971490cf2", "8c78592c-8ab2-4c55-a1cd-72ae44c03cca", "71a8e6a4-91b2-4e1a-af35-4071e6a42851", "bf7aed18-be1b-4ffd-83bf-1010523c0ff9", "0581fc00-e934-4c0a-a7f8-3738c8957341", "be2661ba-fd24-4c48-b0f4-b6e9e43d0449", "0c2545b6-8740-40fd-b8db-870c8a3f14bb", "72692f76-a6cf-4a10-b77b-257c697543b8", "2e2b3abf-c21c-4f13-ac2e-f3907ca8da40", "ebe8fbab-207b-4c07-8cab-e26ebf613926", "e1c2a299-0d27-48ab-90d1-0e7ebaf39460", "6103f75a-b5ed-4b74-9904-52f1958f7d69", "0eba9a57-7685-476c-9a68-b896b092bdb3", "bf8f1752-9480-4d34-ba53-abbd87a5e788", "0b8a211f-84ff-487c-8097-605021b609de", "808fb9de-29e5-4b3b-bd44-955ac259fac5", "73bc13fa-3b49-434c-b612-842f6362b5c2", "5382058e-510b-4f65-b630-d3d29020c2ed", "d787129c-ad2c-4fc4-816d-548231b08182", "a635f1e9-6091-43bb-b86c-c83251d8db8f", "c5b215a2-3850-4f1b-86c5-e536d0f3a78b", "1984ba9a-f84a-4750-b772-5783cef48a52", "19110383-7ae2-45be-865f-b1559f09f475", "e08861cb-d87f-4133-b68c-f469d0cdf8ee", "e56ec3b5-321e-4825-81d0-ab894e33618c", "ac687ab7-3ba6-48dc-89a4-6d0d7e3a66c8", "b5bb3178-3c4d-4d79-97af-a601919e8b3c", "b2af3f46-faa2-437c-acea-8a12551add2c", "f26418f9-06f7-47b6-8d59-5f4fb23a13ee"]}}, "docstore": {"docs": {"1bce21cc-6292-486f-b552-aa583fe1ae6e": {"text": "5 . 1\nO p t i m i z a t i o n\no f\nt h e\nc o m p u t a t i o n s\no f\nh i g h e r - o r d e r\ni n t e r a c t i o n s\na n d\ni n t e g r a t i o n\ni n\nt h e\nF r i t e s\np y t h o n\np a c k a g e\nInformation\nof\nabout\nmentors\n\u25cf\nEtienne\nCombrisson\nEmail:\ne.combrisson@gmail.com\nGithub:\nhttps://github.com/EtienneCmb\n\u25cf\nDaniele\nMarinazzo\nEmail:\ndaniele.marinazzo@gmail.com\nGithub:\nhttps://github.com/danielemarinazzo\nAbstract:\nT h i s\np r o j e c t\na i m s\na t\no p t i m i z i n g\nt h e\nc o m p u t a t i o n", "doc_id": "1bce21cc-6292-486f-b552-aa583fe1ae6e", "embedding": null, "doc_hash": "2d0aca42d8fda6e9df96eec597161751e4b886bb43d41a9c69992f48cad4ce35", "extra_info": null, "node_info": {"start": 0, "end": 500}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "3": "827f06d0-137b-4ddb-9ad8-2ba188209398"}, "__type__": "1"}, "827f06d0-137b-4ddb-9ad8-2ba188209398": {"text": "n t e r a c t i o n s\na n d\ni n t e g r a t i o n\ni n\nt h e\nF r i t e s\np y t h o n\np a c k a g e\nInformation\nof\nabout\nmentors\n\u25cf\nEtienne\nCombrisson\nEmail:\ne.combrisson@gmail.com\nGithub:\nhttps://github.com/EtienneCmb\n\u25cf\nDaniele\nMarinazzo\nEmail:\ndaniele.marinazzo@gmail.com\nGithub:\nhttps://github.com/danielemarinazzo\nAbstract:\nT h i s\np r o j e c t\na i m s\na t\no p t i m i z i n g\nt h e\nc o m p u t a t i o n s\no f\nd y n a m i c\nH O I s .\nT h e\ng o a l\ni s\nt o\nb e\na b l e\nt o\ne s t i m a t e\nt h", "doc_id": "827f06d0-137b-4ddb-9ad8-2ba188209398", "embedding": null, "doc_hash": "1e2157e487dd7b6379ccca97413da79da5718fb523214cce5e0e5fee3f2580b8", "extra_info": null, "node_info": {"start": 170, "end": 664}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "1bce21cc-6292-486f-b552-aa583fe1ae6e", "3": "e162b64c-29fa-4a2a-86c9-b6bd3fc7575d"}, "__type__": "1"}, "e162b64c-29fa-4a2a-86c9-b6bd3fc7575d": {"text": "h i s\np r o j e c t\na i m s\na t\no p t i m i z i n g\nt h e\nc o m p u t a t i o n s\no f\nd y n a m i c\nH O I s .\nT h e\ng o a l\ni s\nt o\nb e\na b l e\nt o\ne s t i m a t e\nt h e\nO - i n f o r m a t i o n\no n\nb o t h\ns i m u l a t e d\nd a t a\na n d\nr e a l\nb r a i n\nd a t a ,\np o s s i b l y\nw i t h\nh i g h\ns p a t i o t e m p o r a l\nr e s o l u t i o n .\nT o\nt h i s\ne n d ,\nw e\ns t a r t\nf r o m\na n\ne x i s t i n g\ni m p l e m e n t", "doc_id": "e162b64c-29fa-4a2a-86c9-b6bd3fc7575d", "embedding": null, "doc_hash": "a4c02707d121333c02d56975ad80056dea7e68ab3df45b324b24fdadf4471425", "extra_info": null, "node_info": {"start": 894, "end": 1323}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "827f06d0-137b-4ddb-9ad8-2ba188209398", "3": "d635ea55-a1c9-4bb3-84a4-530cf2f92c37"}, "__type__": "1"}, "d635ea55-a1c9-4bb3-84a4-530cf2f92c37": {"text": "i c\nH O I s .\nT h e\ng o a l\ni s\nt o\nb e\na b l e\nt o\ne s t i m a t e\nt h e\nO - i n f o r m a t i o n\no n\nb o t h\ns i m u l a t e d\nd a t a\na n d\nr e a l\nb r a i n\nd a t a ,\np o s s i b l y\nw i t h\nh i g h\ns p a t i o t e m p o r a l\nr e s o l u t i o n .\nT o\nt h i s\ne n d ,\nw e\ns t a r t\nf r o m\na n\ne x i s t i n g\ni m p l e m e n t a t i o n\nw h i c h\nw a s\nm a d e\nd u r i n g\nt h e\nB r a i n H a c k\n2 0 2 1\na n d\n2 0 2 2", "doc_id": "d635ea55-a1c9-4bb3-84a4-530cf2f92c37", "embedding": null, "doc_hash": "b0f2fed833716d7a06739f2becb4aa58a264aa56bf712f6139f53455616d8c4f", "extra_info": null, "node_info": {"start": 1226, "end": 1651}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "e162b64c-29fa-4a2a-86c9-b6bd3fc7575d", "3": "e16f4b91-966c-4ba7-93c0-2c66dafbaf01"}, "__type__": "1"}, "e16f4b91-966c-4ba7-93c0-2c66dafbaf01": {"text": "m a t i o n\no n\nb o t h\ns i m u l a t e d\nd a t a\na n d\nr e a l\nb r a i n\nd a t a ,\np o s s i b l y\nw i t h\nh i g h\ns p a t i o t e m p o r a l\nr e s o l u t i o n .\nT o\nt h i s\ne n d ,\nw e\ns t a r t\nf r o m\na n\ne x i s t i n g\ni m p l e m e n t a t i o n\nw h i c h\nw a s\nm a d e\nd u r i n g\nt h e\nB r a i n H a c k\n2 0 2 1\na n d\n2 0 2 2 .\nT h e\nt w o\ni m p l e m e n t a t i o n s\no f\nt h e\nH O I s\na r e :\na\nf i r s t\nv e r s i", "doc_id": "e16f4b91-966c-4ba7-93c0-2c66dafbaf01", "embedding": null, "doc_hash": "9e1e203d356e08433889e604b710e49806253520095fc0e201a93ae7dcb94d51", "extra_info": null, "node_info": {"start": 1652, "end": 2081}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "d635ea55-a1c9-4bb3-84a4-530cf2f92c37", "3": "99adb257-9a82-495e-8767-98455ad07f1f"}, "__type__": "1"}, "99adb257-9a82-495e-8767-98455ad07f1f": {"text": "b l y\nw i t h\nh i g h\ns p a t i o t e m p o r a l\nr e s o l u t i o n .\nT o\nt h i s\ne n d ,\nw e\ns t a r t\nf r o m\na n\ne x i s t i n g\ni m p l e m e n t a t i o n\nw h i c h\nw a s\nm a d e\nd u r i n g\nt h e\nB r a i n H a c k\n2 0 2 1\na n d\n2 0 2 2 .\nT h e\nt w o\ni m p l e m e n t a t i o n s\no f\nt h e\nH O I s\na r e :\na\nf i r s t\nv e r s i o n\nu s i n g\nt h e\ns t a n d a r d\nN u m P y\nl i b r a r y\n( H a r r i s\ne t\na l . ,\n2 0 2 0", "doc_id": "99adb257-9a82-495e-8767-98455ad07f1f", "embedding": null, "doc_hash": "cbb116eb6a3b223a990bec949426a91bf696678dda12101dfb8fd221b9819fda", "extra_info": null, "node_info": {"start": 2082, "end": 2511}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "e16f4b91-966c-4ba7-93c0-2c66dafbaf01", "3": "ee759e11-d017-46a2-a634-00e5823a9768"}, "__type__": "1"}, "ee759e11-d017-46a2-a634-00e5823a9768": {"text": "t a r t\nf r o m\na n\ne x i s t i n g\ni m p l e m e n t a t i o n\nw h i c h\nw a s\nm a d e\nd u r i n g\nt h e\nB r a i n H a c k\n2 0 2 1\na n d\n2 0 2 2 .\nT h e\nt w o\ni m p l e m e n t a t i o n s\no f\nt h e\nH O I s\na r e :\na\nf i r s t\nv e r s i o n\nu s i n g\nt h e\ns t a n d a r d\nN u m P y\nl i b r a r y\n( H a r r i s\ne t\na l . ,\n2 0 2 0 )\nt h a t\nw a s\nc o m p a r e d\nw i t h\na\ns e c o n d\ni m p l e m e n t a t i o n\nu s i n g\na\nm", "doc_id": "ee759e11-d017-46a2-a634-00e5823a9768", "embedding": null, "doc_hash": "6a9e683c5e55b72b2081609c3e2fe804f103c9698bde773f4421cfebad068203", "extra_info": null, "node_info": {"start": 2514, "end": 2941}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "99adb257-9a82-495e-8767-98455ad07f1f", "3": "d1a56696-a130-4c57-9765-49e55bb82d77"}, "__type__": "1"}, "d1a56696-a130-4c57-9765-49e55bb82d77": {"text": "n g\nt h e\nB r a i n H a c k\n2 0 2 1\na n d\n2 0 2 2 .\nT h e\nt w o\ni m p l e m e n t a t i o n s\no f\nt h e\nH O I s\na r e :\na\nf i r s t\nv e r s i o n\nu s i n g\nt h e\ns t a n d a r d\nN u m P y\nl i b r a r y\n( H a r r i s\ne t\na l . ,\n2 0 2 0 )\nt h a t\nw a s\nc o m p a r e d\nw i t h\na\ns e c o n d\ni m p l e m e n t a t i o n\nu s i n g\na\nm o r e\nm o d e r n\nl i b r a r y\nc a l l e d\nJ a x\nf o r\na c c e l e r a t e d\nl i n e a r\na l g", "doc_id": "d1a56696-a130-4c57-9765-49e55bb82d77", "embedding": null, "doc_hash": "92c0550a19efdc3d8ee443ee071a32eb181a05ed28420d6c303cc20181978eed", "extra_info": null, "node_info": {"start": 2940, "end": 3367}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "ee759e11-d017-46a2-a634-00e5823a9768", "3": "42927124-7cd0-46f7-81e2-2e4e6a6093b9"}, "__type__": "1"}, "42927124-7cd0-46f7-81e2-2e4e6a6093b9": {"text": "f\nt h e\nH O I s\na r e :\na\nf i r s t\nv e r s i o n\nu s i n g\nt h e\ns t a n d a r d\nN u m P y\nl i b r a r y\n( H a r r i s\ne t\na l . ,\n2 0 2 0 )\nt h a t\nw a s\nc o m p a r e d\nw i t h\na\ns e c o n d\ni m p l e m e n t a t i o n\nu s i n g\na\nm o r e\nm o d e r n\nl i b r a r y\nc a l l e d\nJ a x\nf o r\na c c e l e r a t e d\nl i n e a r\na l g e b r a\no n\nb o t h\nC P U\na n d\nG P U .\nF i n a l l y ,\nt h e\np r o j e c t\nw i l l\ni n t e g", "doc_id": "42927124-7cd0-46f7-81e2-2e4e6a6093b9", "embedding": null, "doc_hash": "e251bc0fb9c8b2861a09b617d4df408507780075be6d3b578af5617eab4960ee", "extra_info": null, "node_info": {"start": 3369, "end": 3794}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "d1a56696-a130-4c57-9765-49e55bb82d77", "3": "cb01e739-b50f-4a19-ae93-f5e8f3928ff9"}, "__type__": "1"}, "cb01e739-b50f-4a19-ae93-f5e8f3928ff9": {"text": "i b r a r y\n( H a r r i s\ne t\na l . ,\n2 0 2 0 )\nt h a t\nw a s\nc o m p a r e d\nw i t h\na\ns e c o n d\ni m p l e m e n t a t i o n\nu s i n g\na\nm o r e\nm o d e r n\nl i b r a r y\nc a l l e d\nJ a x\nf o r\na c c e l e r a t e d\nl i n e a r\na l g e b r a\no n\nb o t h\nC P U\na n d\nG P U .\nF i n a l l y ,\nt h e\np r o j e c t\nw i l l\ni n t e g r a t e\nt h e\nd e v e l o p m e n t s\ni n t o\nt h e\no p e n - s o u r c e\nt o o l b o x\nc a l l e", "doc_id": "cb01e739-b50f-4a19-ae93-f5e8f3928ff9", "embedding": null, "doc_hash": "35df26efbb8500111240d90ccda4c86d9a3043d947c3a3483f70c0ba19813b0e", "extra_info": null, "node_info": {"start": 3796, "end": 4225}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "42927124-7cd0-46f7-81e2-2e4e6a6093b9", "3": "214e3571-64dd-4b3b-bcf2-bfe87b052dca"}, "__type__": "1"}, "214e3571-64dd-4b3b-bcf2-bfe87b052dca": {"text": "e c o n d\ni m p l e m e n t a t i o n\nu s i n g\na\nm o r e\nm o d e r n\nl i b r a r y\nc a l l e d\nJ a x\nf o r\na c c e l e r a t e d\nl i n e a r\na l g e b r a\no n\nb o t h\nC P U\na n d\nG P U .\nF i n a l l y ,\nt h e\np r o j e c t\nw i l l\ni n t e g r a t e\nt h e\nd e v e l o p m e n t s\ni n t o\nt h e\no p e n - s o u r c e\nt o o l b o x\nc a l l e d\nF r i t e s\nw h i c h\nc u r r e n t l y\no n l y\ns u p p o r t s\np a i r w i s e\ni n t e r a c t i", "doc_id": "214e3571-64dd-4b3b-bcf2-bfe87b052dca", "embedding": null, "doc_hash": "87584bf8acf55f777e28fe3acabda5ca275d49874f06e58a4c42aaf8d5ddf4c3", "extra_info": null, "node_info": {"start": 4225, "end": 4664}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "cb01e739-b50f-4a19-ae93-f5e8f3928ff9", "3": "ddda3c00-63d6-444a-accc-6c5829cb8b25"}, "__type__": "1"}, "ddda3c00-63d6-444a-accc-6c5829cb8b25": {"text": "a x\nf o r\na c c e l e r a t e d\nl i n e a r\na l g e b r a\no n\nb o t h\nC P U\na n d\nG P U .\nF i n a l l y ,\nt h e\np r o j e c t\nw i l l\ni n t e g r a t e\nt h e\nd e v e l o p m e n t s\ni n t o\nt h e\no p e n - s o u r c e\nt o o l b o x\nc a l l e d\nF r i t e s\nw h i c h\nc u r r e n t l y\no n l y\ns u p p o r t s\np a i r w i s e\ni n t e r a c t i o n s", "doc_id": "ddda3c00-63d6-444a-accc-6c5829cb8b25", "embedding": null, "doc_hash": "402c822ab308b28e86dc7d42465f2ddcbf0262add0cf69e66f824110fcea4421", "extra_info": null, "node_info": {"start": 4665, "end": 5012}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "214e3571-64dd-4b3b-bcf2-bfe87b052dca", "3": "94a7b568-ce3c-46f2-9fd7-1bb361b5a96f"}, "__type__": "1"}, "94a7b568-ce3c-46f2-9fd7-1bb361b5a96f": {"text": "o r\na c c e l e r a t e d\nl i n e a r\na l g e b r a\no n\nb o t h\nC P U\na n d\nG P U .\nF i n a l l y ,\nt h e\np r o j e c t\nw i l l\ni n t e g r a t e\nt h e\nd e v e l o p m e n t s\ni n t o\nt h e\no p e n - s o u r c e\nt o o l b o x\nc a l l e d\nF r i t e s\nw h i c h\nc u r r e n t", "doc_id": "94a7b568-ce3c-46f2-9fd7-1bb361b5a96f", "embedding": null, "doc_hash": "b170c5a04833a06f2f20a9d4808cf4caa1e735b7b33b3b08b7ca34070a3bb494", "extra_info": null, "node_info": {"start": 5014, "end": 5287}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "ddda3c00-63d6-444a-accc-6c5829cb8b25", "3": "e3710436-e0b6-49de-94f3-dc99d687ee29"}, "__type__": "1"}, "e3710436-e0b6-49de-94f3-dc99d687ee29": {"text": "e\nt o o l b o x\nc a l l e d\nF r i t e s\nw h i c h\nc u r r e n t l y\no n l y\ns u p p o r t s\np a i r w i s e\ni n t e r a c t i o n s", "doc_id": "e3710436-e0b6-49de-94f3-dc99d687ee29", "embedding": null, "doc_hash": "4cb1a21a1a5a9acd311267d084e59f4a172652d46f90e087e677309c775514e5", "extra_info": null, "node_info": {"start": 5449, "end": 5580}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "94a7b568-ce3c-46f2-9fd7-1bb361b5a96f", "3": "dbeb0e92-bf8f-45cc-a403-f75cc856b76b"}, "__type__": "1"}, "dbeb0e92-bf8f-45cc-a403-f75cc856b76b": {"text": "y\no n l y\ns u p p o r t s\np a i r w i s e\ni n t e r a c t i o n s .\n\nTable\nof\ncontents\nTable\nof\ncontents\n1.\nInformation\nabout\nthe\napplicant\n2.\nProject\nOverview\nand\nDescription\n3.\nStep-by-step\ncontribution\nto\nthe\nproject\n3.1\nDetailed\ndescription\nof\nthe\nstages\nof\nthe\nproject\n3.1.1\nOptimizing\nlow\nlevel\nHOIs\n3.1.2\nMerging\nthe\nnumpy\nand\njax\nimplementations\ninto\na\nsingle", "doc_id": "dbeb0e92-bf8f-45cc-a403-f75cc856b76b", "embedding": null, "doc_hash": "47f80256ca63159d47b9ab483302e201facc3acd7e7b8f0776ed8bfe732410c9", "extra_info": null, "node_info": {"start": 5581, "end": 5948}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "e3710436-e0b6-49de-94f3-dc99d687ee29", "3": "66d62401-d2e4-4a91-8852-48a67e463731"}, "__type__": "1"}, "66d62401-d2e4-4a91-8852-48a67e463731": {"text": " function 3.1.3 Data simulation 3.1.4 HOIs plotting 3.1.5 Frites Integration 3.2 Communication with the mentors 3.3 Project Timeline 4. Candidate Details 4.1 Why am I motivated by this project? 4.2 Why am I a good candidate for this project? 4.3 Past experiences 4.4 When will I be available to run this project? 1. Information about the applicant \u25cf Name : Dishie Vinchhi \u25cf Email : vdishie@gmail.com \u25cf Github : https://github.com/Dishie2498 \u25cf Location : Mumbai, India \u25cf University : Veermata Jijabai Technological Institute \u25cf Degree : B.Tech in Computer Engineering \u25cf Resume : Resume \u25cf Timezone: IST ( UTC +5:30) \u25cf Neurostar ID : @dishie 2. Project Overview and Description Activity patterns of neurons have been studied individually and in pairs so far. However, attempts are for better analysis by studying non-pairwise interactions among neurons. These are known as higher order interactions", "doc_id": "66d62401-d2e4-4a91-8852-48a67e463731", "embedding": null, "doc_hash": "36444d55f6a041ca04b4a9d2a9f25e10a3eeb390e11bf8064f9912664bdffdc6", "extra_info": null, "node_info": {"start": 5986, "end": 6880}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "dbeb0e92-bf8f-45cc-a403-f75cc856b76b", "3": "29d3af5c-2481-4742-8354-89641027b9fd"}, "__type__": "1"}, "29d3af5c-2481-4742-8354-89641027b9fd": {"text": "I motivated by this project? 4.2 Why am I a good candidate for this project? 4.3 Past experiences 4.4 When will I be available to run this project? 1. Information about the applicant \u25cf Name : Dishie Vinchhi \u25cf Email : vdishie@gmail.com \u25cf Github : https://github.com/Dishie2498 \u25cf Location : Mumbai, India \u25cf University : Veermata Jijabai Technological Institute \u25cf Degree : B.Tech in Computer Engineering \u25cf Resume : Resume \u25cf Timezone: IST ( UTC +5:30) \u25cf Neurostar ID : @dishie 2. Project Overview and Description Activity patterns of neurons have been studied individually and in pairs so far. However, attempts are for better analysis by studying non-pairwise interactions among neurons. These are known as higher order interactions (HOIs). Information about organizational structure (o-info) gives us knowledge about the type (redundant or synergistic) and amount of information contained in groups (pairs or multiplets) in the brain. There was an attempt to", "doc_id": "29d3af5c-2481-4742-8354-89641027b9fd", "embedding": null, "doc_hash": "9f187d861bbd08643c38a9c934e7e53d7d444c5654e885630bf4ad542b223d57", "extra_info": null, "node_info": {"start": 6268, "end": 7224}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "66d62401-d2e4-4a91-8852-48a67e463731", "3": "1956f39b-642b-4791-a2cd-a71e69f9118a"}, "__type__": "1"}, "1956f39b-642b-4791-a2cd-a71e69f9118a": {"text": "\u25cf Email : vdishie@gmail.com \u25cf Github : https://github.com/Dishie2498 \u25cf Location : Mumbai, India \u25cf University : Veermata Jijabai Technological Institute \u25cf Degree : B.Tech in Computer Engineering \u25cf Resume : Resume \u25cf Timezone: IST ( UTC +5:30) \u25cf Neurostar ID : @dishie 2. Project Overview and Description Activity patterns of neurons have been studied individually and in pairs so far. However, attempts are for better analysis by studying non-pairwise interactions among neurons. These are known as higher order interactions (HOIs). Information about organizational structure (o-info) gives us knowledge about the type (redundant or synergistic) and amount of information contained in groups (pairs or multiplets) in the brain. There was an attempt to estimate o-info on data using NumPy and Jax libraries earlier. This project aims at: 1. Optimizing the earlier implementations. 2. Merging the two (NumPy and Jax) into a single implementation as per minimum", "doc_id": "1956f39b-642b-4791-a2cd-a71e69f9118a", "embedding": null, "doc_hash": "33c37de8c8ef29dd5b16922521994a4a296e4bbc93e495bb2693848fac2e89c8", "extra_info": null, "node_info": {"start": 7200, "end": 8156}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "29d3af5c-2481-4742-8354-89641027b9fd", "3": "4e497f64-4b7b-45fd-b7a3-5092d0311430"}, "__type__": "1"}, "4e497f64-4b7b-45fd-b7a3-5092d0311430": {"text": "Computer Engineering \u25cf Resume : Resume \u25cf Timezone: IST ( UTC +5:30) \u25cf Neurostar ID : @dishie 2. Project Overview and Description Activity patterns of neurons have been studied individually and in pairs so far. However, attempts are for better analysis by studying non-pairwise interactions among neurons. These are known as higher order interactions (HOIs). Information about organizational structure (o-info) gives us knowledge about the type (redundant or synergistic) and amount of information contained in groups (pairs or multiplets) in the brain. There was an attempt to estimate o-info on data using NumPy and Jax libraries earlier. This project aims at: 1. Optimizing the earlier implementations. 2. Merging the two (NumPy and Jax) into a single implementation as per minimum requirements. As JAX is highly compatible with GPUs, it has inherent compatibility with CPUs, unlike Numpy which is only compatible with CPUs. JAX has an API similar to Numpy and so it can auto-compile code directly on", "doc_id": "4e497f64-4b7b-45fd-b7a3-5092d0311430", "embedding": null, "doc_hash": "960e4464308f041d11b6fceea2be074f14fabd74d5770587e99f6f70d611e72f", "extra_info": null, "node_info": {"start": 8131, "end": 9133}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "1956f39b-642b-4791-a2cd-a71e69f9118a", "3": "371d1e90-3f53-44df-9856-1b02e4f948fe"}, "__type__": "1"}, "371d1e90-3f53-44df-9856-1b02e4f948fe": {"text": "However, attempts are for better analysis by studying non-pairwise interactions among neurons. These are known as higher order interactions (HOIs). Information about organizational structure (o-info) gives us knowledge about the type (redundant or synergistic) and amount of information contained in groups (pairs or multiplets) in the brain. There was an attempt to estimate o-info on data using NumPy and Jax libraries earlier. This project aims at: 1. Optimizing the earlier implementations. 2. Merging the two (NumPy and Jax) into a single implementation as per minimum requirements. As JAX is highly compatible with GPUs, it has inherent compatibility with CPUs, unlike Numpy which is only compatible with CPUs. JAX has an API similar to Numpy and so it can auto-compile code directly on accelerators like GPUs and TPUs, making the process seamless. 3. Plotting the HOIs. 4. Finally, the HOI generating code must be integrated with Frites. Frites is a Python toolbox for assessing", "doc_id": "371d1e90-3f53-44df-9856-1b02e4f948fe", "embedding": null, "doc_hash": "7e2e7b1b8476f024590d4b2a4be53fa4bf4ca0eba71acb39bcfa00bf5844e22d", "extra_info": null, "node_info": {"start": 9127, "end": 10112}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "4e497f64-4b7b-45fd-b7a3-5092d0311430", "3": "c8762864-03ec-4fd8-8cf8-fd5fe9b5c591"}, "__type__": "1"}, "c8762864-03ec-4fd8-8cf8-fd5fe9b5c591": {"text": "(redundant or synergistic) and amount of information contained in groups (pairs or multiplets) in the brain. There was an attempt to estimate o-info on data using NumPy and Jax libraries earlier. This project aims at: 1. Optimizing the earlier implementations. 2. Merging the two (NumPy and Jax) into a single implementation as per minimum requirements. As JAX is highly compatible with GPUs, it has inherent compatibility with CPUs, unlike Numpy which is only compatible with CPUs. JAX has an API similar to Numpy and so it can auto-compile code directly on accelerators like GPUs and TPUs, making the process seamless. 3. Plotting the HOIs. 4. Finally, the HOI generating code must be integrated with Frites. Frites is a Python toolbox for assessing information-theoretic measures on human and animal neurophysiological data. 3. Step-by-step contribution to the project 3.1 Detailed description of the stages of the project 3 . 1 . 1\nO p t i m i z i n", "doc_id": "c8762864-03ec-4fd8-8cf8-fd5fe9b5c591", "embedding": null, "doc_hash": "abb557a1748621cc73cfb11c51545999d5af5dba8e5c8a5ad5d04c594587c12d", "extra_info": null, "node_info": {"start": 10154, "end": 11107}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "371d1e90-3f53-44df-9856-1b02e4f948fe", "3": "07a4a574-4fea-4c85-83f0-2dbb6e9ff97a"}, "__type__": "1"}, "07a4a574-4fea-4c85-83f0-2dbb6e9ff97a": {"text": "at: 1. Optimizing the earlier implementations. 2. Merging the two (NumPy and Jax) into a single implementation as per minimum requirements. As JAX is highly compatible with GPUs, it has inherent compatibility with CPUs, unlike Numpy which is only compatible with CPUs. JAX has an API similar to Numpy and so it can auto-compile code directly on accelerators like GPUs and TPUs, making the process seamless. 3. Plotting the HOIs. 4. Finally, the HOI generating code must be integrated with Frites. Frites is a Python toolbox for assessing information-theoretic measures on human and animal neurophysiological data. 3. Step-by-step contribution to the project 3.1 Detailed description of the stages of the project 3 . 1 . 1\nO p t i m i z i n g\nl o w\nl e v e l\nH O I s\n\u25cf\nCache\nr epeated\ncomputations\n:\nThe\ncode\nper forms\nse v er al\nr", "doc_id": "07a4a574-4fea-4c85-83f0-2dbb6e9ff97a", "embedding": null, "doc_hash": "4f3483fe3523915ba326478df0d49ca5a8be111092c1b498173329b84bccc5d7", "extra_info": null, "node_info": {"start": 11122, "end": 11952}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "c8762864-03ec-4fd8-8cf8-fd5fe9b5c591", "3": "f627a822-8162-4d90-b3d1-dbc42861a43f"}, "__type__": "1"}, "f627a822-8162-4d90-b3d1-dbc42861a43f": {"text": "GPUs, it has inherent compatibility with CPUs, unlike Numpy which is only compatible with CPUs. JAX has an API similar to Numpy and so it can auto-compile code directly on accelerators like GPUs and TPUs, making the process seamless. 3. Plotting the HOIs. 4. Finally, the HOI generating code must be integrated with Frites. Frites is a Python toolbox for assessing information-theoretic measures on human and animal neurophysiological data. 3. Step-by-step contribution to the project 3.1 Detailed description of the stages of the project 3 . 1 . 1\nO p t i m i z i n g\nl o w\nl e v e l\nH O I s\n\u25cf\nCache\nr epeated\ncomputations\n:\nThe\ncode\nper forms\nse v er al\nr epeated\ncomputations,\nsuch\nas\nthe\nCholesky\ndecomposition\nand\nlogarithmic\nfunctions.\nCaching\nthese\ncomputations\ncan\nhelp\nr educe\nthe\no v er", "doc_id": "f627a822-8162-4d90-b3d1-dbc42861a43f", "embedding": null, "doc_hash": "246ddd3114d640a52e941693e36482421c8884df90e9f6a2883da4a33287e238", "extra_info": null, "node_info": {"start": 12023, "end": 12819}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "07a4a574-4fea-4c85-83f0-2dbb6e9ff97a", "3": "e704e61b-747f-4863-95dc-17332d8d40c6"}, "__type__": "1"}, "e704e61b-747f-4863-95dc-17332d8d40c6": {"text": "making the process seamless. 3. Plotting the HOIs. 4. Finally, the HOI generating code must be integrated with Frites. Frites is a Python toolbox for assessing information-theoretic measures on human and animal neurophysiological data. 3. Step-by-step contribution to the project 3.1 Detailed description of the stages of the project 3 . 1 . 1\nO p t i m i z i n g\nl o w\nl e v e l\nH O I s\n\u25cf\nCache\nr epeated\ncomputations\n:\nThe\ncode\nper forms\nse v er al\nr epeated\ncomputations,\nsuch\nas\nthe\nCholesky\ndecomposition\nand\nlogarithmic\nfunctions.\nCaching\nthese\ncomputations\ncan\nhelp\nr educe\nthe\no v er all\ncomputation\ntime.\nW e\ncan\nuse\nthe\nlru_cache\ndecor at or\nfr om\nthe\n'funct ools'\nmodule\nin\np ython\nt", "doc_id": "e704e61b-747f-4863-95dc-17332d8d40c6", "embedding": null, "doc_hash": "5f306e83415705bc85be829fcf85073cb2bccfd9f3c59206a5a29c0cc16cac0e", "extra_info": null, "node_info": {"start": 12855, "end": 13549}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "f627a822-8162-4d90-b3d1-dbc42861a43f", "3": "dc45cb06-0d54-4f47-a5f3-0347a42f7e01"}, "__type__": "1"}, "dc45cb06-0d54-4f47-a5f3-0347a42f7e01": {"text": "measures on human and animal neurophysiological data. 3. Step-by-step contribution to the project 3.1 Detailed description of the stages of the project 3 . 1 . 1\nO p t i m i z i n g\nl o w\nl e v e l\nH O I s\n\u25cf\nCache\nr epeated\ncomputations\n:\nThe\ncode\nper forms\nse v er al\nr epeated\ncomputations,\nsuch\nas\nthe\nCholesky\ndecomposition\nand\nlogarithmic\nfunctions.\nCaching\nthese\ncomputations\ncan\nhelp\nr educe\nthe\no v er all\ncomputation\ntime.\nW e\ncan\nuse\nthe\nlru_cache\ndecor at or\nfr om\nthe\n'funct ools'\nmodule\nin\np ython\nt o\ncache\nthe\noutput\nof\na\nfunction\nbased\non\nits\ninputs.\nConsider\na\nsimple,\nr ecursiv e\nfunction\nt", "doc_id": "dc45cb06-0d54-4f47-a5f3-0347a42f7e01", "embedding": null, "doc_hash": "3aebfb07dbeaecfa93b0e600d4a59a772dbdb1f489d65e070022f4e5a2789f23", "extra_info": null, "node_info": {"start": 13609, "end": 14217}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "e704e61b-747f-4863-95dc-17332d8d40c6", "3": "8dd41955-2532-48dd-832a-dff5d755e0ce"}, "__type__": "1"}, "8dd41955-2532-48dd-832a-dff5d755e0ce": {"text": ". 1\nO p t i m i z i n g\nl o w\nl e v e l\nH O I s\n\u25cf\nCache\nr epeated\ncomputations\n:\nThe\ncode\nper forms\nse v er al\nr epeated\ncomputations,\nsuch\nas\nthe\nCholesky\ndecomposition\nand\nlogarithmic\nfunctions.\nCaching\nthese\ncomputations\ncan\nhelp\nr educe\nthe\no v er all\ncomputation\ntime.\nW e\ncan\nuse\nthe\nlru_cache\ndecor at or\nfr om\nthe\n'funct ools'\nmodule\nin\np ython\nt o\ncache\nthe\noutput\nof\na\nfunction\nbased\non\nits\ninputs.\nConsider\na\nsimple,\nr ecursiv e\nfunction\nt o\ncalculate\nthe\noutput\nfor\ninput\n`n`.\nThe\noutput\nwill\nbe\ncached\nwhen\ncomputed.\nTher e\nwill\nbe\nno\nneed\nt", "doc_id": "8dd41955-2532-48dd-832a-dff5d755e0ce", "embedding": null, "doc_hash": "83dece7913cf929b57c38cdab395d630e69b94de5c1394c8700388774df4ad08", "extra_info": null, "node_info": {"start": 14258, "end": 14812}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "dc45cb06-0d54-4f47-a5f3-0347a42f7e01", "3": "9741174c-6633-4d61-99db-80ed23bf6dc5"}, "__type__": "1"}, "9741174c-6633-4d61-99db-80ed23bf6dc5": {"text": "forms\nse v er al\nr epeated\ncomputations,\nsuch\nas\nthe\nCholesky\ndecomposition\nand\nlogarithmic\nfunctions.\nCaching\nthese\ncomputations\ncan\nhelp\nr educe\nthe\no v er all\ncomputation\ntime.\nW e\ncan\nuse\nthe\nlru_cache\ndecor at or\nfr om\nthe\n'funct ools'\nmodule\nin\np ython\nt o\ncache\nthe\noutput\nof\na\nfunction\nbased\non\nits\ninputs.\nConsider\na\nsimple,\nr ecursiv e\nfunction\nt o\ncalculate\nthe\noutput\nfor\ninput\n`n`.\nThe\noutput\nwill\nbe\ncached\nwhen\ncomputed.\nTher e\nwill\nbe\nno\nneed\nt o\ncall\nthe\nfunction\nagain\nfor\ninput\n`n`\nhencefor th,\nthe\ncached\nv alue is used instead. Here is a comparison of repeated computations using the cache and without it. import timeit", "doc_id": "9741174c-6633-4d61-99db-80ed23bf6dc5", "embedding": null, "doc_hash": "910686dda07f0b3ae826716f1726805792bf146a1ba693e5a46486bef7adb1e1", "extra_info": null, "node_info": {"start": 14784, "end": 15424}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "8dd41955-2532-48dd-832a-dff5d755e0ce", "3": "e9f18049-f1ef-4b64-93b3-50575e34cafb"}, "__type__": "1"}, "e9f18049-f1ef-4b64-93b3-50575e34cafb": {"text": "educe\nthe\no v er all\ncomputation\ntime.\nW e\ncan\nuse\nthe\nlru_cache\ndecor at or\nfr om\nthe\n'funct ools'\nmodule\nin\np ython\nt o\ncache\nthe\noutput\nof\na\nfunction\nbased\non\nits\ninputs.\nConsider\na\nsimple,\nr ecursiv e\nfunction\nt o\ncalculate\nthe\noutput\nfor\ninput\n`n`.\nThe\noutput\nwill\nbe\ncached\nwhen\ncomputed.\nTher e\nwill\nbe\nno\nneed\nt o\ncall\nthe\nfunction\nagain\nfor\ninput\n`n`\nhencefor th,\nthe\ncached\nv alue is used instead. Here is a comparison of repeated computations using the cache and without it. import timeit import matplotlib . pyplot as plt times_ent_g = [] times_ent_g_cached = [] # Generate random data x = np.random.randn( 10 , 10 ) # Calling the ent_g and", "doc_id": "e9f18049-f1ef-4b64-93b3-50575e34cafb", "embedding": null, "doc_hash": "837b26e986f8d9d777f3889dc18e7acb5c0d55da92b38cf9cedc56a0fd092939", "extra_info": null, "node_info": {"start": 15402, "end": 16054}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "9741174c-6633-4d61-99db-80ed23bf6dc5", "3": "fde0fbd4-1866-433e-9d7a-a7aa904b038b"}, "__type__": "1"}, "fde0fbd4-1866-433e-9d7a-a7aa904b038b": {"text": "ython\nt o\ncache\nthe\noutput\nof\na\nfunction\nbased\non\nits\ninputs.\nConsider\na\nsimple,\nr ecursiv e\nfunction\nt o\ncalculate\nthe\noutput\nfor\ninput\n`n`.\nThe\noutput\nwill\nbe\ncached\nwhen\ncomputed.\nTher e\nwill\nbe\nno\nneed\nt o\ncall\nthe\nfunction\nagain\nfor\ninput\n`n`\nhencefor th,\nthe\ncached\nv alue is used instead. Here is a comparison of repeated computations using the cache and without it. import timeit import matplotlib . pyplot as plt times_ent_g = [] times_ent_g_cached = [] # Generate random data x = np.random.randn( 10 , 10 ) # Calling the ent_g and ent_g_cached functions for the same input to compare difference in computation times repetition = 3 for i in range ( repetition ): # Time ent_g start_time = timeit . default_timer () ent_g(", "doc_id": "fde0fbd4-1866-433e-9d7a-a7aa904b038b", "embedding": null, "doc_hash": "89247c4a4c1352268b4958df91e789023dd347bc1f8b06629f201333751c7c11", "extra_info": null, "node_info": {"start": 16033, "end": 16763}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "e9f18049-f1ef-4b64-93b3-50575e34cafb", "3": "e3e20d8d-48e7-4deb-b194-fe2d8e01a463"}, "__type__": "1"}, "e3e20d8d-48e7-4deb-b194-fe2d8e01a463": {"text": "e\nwill\nbe\nno\nneed\nt o\ncall\nthe\nfunction\nagain\nfor\ninput\n`n`\nhencefor th,\nthe\ncached\nv alue is used instead. Here is a comparison of repeated computations using the cache and without it. import timeit import matplotlib . pyplot as plt times_ent_g = [] times_ent_g_cached = [] # Generate random data x = np.random.randn( 10 , 10 ) # Calling the ent_g and ent_g_cached functions for the same input to compare difference in computation times repetition = 3 for i in range ( repetition ): # Time ent_g start_time = timeit . default_timer () ent_g( x ) end_time = timeit . default_timer () times_ent_g . append ( end_time - start_time ) # print(end_time-start_time) # Time ent_g_cached start_time = timeit . default_timer () ent_g_cached( x ) end_time = timeit . default_timer ()", "doc_id": "e3e20d8d-48e7-4deb-b194-fe2d8e01a463", "embedding": null, "doc_hash": "33ca6b9066dfb90a848601d925a6734e18c6358d6cd0f794cd072ce1a346f7ec", "extra_info": null, "node_info": {"start": 16789, "end": 17562}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "fde0fbd4-1866-433e-9d7a-a7aa904b038b", "3": "5b8b2298-809f-4c6f-97d8-e6ad1e588be2"}, "__type__": "1"}, "5b8b2298-809f-4c6f-97d8-e6ad1e588be2": {"text": "computations using the cache and without it. import timeit import matplotlib . pyplot as plt times_ent_g = [] times_ent_g_cached = [] # Generate random data x = np.random.randn( 10 , 10 ) # Calling the ent_g and ent_g_cached functions for the same input to compare difference in computation times repetition = 3 for i in range ( repetition ): # Time ent_g start_time = timeit . default_timer () ent_g( x ) end_time = timeit . default_timer () times_ent_g . append ( end_time - start_time ) # print(end_time-start_time) # Time ent_g_cached start_time = timeit . default_timer () ent_g_cached( x ) end_time = timeit . default_timer () times_ent_g_cached . append ( end_time - start_time ) # print(end_time-start_time) print ( \"times_ent_g:\" , times_ent_g ) print (", "doc_id": "5b8b2298-809f-4c6f-97d8-e6ad1e588be2", "embedding": null, "doc_hash": "501e0f69381c008e20263f218bc51ca279cd0a4495b7eeb110978752f92d2f47", "extra_info": null, "node_info": {"start": 17496, "end": 18258}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "e3e20d8d-48e7-4deb-b194-fe2d8e01a463", "3": "14a17423-13f0-4c7b-b557-141645ae59cf"}, "__type__": "1"}, "14a17423-13f0-4c7b-b557-141645ae59cf": {"text": "10 , 10 ) # Calling the ent_g and ent_g_cached functions for the same input to compare difference in computation times repetition = 3 for i in range ( repetition ): # Time ent_g start_time = timeit . default_timer () ent_g( x ) end_time = timeit . default_timer () times_ent_g . append ( end_time - start_time ) # print(end_time-start_time) # Time ent_g_cached start_time = timeit . default_timer () ent_g_cached( x ) end_time = timeit . default_timer () times_ent_g_cached . append ( end_time - start_time ) # print(end_time-start_time) print ( \"times_ent_g:\" , times_ent_g ) print ( \"times_ent_g_cached:\" , times_ent_g_cached ) # set width of the bars barWidth = 0.25 # Set position of bar on X axis r1 = np.arange( len ( times_ent_g )) r2 = [ x +", "doc_id": "14a17423-13f0-4c7b-b557-141645ae59cf", "embedding": null, "doc_hash": "833983f1a6436ee668e84cf9fdeb9c9757f9a5bab2421af103fd9e9681942d58", "extra_info": null, "node_info": {"start": 18297, "end": 19046}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "5b8b2298-809f-4c6f-97d8-e6ad1e588be2", "3": "09713ad0-2cca-4e8d-a2d2-974cb8e356fe"}, "__type__": "1"}, "09713ad0-2cca-4e8d-a2d2-974cb8e356fe": {"text": "timeit . default_timer () ent_g( x ) end_time = timeit . default_timer () times_ent_g . append ( end_time - start_time ) # print(end_time-start_time) # Time ent_g_cached start_time = timeit . default_timer () ent_g_cached( x ) end_time = timeit . default_timer () times_ent_g_cached . append ( end_time - start_time ) # print(end_time-start_time) print ( \"times_ent_g:\" , times_ent_g ) print ( \"times_ent_g_cached:\" , times_ent_g_cached ) # set width of the bars barWidth = 0.25 # Set position of bar on X axis r1 = np.arange( len ( times_ent_g )) r2 = [ x + barWidth for x in r1 ] # Make the plot plt . bar ( r1 , times_ent_g , color = 'blue' , width = barWidth , edgecolor = 'grey' , label = 'ent_g' ) plt . bar", "doc_id": "09713ad0-2cca-4e8d-a2d2-974cb8e356fe", "embedding": null, "doc_hash": "48062555dd8f2557ea9d659021ae9d3275cf13dd9b75afc6c3151882f7a281cb", "extra_info": null, "node_info": {"start": 19070, "end": 19783}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "14a17423-13f0-4c7b-b557-141645ae59cf", "3": "e479e673-2a0f-456e-aeb6-dd1cf188203c"}, "__type__": "1"}, "e479e673-2a0f-456e-aeb6-dd1cf188203c": {"text": "start_time = timeit . default_timer () ent_g_cached( x ) end_time = timeit . default_timer () times_ent_g_cached . append ( end_time - start_time ) # print(end_time-start_time) print ( \"times_ent_g:\" , times_ent_g ) print ( \"times_ent_g_cached:\" , times_ent_g_cached ) # set width of the bars barWidth = 0.25 # Set position of bar on X axis r1 = np.arange( len ( times_ent_g )) r2 = [ x + barWidth for x in r1 ] # Make the plot plt . bar ( r1 , times_ent_g , color = 'blue' , width = barWidth , edgecolor = 'grey' , label = 'ent_g' ) plt . bar ( r2 , times_ent_g_cached , color = 'orange' , width = barWidth , edgecolor = 'grey' , label = 'ent_g_cached' ) # Add xticks on the middle of the group bars plt . xlabel", "doc_id": "e479e673-2a0f-456e-aeb6-dd1cf188203c", "embedding": null, "doc_hash": "b33c959a4a1d628a083ca5ac942c8000a48a43e9635f8e4136373e7873d5ae3f", "extra_info": null, "node_info": {"start": 19810, "end": 20523}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "09713ad0-2cca-4e8d-a2d2-974cb8e356fe", "3": "81efe060-3e53-4e1e-bcdb-6b9aff005be7"}, "__type__": "1"}, "81efe060-3e53-4e1e-bcdb-6b9aff005be7": {"text": "print ( \"times_ent_g:\" , times_ent_g ) print ( \"times_ent_g_cached:\" , times_ent_g_cached ) # set width of the bars barWidth = 0.25 # Set position of bar on X axis r1 = np.arange( len ( times_ent_g )) r2 = [ x + barWidth for x in r1 ] # Make the plot plt . bar ( r1 , times_ent_g , color = 'blue' , width = barWidth , edgecolor = 'grey' , label = 'ent_g' ) plt . bar ( r2 , times_ent_g_cached , color = 'orange' , width = barWidth , edgecolor = 'grey' , label = 'ent_g_cached' ) # Add xticks on the middle of the group bars plt . xlabel ( 'Computation number' ) plt . ylabel ( 'Time (s)' ) plt . xticks ([ r + barWidth / 2 for r in range ( len ( times_ent_g ))], [ '1st computation' , '2nd", "doc_id": "81efe060-3e53-4e1e-bcdb-6b9aff005be7", "embedding": null, "doc_hash": "2195d8b4cfd8ae75c3cadea6be1b4c816016aeee744750495bafc877ecef05b8", "extra_info": null, "node_info": {"start": 20540, "end": 21229}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "e479e673-2a0f-456e-aeb6-dd1cf188203c", "3": "5738e669-dbd5-4035-aca1-baeaba4bcec9"}, "__type__": "1"}, "5738e669-dbd5-4035-aca1-baeaba4bcec9": {"text": "of bar on X axis r1 = np.arange( len ( times_ent_g )) r2 = [ x + barWidth for x in r1 ] # Make the plot plt . bar ( r1 , times_ent_g , color = 'blue' , width = barWidth , edgecolor = 'grey' , label = 'ent_g' ) plt . bar ( r2 , times_ent_g_cached , color = 'orange' , width = barWidth , edgecolor = 'grey' , label = 'ent_g_cached' ) # Add xticks on the middle of the group bars plt . xlabel ( 'Computation number' ) plt . ylabel ( 'Time (s)' ) plt . xticks ([ r + barWidth / 2 for r in range ( len ( times_ent_g ))], [ '1st computation' , '2nd computation' , '3rd computation' ]) # Create legend & Show graphic plt . legend () plt . show () \u25cf W e can compute faster the entropies of more than one tensor using vmap() The", "doc_id": "5738e669-dbd5-4035-aca1-baeaba4bcec9", "embedding": null, "doc_hash": "0029e8d47fae6c86a0640c10f668dc95720d8a6a1ab9091906dc7ca99f6731a5", "extra_info": null, "node_info": {"start": 21234, "end": 21953}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "81efe060-3e53-4e1e-bcdb-6b9aff005be7", "3": "f2da7778-7ac7-48e6-8124-0c298d652330"}, "__type__": "1"}, "f2da7778-7ac7-48e6-8124-0c298d652330": {"text": "'blue' , width = barWidth , edgecolor = 'grey' , label = 'ent_g' ) plt . bar ( r2 , times_ent_g_cached , color = 'orange' , width = barWidth , edgecolor = 'grey' , label = 'ent_g_cached' ) # Add xticks on the middle of the group bars plt . xlabel ( 'Computation number' ) plt . ylabel ( 'Time (s)' ) plt . xticks ([ r + barWidth / 2 for r in range ( len ( times_ent_g ))], [ '1st computation' , '2nd computation' , '3rd computation' ]) # Create legend & Show graphic plt . legend () plt . show () \u25cf W e can compute faster the entropies of more than one tensor using vmap() The following code illustrates the computation time saved. @partial (jax.jit, static_argnums = 1 ) def ent_g ( x : jnp.array, biascorrect = True ) -> jnp.array:", "doc_id": "f2da7778-7ac7-48e6-8124-0c298d652330", "embedding": null, "doc_hash": "83b5adb3250b1da85975045912a87536576c22cd42fc3ceec48987630e62ebef", "extra_info": null, "node_info": {"start": 21918, "end": 22651}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "5738e669-dbd5-4035-aca1-baeaba4bcec9", "3": "6d5169ed-f5e9-43b7-8c75-b56259949947"}, "__type__": "1"}, "6d5169ed-f5e9-43b7-8c75-b56259949947": {"text": "= 'grey' , label = 'ent_g_cached' ) # Add xticks on the middle of the group bars plt . xlabel ( 'Computation number' ) plt . ylabel ( 'Time (s)' ) plt . xticks ([ r + barWidth / 2 for r in range ( len ( times_ent_g ))], [ '1st computation' , '2nd computation' , '3rd computation' ]) # Create legend & Show graphic plt . legend () plt . show () \u25cf W e can compute faster the entropies of more than one tensor using vmap() The following code illustrates the computation time saved. @partial (jax.jit, static_argnums = 1 ) def ent_g ( x : jnp.array, biascorrect = True ) -> jnp.array: \"\"\"Entropy of a tensor of shape (..., n_vars, n_trials)\"\"\" nvarx , ntrl = x .shape[- 2 ], x .shape[- 1 ] # covariance c =", "doc_id": "6d5169ed-f5e9-43b7-8c75-b56259949947", "embedding": null, "doc_hash": "ab1435f23b65b248e85a1045a59fc19acb2318c34835ca1059009dc534071d83", "extra_info": null, "node_info": {"start": 22642, "end": 23344}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "f2da7778-7ac7-48e6-8124-0c298d652330", "3": "c694ab14-5d44-471d-b5ef-97a83fcd5d30"}, "__type__": "1"}, "c694ab14-5d44-471d-b5ef-97a83fcd5d30": {"text": ") plt . xticks ([ r + barWidth / 2 for r in range ( len ( times_ent_g ))], [ '1st computation' , '2nd computation' , '3rd computation' ]) # Create legend & Show graphic plt . legend () plt . show () \u25cf W e can compute faster the entropies of more than one tensor using vmap() The following code illustrates the computation time saved. @partial (jax.jit, static_argnums = 1 ) def ent_g ( x : jnp.array, biascorrect = True ) -> jnp.array: \"\"\"Entropy of a tensor of shape (..., n_vars, n_trials)\"\"\" nvarx , ntrl = x .shape[- 2 ], x .shape[- 1 ] # covariance c = jnp.einsum( '...ij, ...kj->...ik' , x , x ) c /= float ( ntrl - 1 .) chc = jnp.linalg.cholesky( c )  # entropy in nats", "doc_id": "c694ab14-5d44-471d-b5ef-97a83fcd5d30", "embedding": null, "doc_hash": "cf04268f11cc68b7147af71a3b5abb5b3eb2b0e868157f0a6438072890ffa081", "extra_info": null, "node_info": {"start": 23363, "end": 24039}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "6d5169ed-f5e9-43b7-8c75-b56259949947", "3": "65fd0866-608c-4e90-96a5-46f4c9120cc2"}, "__type__": "1"}, "65fd0866-608c-4e90-96a5-46f4c9120cc2": {"text": "& Show graphic plt . legend () plt . show () \u25cf W e can compute faster the entropies of more than one tensor using vmap() The following code illustrates the computation time saved. @partial (jax.jit, static_argnums = 1 ) def ent_g ( x : jnp.array, biascorrect = True ) -> jnp.array: \"\"\"Entropy of a tensor of shape (..., n_vars, n_trials)\"\"\" nvarx , ntrl = x .shape[- 2 ], x .shape[- 1 ] # covariance c = jnp.einsum( '...ij, ...kj->...ik' , x , x ) c /= float ( ntrl - 1 .) chc = jnp.linalg.cholesky( c )  # entropy in nats hx = jnp.log(jnp.einsum( '...ii->...i' , chc )).sum(- 1 ) + 0.5 * nvarx * ( jnp.log( 2 * jnp.pi) + 1.0 )", "doc_id": "65fd0866-608c-4e90-96a5-46f4c9120cc2", "embedding": null, "doc_hash": "a380a67ef353d659bf1f567b0798a44bf82c9cd334ffa25cdb14bda0e0d83c62", "extra_info": null, "node_info": {"start": 24069, "end": 24696}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "c694ab14-5d44-471d-b5ef-97a83fcd5d30", "3": "b32875b6-44da-419b-b329-acde6729f7fb"}, "__type__": "1"}, "b32875b6-44da-419b-b329-acde6729f7fb": {"text": "static_argnums = 1 ) def ent_g ( x : jnp.array, biascorrect = True ) -> jnp.array: \"\"\"Entropy of a tensor of shape (..., n_vars, n_trials)\"\"\" nvarx , ntrl = x .shape[- 2 ], x .shape[- 1 ] # covariance c = jnp.einsum( '...ij, ...kj->...ik' , x , x ) c /= float ( ntrl - 1 .) chc = jnp.linalg.cholesky( c )  # entropy in nats hx = jnp.log(jnp.einsum( '...ii->...i' , chc )).sum(- 1 ) + 0.5 * nvarx * ( jnp.log( 2 * jnp.pi) + 1.0 ) ln2 = jnp.log( 2 ) if biascorrect : psiterms = jsp.digamma(( ntrl - jnp.arange( 1 , nvarx + 1 ).astype( float )) / 2 .) / 2 . dterm = ( ln2", "doc_id": "b32875b6-44da-419b-b329-acde6729f7fb", "embedding": null, "doc_hash": "c6becb529fbe1e8a28fbac2a6587e0fb1bcf00d5c9f24aaf97e12672f8d7bce0", "extra_info": null, "node_info": {"start": 24777, "end": 25345}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "65fd0866-608c-4e90-96a5-46f4c9120cc2", "3": "4c94d296-be9d-4882-897b-f1c2e160594f"}, "__type__": "1"}, "4c94d296-be9d-4882-897b-f1c2e160594f": {"text": ", ntrl = x .shape[- 2 ], x .shape[- 1 ] # covariance c = jnp.einsum( '...ij, ...kj->...ik' , x , x ) c /= float ( ntrl - 1 .) chc = jnp.linalg.cholesky( c )  # entropy in nats hx = jnp.log(jnp.einsum( '...ii->...i' , chc )).sum(- 1 ) + 0.5 * nvarx * ( jnp.log( 2 * jnp.pi) + 1.0 ) ln2 = jnp.log( 2 ) if biascorrect : psiterms = jsp.digamma(( ntrl - jnp.arange( 1 , nvarx + 1 ).astype( float )) / 2 .) / 2 . dterm = ( ln2 - jnp.log( ntrl - 1 .)) / 2 . hx = hx - nvarx * dterm - psiterms .sum() return hx batch_size = 5000 n_vars = 100 n_trials = 10 x_batch =", "doc_id": "4c94d296-be9d-4882-897b-f1c2e160594f", "embedding": null, "doc_hash": "62b229301dfd8ef4415b126a8ec38627fd2a2151fd314f42ccf1393cc8e931b0", "extra_info": null, "node_info": {"start": 25360, "end": 25917}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "b32875b6-44da-419b-b329-acde6729f7fb", "3": "262cf7a1-114f-41b9-8605-1de677babe5b"}, "__type__": "1"}, "262cf7a1-114f-41b9-8605-1de677babe5b": {"text": ".) chc = jnp.linalg.cholesky( c )  # entropy in nats hx = jnp.log(jnp.einsum( '...ii->...i' , chc )).sum(- 1 ) + 0.5 * nvarx * ( jnp.log( 2 * jnp.pi) + 1.0 ) ln2 = jnp.log( 2 ) if biascorrect : psiterms = jsp.digamma(( ntrl - jnp.arange( 1 , nvarx + 1 ).astype( float )) / 2 .) / 2 . dterm = ( ln2 - jnp.log( ntrl - 1 .)) / 2 . hx = hx - nvarx * dterm - psiterms .sum() return hx batch_size = 5000 n_vars = 100 n_trials = 10 x_batch = jnp.random.normal( size =( batch_size , n_vars , n_trials )) # batch_size = 1000 # n_vars = 10 # n_trials = 100 # x_batch =", "doc_id": "262cf7a1-114f-41b9-8605-1de677babe5b", "embedding": null, "doc_hash": "56ec6deb37575534c20697fb2174d8a574c20dfc23344b1cf7e4aacfb4d6b461", "extra_info": null, "node_info": {"start": 25906, "end": 26464}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "4c94d296-be9d-4882-897b-f1c2e160594f", "3": "809a1279-2d99-4487-8e4e-a0b66ac0aa75"}, "__type__": "1"}, "809a1279-2d99-4487-8e4e-a0b66ac0aa75": {"text": ")).sum(- 1 ) + 0.5 * nvarx * ( jnp.log( 2 * jnp.pi) + 1.0 ) ln2 = jnp.log( 2 ) if biascorrect : psiterms = jsp.digamma(( ntrl - jnp.arange( 1 , nvarx + 1 ).astype( float )) / 2 .) / 2 . dterm = ( ln2 - jnp.log( ntrl - 1 .)) / 2 . hx = hx - nvarx * dterm - psiterms .sum() return hx batch_size = 5000 n_vars = 100 n_trials = 10 x_batch = jnp.random.normal( size =( batch_size , n_vars , n_trials )) # batch_size = 1000 # n_vars = 10 # n_trials = 100 # x_batch = np.random.normal(size=(batch_size, n_vars, n_trials)) times =[] # Compute the entropy of the batch of tensors start_time = timeit . default_timer () ent_g_batch =", "doc_id": "809a1279-2d99-4487-8e4e-a0b66ac0aa75", "embedding": null, "doc_hash": "a46e37a29698f1be641a08265997491d6e1dc3232851c4fb9469b31a89bb83e8", "extra_info": null, "node_info": {"start": 26446, "end": 27069}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "262cf7a1-114f-41b9-8605-1de677babe5b", "3": "b07b0a20-8c4b-4b10-944f-6d278c3a73d3"}, "__type__": "1"}, "b07b0a20-8c4b-4b10-944f-6d278c3a73d3": {"text": "ntrl - jnp.arange( 1 , nvarx + 1 ).astype( float )) / 2 .) / 2 . dterm = ( ln2 - jnp.log( ntrl - 1 .)) / 2 . hx = hx - nvarx * dterm - psiterms .sum() return hx batch_size = 5000 n_vars = 100 n_trials = 10 x_batch = jnp.random.normal( size =( batch_size , n_vars , n_trials )) # batch_size = 1000 # n_vars = 10 # n_trials = 100 # x_batch = np.random.normal(size=(batch_size, n_vars, n_trials)) times =[] # Compute the entropy of the batch of tensors start_time = timeit . default_timer () ent_g_batch = jax.vmap( ent_g )( x_batch ) end_time = timeit . default_timer () print ( end_time - start_time ) times . append ( end_time - start_time ) start_time = timeit . default_timer ()", "doc_id": "b07b0a20-8c4b-4b10-944f-6d278c3a73d3", "embedding": null, "doc_hash": "45a258cbbd564274b6d16dc12880010db250c6bda174ac8ab2fda984501db435", "extra_info": null, "node_info": {"start": 27023, "end": 27703}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "809a1279-2d99-4487-8e4e-a0b66ac0aa75", "3": "fc793b9c-85bb-4e80-9577-2a9ed02b9487"}, "__type__": "1"}, "fc793b9c-85bb-4e80-9577-2a9ed02b9487": {"text": "- nvarx * dterm - psiterms .sum() return hx batch_size = 5000 n_vars = 100 n_trials = 10 x_batch = jnp.random.normal( size =( batch_size , n_vars , n_trials )) # batch_size = 1000 # n_vars = 10 # n_trials = 100 # x_batch = np.random.normal(size=(batch_size, n_vars, n_trials)) times =[] # Compute the entropy of the batch of tensors start_time = timeit . default_timer () ent_g_batch = jax.vmap( ent_g )( x_batch ) end_time = timeit . default_timer () print ( end_time - start_time ) times . append ( end_time - start_time ) start_time = timeit . default_timer () ent_g_batch = ent_g ( x_batch ) end_time = timeit . default_timer () print ( end_time - start_time ) times . append ( end_time - start_time ) func =[ \"using vmap\" ,", "doc_id": "fc793b9c-85bb-4e80-9577-2a9ed02b9487", "embedding": null, "doc_hash": "72614a9ac41ef519f853ad61d61237f9f75c875f078ce111b7477fad85299741", "extra_info": null, "node_info": {"start": 27641, "end": 28369}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "b07b0a20-8c4b-4b10-944f-6d278c3a73d3", "3": "8ec91488-f51b-47e5-844e-66ee93580447"}, "__type__": "1"}, "8ec91488-f51b-47e5-844e-66ee93580447": {"text": ", n_trials )) # batch_size = 1000 # n_vars = 10 # n_trials = 100 # x_batch = np.random.normal(size=(batch_size, n_vars, n_trials)) times =[] # Compute the entropy of the batch of tensors start_time = timeit . default_timer () ent_g_batch = jax.vmap( ent_g )( x_batch ) end_time = timeit . default_timer () print ( end_time - start_time ) times . append ( end_time - start_time ) start_time = timeit . default_timer () ent_g_batch = ent_g ( x_batch ) end_time = timeit . default_timer () print ( end_time - start_time ) times . append ( end_time - start_time ) func =[ \"using vmap\" , 'without vmap' ] plt . bar ( func , times , color = 'maroon' , width = 0.4 ) plt . xlabel ( \"Type of ent_g\" ) plt . ylabel ( \"Computation time\" )", "doc_id": "8ec91488-f51b-47e5-844e-66ee93580447", "embedding": null, "doc_hash": "9802beca8ceda65cb95d527e513d071c31ed90e7963ab14301095e3bbb9c7ea2", "extra_info": null, "node_info": {"start": 28356, "end": 29084}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "fc793b9c-85bb-4e80-9577-2a9ed02b9487", "3": "b37a9554-fc95-4c11-a1aa-61375bad250b"}, "__type__": "1"}, "b37a9554-fc95-4c11-a1aa-61375bad250b": {"text": "# Compute the entropy of the batch of tensors start_time = timeit . default_timer () ent_g_batch = jax.vmap( ent_g )( x_batch ) end_time = timeit . default_timer () print ( end_time - start_time ) times . append ( end_time - start_time ) start_time = timeit . default_timer () ent_g_batch = ent_g ( x_batch ) end_time = timeit . default_timer () print ( end_time - start_time ) times . append ( end_time - start_time ) func =[ \"using vmap\" , 'without vmap' ] plt . bar ( func , times , color = 'maroon' , width = 0.4 ) plt . xlabel ( \"Type of ent_g\" ) plt . ylabel ( \"Computation time\" ) plt . title ( \"Comparison of ent_g with and without using vmap\" ) plt . show () In the example above, we generate a batch of tensors of shape (batch_size, n_vars, n_trials) and", "doc_id": "b37a9554-fc95-4c11-a1aa-61375bad250b", "embedding": null, "doc_hash": "5f432a1271cfaaef278a4c051c3536e9ccce5729a08d75ea039e5871ba2601a7", "extra_info": null, "node_info": {"start": 29091, "end": 29855}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "8ec91488-f51b-47e5-844e-66ee93580447", "3": "6d30bdfa-f603-4428-be3f-d27fb323be36"}, "__type__": "1"}, "6d30bdfa-f603-4428-be3f-d27fb323be36": {"text": "( end_time - start_time ) times . append ( end_time - start_time ) start_time = timeit . default_timer () ent_g_batch = ent_g ( x_batch ) end_time = timeit . default_timer () print ( end_time - start_time ) times . append ( end_time - start_time ) func =[ \"using vmap\" , 'without vmap' ] plt . bar ( func , times , color = 'maroon' , width = 0.4 ) plt . xlabel ( \"Type of ent_g\" ) plt . ylabel ( \"Computation time\" ) plt . title ( \"Comparison of ent_g with and without using vmap\" ) plt . show () In the example above, we generate a batch of tensors of shape (batch_size, n_vars, n_trials) and compute their entropy using `jax.vmap(ent_g)` and `ent_g` and compare their computation times. Using vmap can greatly speed up the computation of the entropy for multiple tensors, as", "doc_id": "6d30bdfa-f603-4428-be3f-d27fb323be36", "embedding": null, "doc_hash": "f1e449f1a1d3c5d0e7fba720eae52c2ec641e5db7a6aa32ddf6e1e3e768d2020", "extra_info": null, "node_info": {"start": 29854, "end": 30630}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "b37a9554-fc95-4c11-a1aa-61375bad250b", "3": "6f112c29-d5ab-4c63-b201-01b9f3a7f354"}, "__type__": "1"}, "6f112c29-d5ab-4c63-b201-01b9f3a7f354": {"text": "() print ( end_time - start_time ) times . append ( end_time - start_time ) func =[ \"using vmap\" , 'without vmap' ] plt . bar ( func , times , color = 'maroon' , width = 0.4 ) plt . xlabel ( \"Type of ent_g\" ) plt . ylabel ( \"Computation time\" ) plt . title ( \"Comparison of ent_g with and without using vmap\" ) plt . show () In the example above, we generate a batch of tensors of shape (batch_size, n_vars, n_trials) and compute their entropy using `jax.vmap(ent_g)` and `ent_g` and compare their computation times. Using vmap can greatly speed up the computation of the entropy for multiple tensors, as the computation can be parallelized across the batch dimension. For a large tensor with batch_size=1000 and num_classes=1000, the runtime of the vmap version is approximately 40 times faster than the non-vmap version. However,", "doc_id": "6f112c29-d5ab-4c63-b201-01b9f3a7f354", "embedding": null, "doc_hash": "01f3b647ba879f0cabe523b704d6f121a99525f6066b38829afdb81c184f8c74", "extra_info": null, "node_info": {"start": 30617, "end": 31448}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "6d30bdfa-f603-4428-be3f-d27fb323be36", "3": "2981ef25-c99b-411a-acf0-c94a8ecdc71f"}, "__type__": "1"}, "2981ef25-c99b-411a-acf0-c94a8ecdc71f": {"text": ") plt . xlabel ( \"Type of ent_g\" ) plt . ylabel ( \"Computation time\" ) plt . title ( \"Comparison of ent_g with and without using vmap\" ) plt . show () In the example above, we generate a batch of tensors of shape (batch_size, n_vars, n_trials) and compute their entropy using `jax.vmap(ent_g)` and `ent_g` and compare their computation times. Using vmap can greatly speed up the computation of the entropy for multiple tensors, as the computation can be parallelized across the batch dimension. For a large tensor with batch_size=1000 and num_classes=1000, the runtime of the vmap version is approximately 40 times faster than the non-vmap version. However, the exact speedup will depend on the specific input tensor and hardware being used.  \u25cf Parallel computations can be further used to speed up the implementations: For Jax implementation For parallel programming of multiple accelerators, like multiple", "doc_id": "2981ef25-c99b-411a-acf0-c94a8ecdc71f", "embedding": null, "doc_hash": "b6145986219c0ec56ba164e6b19253e5b402280151ec89c4092c4c9e68d77545", "extra_info": null, "node_info": {"start": 31391, "end": 32298}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "6f112c29-d5ab-4c63-b201-01b9f3a7f354", "3": "9fe20c72-4216-4dd9-ad13-d554fb6764dd"}, "__type__": "1"}, "9fe20c72-4216-4dd9-ad13-d554fb6764dd": {"text": "example above, we generate a batch of tensors of shape (batch_size, n_vars, n_trials) and compute their entropy using `jax.vmap(ent_g)` and `ent_g` and compare their computation times. Using vmap can greatly speed up the computation of the entropy for multiple tensors, as the computation can be parallelized across the batch dimension. For a large tensor with batch_size=1000 and num_classes=1000, the runtime of the vmap version is approximately 40 times faster than the non-vmap version. However, the exact speedup will depend on the specific input tensor and hardware being used.  \u25cf Parallel computations can be further used to speed up the implementations: For Jax implementation For parallel programming of multiple accelerators, like multiple GPUs,we can use pmap . With pmap, we write single-program multiple-data (SPMD) programs, including fast parallel collective communication operations. Applying pmap will mean that the function we write is compiled by XLA", "doc_id": "9fe20c72-4216-4dd9-ad13-d554fb6764dd", "embedding": null, "doc_hash": "39dff425136ee6e53f19d503bcd0e7639904e65f4e9486ae024087f2fb4b2953", "extra_info": null, "node_info": {"start": 32210, "end": 33179}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "2981ef25-c99b-411a-acf0-c94a8ecdc71f", "3": "7c82a23b-db71-4f6a-b3d0-e28139fde880"}, "__type__": "1"}, "7c82a23b-db71-4f6a-b3d0-e28139fde880": {"text": "compare their computation times. Using vmap can greatly speed up the computation of the entropy for multiple tensors, as the computation can be parallelized across the batch dimension. For a large tensor with batch_size=1000 and num_classes=1000, the runtime of the vmap version is approximately 40 times faster than the non-vmap version. However, the exact speedup will depend on the specific input tensor and hardware being used.  \u25cf Parallel computations can be further used to speed up the implementations: For Jax implementation For parallel programming of multiple accelerators, like multiple GPUs,we can use pmap . With pmap, we write single-program multiple-data (SPMD) programs, including fast parallel collective communication operations. Applying pmap will mean that the function we write is compiled by XLA (similarly to jit), then replicated and executed in parallel across devices. For NumPy implementation We can use np.apply_along_axis (due to faster execution of loops of the function in C) in case of small to", "doc_id": "7c82a23b-db71-4f6a-b3d0-e28139fde880", "embedding": null, "doc_hash": "9a32e7c1095b0db58f65f94ca1d822fda22289ce3881ea53dd34421e9e1f42e2", "extra_info": null, "node_info": {"start": 33122, "end": 34148}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "9fe20c72-4216-4dd9-ad13-d554fb6764dd", "3": "bc73a9ad-9412-4e11-957f-8b7f34056979"}, "__type__": "1"}, "bc73a9ad-9412-4e11-957f-8b7f34056979": {"text": "and num_classes=1000, the runtime of the vmap version is approximately 40 times faster than the non-vmap version. However, the exact speedup will depend on the specific input tensor and hardware being used.  \u25cf Parallel computations can be further used to speed up the implementations: For Jax implementation For parallel programming of multiple accelerators, like multiple GPUs,we can use pmap . With pmap, we write single-program multiple-data (SPMD) programs, including fast parallel collective communication operations. Applying pmap will mean that the function we write is compiled by XLA (similarly to jit), then replicated and executed in parallel across devices. For NumPy implementation We can use np.apply_along_axis (due to faster execution of loops of the function in C) in case of small to medium-sized arrays while for large arrays, we could consider using parallel computing libraries such as multiprocessing or joblib to parallelize the computation. \u25cf SPECIFICALL", "doc_id": "bc73a9ad-9412-4e11-957f-8b7f34056979", "embedding": null, "doc_hash": "05ec8aad1824a5ad47c068ff464a6dd0ed422afcb20886157de4a7932bdcf827", "extra_info": null, "node_info": {"start": 34165, "end": 35143}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "7c82a23b-db71-4f6a-b3d0-e28139fde880", "3": "de5a1729-c464-45ac-80f5-cbd8583f0878"}, "__type__": "1"}, "de5a1729-c464-45ac-80f5-cbd8583f0878": {"text": "and hardware being used.  \u25cf Parallel computations can be further used to speed up the implementations: For Jax implementation For parallel programming of multiple accelerators, like multiple GPUs,we can use pmap . With pmap, we write single-program multiple-data (SPMD) programs, including fast parallel collective communication operations. Applying pmap will mean that the function we write is compiled by XLA (similarly to jit), then replicated and executed in parallel across devices. For NumPy implementation We can use np.apply_along_axis (due to faster execution of loops of the function in C) in case of small to medium-sized arrays while for large arrays, we could consider using parallel computing libraries such as multiprocessing or joblib to parallelize the computation. \u25cf SPECIFICALL Y\nFOR\nNUMPY:\nThe\ncode\ncan\nbe\nfur ther\noptimiz ed\nusing\na\nJI", "doc_id": "de5a1729-c464-45ac-80f5-cbd8583f0878", "embedding": null, "doc_hash": "de2f0c6c1aa3d72c205a4d273278c6ab59290ebc29de0006da025c6a0d22045f", "extra_info": null, "node_info": {"start": 35145, "end": 36001}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "bc73a9ad-9412-4e11-957f-8b7f34056979", "3": "51baf38e-b5c2-438a-a541-cdf1e36abd24"}, "__type__": "1"}, "51baf38e-b5c2-438a-a541-cdf1e36abd24": {"text": "implementation For parallel programming of multiple accelerators, like multiple GPUs,we can use pmap . With pmap, we write single-program multiple-data (SPMD) programs, including fast parallel collective communication operations. Applying pmap will mean that the function we write is compiled by XLA (similarly to jit), then replicated and executed in parallel across devices. For NumPy implementation We can use np.apply_along_axis (due to faster execution of loops of the function in C) in case of small to medium-sized arrays while for large arrays, we could consider using parallel computing libraries such as multiprocessing or joblib to parallelize the computation. \u25cf SPECIFICALL Y\nFOR\nNUMPY:\nThe\ncode\ncan\nbe\nfur ther\noptimiz ed\nusing\na\nJI T\n(just-in-time)\ncompiler\nsuch\nas\nNumba.\nThis\ncan\nsigni\ufb01cantly\nimpr o v e\nper formance,\nespecially\nfor\nlar", "doc_id": "51baf38e-b5c2-438a-a541-cdf1e36abd24", "embedding": null, "doc_hash": "bb493a7d0646566b6d30d1bb31f1cba023b351b3f5ac39a05c71304849ccd44c", "extra_info": null, "node_info": {"start": 36037, "end": 36889}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "de5a1729-c464-45ac-80f5-cbd8583f0878", "3": "bd7e5557-7704-48f1-bcca-193a8c573fd6"}, "__type__": "1"}, "bd7e5557-7704-48f1-bcca-193a8c573fd6": {"text": "communication operations. Applying pmap will mean that the function we write is compiled by XLA (similarly to jit), then replicated and executed in parallel across devices. For NumPy implementation We can use np.apply_along_axis (due to faster execution of loops of the function in C) in case of small to medium-sized arrays while for large arrays, we could consider using parallel computing libraries such as multiprocessing or joblib to", "doc_id": "bd7e5557-7704-48f1-bcca-193a8c573fd6", "embedding": null, "doc_hash": "427c10161f534ad9674328d4a5ef15a5279cdacf0046e31230841e28b22d84e8", "extra_info": null, "node_info": {"start": 36966, "end": 37404}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "51baf38e-b5c2-438a-a541-cdf1e36abd24", "3": "c376ecb7-3ec8-4607-acc4-0599366f85bf"}, "__type__": "1"}, "c376ecb7-3ec8-4607-acc4-0599366f85bf": {"text": "parallelize the computation. \u25cf SPECIFICALL Y\nFOR\nNUMPY:\nThe\ncode\ncan\nbe\nfur ther\noptimiz ed\nusing\na\nJI T\n(just-in-time)\ncompiler\nsuch\nas\nNumba.\nThis\ncan\nsigni\ufb01cantly\nimpr o v e\nper formance,\nespecially\nfor\nlar ge\ndatasets.\nNumba\nis\na\njust-in-time\ncompiler\nfor\nPython\nthat\nworks\nbest\non\ncode\nthat\nuses\nNumPy\narrays\nand\nfunctions,\nand\nloops\n.\nThe\nfollowing\nis\na\ngraph\nshowing\nthe\nspeedup\noffered\nby\ncompilation\nusing\nNumba\nfor\na\nsimple\npiece\nof\ncode\nto\ncalculate\nagainst\nthat\nby\npython.\n\n3 . 1 . 2\nM e r g i n g\nt h e\nn u m p y\na n d\nj a x\ni m p l e m e n t a t", "doc_id": "c376ecb7-3ec8-4607-acc4-0599366f85bf", "embedding": null, "doc_hash": "0f9f0374dea8988a748a549e1f3e5dc301d90144f1c9960e7d75c349712e2279", "extra_info": null, "node_info": {"start": 37973, "end": 38532}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "bd7e5557-7704-48f1-bcca-193a8c573fd6", "3": "fbb0bc3a-e161-48b5-8101-a4e6a93a1399"}, "__type__": "1"}, "fbb0bc3a-e161-48b5-8101-a4e6a93a1399": {"text": "o v e\nper formance,\nespecially\nfor\nlar ge\ndatasets.\nNumba\nis\na\njust-in-time\ncompiler\nfor\nPython\nthat\nworks\nbest\non\ncode\nthat\nuses\nNumPy\narrays\nand\nfunctions,\nand\nloops\n.\nThe\nfollowing\nis\na\ngraph\nshowing\nthe\nspeedup\noffered\nby\ncompilation\nusing\nNumba\nfor\na\nsimple\npiece\nof\ncode\nto\ncalculate\nagainst\nthat\nby\npython.\n\n3 . 1 . 2\nM e r g i n g\nt h e\nn u m p y\na n d\nj a x\ni m p l e m e n t a t i o n s\ni n t o\na\ns i n g l e\nf u n c t i o n \u25cf Our goal is to make the jax implementation the first priority due to its C/GPU use and faster computations. \u25cf But, to minimize requirements, we may not want the user to install the jax library (if", "doc_id": "fbb0bc3a-e161-48b5-8101-a4e6a93a1399", "embedding": null, "doc_hash": "2440b132882d7f55c2593889b127b42bd5334d43130197dbb3d4fc4b0b58132f", "extra_info": null, "node_info": {"start": 38179, "end": 38812}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "c376ecb7-3ec8-4607-acc4-0599366f85bf", "3": "61e90ff3-a68e-42d9-8470-eb822a05dce3"}, "__type__": "1"}, "61e90ff3-a68e-42d9-8470-eb822a05dce3": {"text": ". 1 . 2\nM e r g i n g\nt h e\nn u m p y\na n d\nj a x\ni m p l e m e n t a t i o n s\ni n t o\na\ns i n g l e\nf u n c t i o n \u25cf Our goal is to make the jax implementation the first priority due to its C/GPU use and faster computations. \u25cf But, to minimize requirements, we may not want the user to install the jax library (if not already installed). \u25cf We aim to design a function which would check the existence of the jax library and implement the jax version if the library is found and the numpy version, if it is not. \u25cf The following could be the logic used: try : import jax import jax.numpy as np except ImportError : import numpy as np if 'jax' in globals (): # Use JAX implementation else : # Use NumPy implementation The following are a few factors which must be checked (by the code itself) to select one of the implementations: \u25cf What are the dependencies", "doc_id": "61e90ff3-a68e-42d9-8470-eb822a05dce3", "embedding": null, "doc_hash": "b0c5949beda381cd301d1596f5686202817348f16f5fc9c8bac5c4e6e0213822", "extra_info": null, "node_info": {"start": 38936, "end": 39793}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "fbb0bc3a-e161-48b5-8101-a4e6a93a1399", "3": "0861d760-e8a9-47ea-a2b9-3856c5958f9b"}, "__type__": "1"}, "0861d760-e8a9-47ea-a2b9-3856c5958f9b": {"text": "n g l e\nf u n c t i o n \u25cf Our goal is to make the jax implementation the first priority due to its C/GPU use and faster computations. \u25cf But, to minimize requirements, we may not want the user to install the jax library (if not already installed). \u25cf We aim to design a function which would check the existence of the jax library and implement the jax version if the library is found and the numpy version, if it is not. \u25cf The following could be the logic used: try : import jax import jax.numpy as np except ImportError : import numpy as np if 'jax' in globals (): # Use JAX implementation else : # Use NumPy implementation The following are a few factors which must be checked (by the code itself) to select one of the implementations: \u25cf What are the dependencies of Jax when installed using CPU only? These libraries are a prerequisite for Jax to function: scipy>=1.5,opt-einsum,numpy>=1.20,jaxlib==0.4.6 \u25cf The", "doc_id": "0861d760-e8a9-47ea-a2b9-3856c5958f9b", "embedding": null, "doc_hash": "6df678cf75b0ff7746bad600a6ea26dfe4b46c3bb96b8f79227bf4ceb65fe244", "extra_info": null, "node_info": {"start": 39409, "end": 40320}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "61e90ff3-a68e-42d9-8470-eb822a05dce3", "3": "22632d94-c8cb-4c02-a811-1d0ddbeda6b9"}, "__type__": "1"}, "22632d94-c8cb-4c02-a811-1d0ddbeda6b9": {"text": "to install the jax library (if not already installed). \u25cf We aim to design a function which would check the existence of the jax library and implement the jax version if the library is found and the numpy version, if it is not. \u25cf The following could be the logic used: try : import jax import jax.numpy as np except ImportError : import numpy as np if 'jax' in globals (): # Use JAX implementation else : # Use NumPy implementation The following are a few factors which must be checked (by the code itself) to select one of the implementations: \u25cf What are the dependencies of Jax when installed using CPU only? These libraries are a prerequisite for Jax to function: scipy>=1.5,opt-einsum,numpy>=1.20,jaxlib==0.4.6 \u25cf The operating system being used. We can check this using the OS module in python. Ubuntu 16.04 or later and macOS (10.12 or later) are platforms which support the JAX library. However, Windows doesn\u2019t. 3 . 1 .", "doc_id": "22632d94-c8cb-4c02-a811-1d0ddbeda6b9", "embedding": null, "doc_hash": "69a44c1f70a3a264be18a63f66950979ce24aa52bae2a59363dc4d7cdad317ae", "extra_info": null, "node_info": {"start": 40342, "end": 41267}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "0861d760-e8a9-47ea-a2b9-3856c5958f9b", "3": "99ef7f4a-3e1b-4f21-adce-7e9d7b4f1185"}, "__type__": "1"}, "99ef7f4a-3e1b-4f21-adce-7e9d7b4f1185": {"text": "could be the logic used: try : import jax import jax.numpy as np except ImportError : import numpy as np if 'jax' in globals (): # Use JAX implementation else : # Use NumPy implementation The following are a few factors which must be checked (by the code itself) to select one of the implementations: \u25cf What are the dependencies of Jax when installed using CPU only? These libraries are a prerequisite for Jax to function: scipy>=1.5,opt-einsum,numpy>=1.20,jaxlib==0.4.6 \u25cf The operating system being used. We can check this using the OS module in python. Ubuntu 16.04 or later and macOS (10.12 or later) are platforms which support the JAX library. However, Windows doesn\u2019t. 3 . 1 . 3\nD a t a\ns i m u l a t i o n Rosas\u2019 paper defines redundancy and synergy as: Redundancy-dominated scenarios are where three or more variables have copies of the same information.", "doc_id": "99ef7f4a-3e1b-4f21-adce-7e9d7b4f1185", "embedding": null, "doc_hash": "5acd7013a50315be3ecb06f8aea80aa64c050072999b2be06ee3e337b9e7d956", "extra_info": null, "node_info": {"start": 41296, "end": 42158}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "22632d94-c8cb-4c02-a811-1d0ddbeda6b9", "3": "5e7613fe-7d60-401c-a80e-9991dc3e55f6"}, "__type__": "1"}, "5e7613fe-7d60-401c-a80e-9991dc3e55f6": {"text": "following are a few factors which must be checked (by the code itself) to select one of the implementations: \u25cf What are the dependencies of Jax when installed using CPU only? These libraries are a prerequisite for Jax to function: scipy>=1.5,opt-einsum,numpy>=1.20,jaxlib==0.4.6 \u25cf The operating system being used. We can check this using the OS module in python. Ubuntu 16.04 or later and macOS (10.12 or later) are platforms which support the JAX library. However, Windows doesn\u2019t. 3 . 1 . 3\nD a t a\ns i m u l a t i o n Rosas\u2019 paper defines redundancy and synergy as: Redundancy-dominated scenarios are where three or more variables have copies of the same information. Synergy-dominated scenarios are those which are characterized by high-order patterns that cannot be traced from low-order marginals. We will create a function `simulate_hoi` which is able to simulate ground truth. 1. This", "doc_id": "5e7613fe-7d60-401c-a80e-9991dc3e55f6", "embedding": null, "doc_hash": "9a4fb46780da1fa3e3225d41dca5d6ff1f295e8f8e8981ea824cd3649574ed58", "extra_info": null, "node_info": {"start": 42169, "end": 43061}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "99ef7f4a-3e1b-4f21-adce-7e9d7b4f1185", "3": "943626f0-5f75-4025-ac64-ab4d3e0b240f"}, "__type__": "1"}, "943626f0-5f75-4025-ac64-ab4d3e0b240f": {"text": "\u25cf The operating system being used. We can check this using the OS module in python. Ubuntu 16.04 or later and macOS (10.12 or later) are platforms which support the JAX library. However, Windows doesn\u2019t. 3 . 1 . 3\nD a t a\ns i m u l a t i o n Rosas\u2019 paper defines redundancy and synergy as: Redundancy-dominated scenarios are where three or more variables have copies of the same information. Synergy-dominated scenarios are those which are characterized by high-order patterns that cannot be traced from low-order marginals. We will create a function `simulate_hoi` which is able to simulate ground truth. 1. This would be a function which takes a few multiplets and purposefully generates redundant and synergistic interactions between the groups or, we use data whose interactions we are already cognizant of. 2. We call our function on the HOIs and determine whether the interactions obtained are more redundant or synergistic. 3. We then compare the results with the original", "doc_id": "943626f0-5f75-4025-ac64-ab4d3e0b240f", "embedding": null, "doc_hash": "1f5f126694e527f970ce1825136e1071fb68d8a4304f2d2b76a283358a38b070", "extra_info": null, "node_info": {"start": 43110, "end": 44089}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "5e7613fe-7d60-401c-a80e-9991dc3e55f6", "3": "10b7ee5f-2341-40e4-af56-47c6aace71ff"}, "__type__": "1"}, "10b7ee5f-2341-40e4-af56-47c6aace71ff": {"text": "1 . 3\nD a t a\ns i m u l a t i o n Rosas\u2019 paper defines redundancy and synergy as: Redundancy-dominated scenarios are where three or more variables have copies of the same information. Synergy-dominated scenarios are those which are characterized by high-order patterns that cannot be traced from low-order marginals. We will create a function `simulate_hoi` which is able to simulate ground truth. 1. This would be a function which takes a few multiplets and purposefully generates redundant and synergistic interactions between the groups or, we use data whose interactions we are already cognizant of. 2. We call our function on the HOIs and determine whether the interactions obtained are more redundant or synergistic. 3. We then compare the results with the original data and this would help us determine the correctness of our code. 3 . 1 . 4\nH O I s\np l o t t i n", "doc_id": "10b7ee5f-2341-40e4-af56-47c6aace71ff", "embedding": null, "doc_hash": "a586cecf747ac4e72b0684bcebdbefecb4267c063ece05176d3eabafdf78b389", "extra_info": null, "node_info": {"start": 43953, "end": 44823}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "943626f0-5f75-4025-ac64-ab4d3e0b240f", "3": "43f9205c-dfd9-4d3e-81ff-55d3579b0847"}, "__type__": "1"}, "43f9205c-dfd9-4d3e-81ff-55d3579b0847": {"text": "Redundancy-dominated scenarios are where three or more variables have copies of the same information. Synergy-dominated scenarios are those which are characterized by high-order patterns that cannot be traced from low-order marginals. We will create a function `simulate_hoi` which is able to simulate ground truth. 1. This would be a function which takes a few multiplets and purposefully generates redundant and synergistic interactions between the groups or, we use data whose interactions we are already cognizant of. 2. We call our function on the HOIs and determine whether the interactions obtained are more redundant or synergistic. 3. We then compare the", "doc_id": "43f9205c-dfd9-4d3e-81ff-55d3579b0847", "embedding": null, "doc_hash": "5b491435084cb6aac142e508ea98e415558bb9677c3c9e7a78d799fe2e32fefa", "extra_info": null, "node_info": {"start": 44811, "end": 45474}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "10b7ee5f-2341-40e4-af56-47c6aace71ff", "3": "e25e0f29-b1b0-49ae-87ca-0bfd99804aac"}, "__type__": "1"}, "e25e0f29-b1b0-49ae-87ca-0bfd99804aac": {"text": "results with the original data and this would help us determine the correctness of our code. 3 . 1 . 4\nH O I s\np l o t t i n g\nSince\nour\nanalysis\ninvolves\nthe\nstudy\nof\ncomplex\nsystems\nwith\nhigher-order\ninteractions,\nI\nwould\nprefer\nusing\nHyperNetX\naccording\nto\nthe\nsuggestions\nof\nthe\nmentors.\nWe\ncould\nalso\nuse\na\ncombination\nof\nXGI\nand\nHyperNetX\nto\nanalyze\ncomplex\nsystems\nwith\nboth\ngroup\ninteractions\n(dealt\nby\nXGI)\nand\nhigher-order\ninteractions\n(dealt\nby\nHyperNetX).\nThese\ntutorials\non\nHyperNetX\nwould\nmake\nthe\nimplementation\nfaster\nand\neasier.\n3 . 1 . 5\nF r i t e s\nI n t e g r a t i o n Frites is a Python toolbox for assessing information-theoretic measures on human and animal neurophysiological data. The final step", "doc_id": "e25e0f29-b1b0-49ae-87ca-0bfd99804aac", "embedding": null, "doc_hash": "46b90199327ae8a4b7af52979cc838e9a62a6494a323fec6ae4bf21087b3f3e1", "extra_info": null, "node_info": {"start": 46134, "end": 46855}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "43f9205c-dfd9-4d3e-81ff-55d3579b0847", "3": "2cb73adf-a6dc-4c31-ac56-3303670570f3"}, "__type__": "1"}, "2cb73adf-a6dc-4c31-ac56-3303670570f3": {"text": ". 1 . 5\nF r i t e s\nI n t e g r a t i o n Frites is a Python toolbox for assessing information-theoretic measures on human and animal neurophysiological data. The final step of the project is to integrate the HOI generating function to the Frites package. This would involve making our code compatible with Frites requirements. Few of the checks for compatibility are: \u25cf Test with pytest \u25cf Install all required dependencies \u25cf Check coding style and errors using Flake8 which uses PyFlakes ( for errors and potential code problems, pycodestyle - checks coding style using a subset of PEP8.) Also, creating a detailed readme (explaining how to use our functions with any prerequisites) containing: \u25cf Description of functions understandable to non-coders \u25cf Installations of necessary dependencies And other relevant material. 3.2 Communication with the mentors 1. I make sure to communicate with my mentors on a daily basis and keep them updated about my progress each day. 2. I will reach out to them on the platform preferred by them (e-mail, discord", "doc_id": "2cb73adf-a6dc-4c31-ac56-3303670570f3", "embedding": null, "doc_hash": "efe3690fe8f767ffc8ae63a28ae1274c7fd2d5df7243863a4bac70582f4e007c", "extra_info": null, "node_info": {"start": 46719, "end": 47768}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "e25e0f29-b1b0-49ae-87ca-0bfd99804aac", "3": "89095b03-f168-4478-8a18-7c4c4ded862c"}, "__type__": "1"}, "89095b03-f168-4478-8a18-7c4c4ded862c": {"text": "to integrate the HOI generating function to the Frites package. This would involve making our code compatible with Frites requirements. Few of the checks for compatibility are: \u25cf Test with pytest \u25cf Install all required dependencies \u25cf Check coding style and errors using Flake8 which uses PyFlakes ( for errors and potential code problems, pycodestyle - checks coding style using a subset of PEP8.) Also, creating a detailed readme (explaining how to use our functions with any prerequisites) containing: \u25cf Description of functions understandable to non-coders \u25cf Installations of necessary dependencies And other relevant material. 3.2 Communication with the mentors 1. I make sure to communicate with my mentors on a daily basis and keep them updated about my progress each day. 2. I will reach out to them on the platform preferred by them (e-mail, discord or any of their convenience). 3. I would like to have a weekly meeting with the mentors in order to get a better understanding of the correctness of my approach and any improvements they suggest. 3.3 Project Timeline Detailed timeline for", "doc_id": "89095b03-f168-4478-8a18-7c4c4ded862c", "embedding": null, "doc_hash": "180cf57da4b271be2cf910cef2b23009f5e820a4ce73ba013cbdde7954fb56f8", "extra_info": null, "node_info": {"start": 47185, "end": 48281}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "2cb73adf-a6dc-4c31-ac56-3303670570f3", "3": "713e9567-730f-464b-9f2a-7ad04f61d5e1"}, "__type__": "1"}, "713e9567-730f-464b-9f2a-7ad04f61d5e1": {"text": "using Flake8 which uses PyFlakes ( for errors and potential code problems, pycodestyle - checks coding style using a subset of PEP8.) Also, creating a detailed readme (explaining how to use our functions with any prerequisites) containing: \u25cf Description of functions understandable to non-coders \u25cf Installations of necessary dependencies And other relevant material. 3.2 Communication with the mentors 1. I make sure to communicate with my mentors on a daily basis and keep them updated about my progress each day. 2. I will reach out to them on the platform preferred by them (e-mail, discord or any of their convenience). 3. I would like to have a weekly meeting with the mentors in order to get a better understanding of the correctness of my approach and any improvements they suggest. 3.3 Project Timeline Detailed timeline for each task with respective deliverables. Date Event Proposed tasks March 20 - April 4 GSoc application period \u25cf Submit final proposal on portal April 4 - May 4 Pre- selection phase \u25cf Do maximum research on project", "doc_id": "713e9567-730f-464b-9f2a-7ad04f61d5e1", "embedding": null, "doc_hash": "f1928154ac4516f08ac7516ea3523603a5ab72df7c1c1f320a1cb320493e4a87", "extra_info": null, "node_info": {"start": 48306, "end": 49351}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "89095b03-f168-4478-8a18-7c4c4ded862c", "3": "6b6cf7eb-1b7d-482d-be97-5a9f3fe85b64"}, "__type__": "1"}, "6b6cf7eb-1b7d-482d-be97-5a9f3fe85b64": {"text": "how to use our functions with any prerequisites) containing: \u25cf Description of functions understandable to non-coders \u25cf Installations of necessary dependencies And other relevant material. 3.2 Communication with the mentors 1. I make sure to communicate with my mentors on a daily basis and keep them updated about my progress each day. 2. I will reach out to them on the platform preferred by them (e-mail, discord or any of their convenience). 3. I would like to have a weekly meeting with the mentors in order to get a better understanding of the correctness of my approach and any improvements they suggest. 3.3 Project Timeline Detailed timeline for each task with respective deliverables. Date Event Proposed tasks March 20 - April 4 GSoc application period \u25cf Submit final proposal on portal April 4 - May 4 Pre- selection phase \u25cf Do maximum research on project \n\u25cf\nFamiliarize\nwith\nmethods\nto \noptimize\nHOIs\nMay\n4\n-\n28\nCommunity\nbonding\nperiod\n\u25cf\nTalk\nto\nand\nlearn\nfrom\nother \npeople\nand\ntheir\ninterests.", "doc_id": "6b6cf7eb-1b7d-482d-be97-5a9f3fe85b64", "embedding": null, "doc_hash": "cde43893504b707c0d13b123ccc7f9d3fbc45fba079d9f1677935f1e77ea190e", "extra_info": null, "node_info": {"start": 49327, "end": 50335}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "713e9567-730f-464b-9f2a-7ad04f61d5e1", "3": "f1f9231a-56af-4079-87e8-e18971490cf2"}, "__type__": "1"}, "f1f9231a-56af-4079-87e8-e18971490cf2": {"text": "my mentors on a daily basis and keep them updated about my progress each day. 2. I will reach out to them on the platform preferred by them (e-mail, discord or any of their convenience). 3. I would like to have a weekly meeting with the mentors in order to get a better understanding of the correctness of my approach and any improvements they suggest. 3.3 Project Timeline Detailed timeline for each task with respective deliverables. Date Event Proposed tasks March 20 - April 4 GSoc application period \u25cf Submit final proposal on portal April 4 - May 4 Pre- selection phase \u25cf Do maximum research on project \n\u25cf\nFamiliarize\nwith\nmethods\nto \noptimize\nHOIs\nMay\n4\n-\n28\nCommunity\nbonding\nperiod\n\u25cf\nTalk\nto\nand\nlearn\nfrom\nother \npeople\nand\ntheir\ninterests. \n\u25cf\nDiligently\nstudy\nany\nadditional \nresources\nrelevant.\nMay\n15\n-\nJune\n1\nUniversity\nExams\n\u25cf\nFocus\non\nCollege\nexaminations\nMay\n29\n-\nJune\n12", "doc_id": "f1f9231a-56af-4079-87e8-e18971490cf2", "embedding": null, "doc_hash": "068bafa785a6efa045254de353c6da6c53317b319e17c5af742c5cfb120d5dc8", "extra_info": null, "node_info": {"start": 50418, "end": 51306}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "6b6cf7eb-1b7d-482d-be97-5a9f3fe85b64", "3": "8c78592c-8ab2-4c55-a1cd-72ae44c03cca"}, "__type__": "1"}, "8c78592c-8ab2-4c55-a1cd-72ae44c03cca": {"text": "weekly meeting with the mentors in order to get a better understanding of the correctness of my approach and any improvements they suggest. 3.3 Project Timeline Detailed timeline for each task with respective deliverables. Date Event Proposed tasks March 20 - April 4 GSoc application period \u25cf Submit final proposal on portal April 4 - May 4 Pre- selection phase \u25cf Do maximum research on project \n\u25cf\nFamiliarize\nwith\nmethods\nto \noptimize\nHOIs\nMay\n4\n-\n28\nCommunity\nbonding\nperiod\n\u25cf\nTalk\nto\nand\nlearn\nfrom\nother \npeople\nand\ntheir\ninterests. \n\u25cf\nDiligently\nstudy\nany\nadditional \nresources\nrelevant.\nMay\n15\n-\nJune\n1\nUniversity\nExams\n\u25cf\nFocus\non\nCollege\nexaminations\nMay\n29\n-\nJune\n12 \n[\nWeek\n1\n-\nWeek\n2\n]\nCoding\nbegins\n\u25cf\nUse\nthe\nresearch\ndone\nin \npre-selection\nphase\nand\nwork\nto", "doc_id": "8c78592c-8ab2-4c55-a1cd-72ae44c03cca", "embedding": null, "doc_hash": "8a0f9e7870b3e2a1074a28662d5f3a99f3ebcf74cc08f69a54265eeba3cb2ad2", "extra_info": null, "node_info": {"start": 51342, "end": 52112}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "f1f9231a-56af-4079-87e8-e18971490cf2", "3": "71a8e6a4-91b2-4e1a-af35-4071e6a42851"}, "__type__": "1"}, "71a8e6a4-91b2-4e1a-af35-4071e6a42851": {"text": "deliverables. Date Event Proposed tasks March 20 - April 4 GSoc application period \u25cf Submit final proposal on portal April 4 - May 4 Pre- selection phase \u25cf Do maximum research on project \n\u25cf\nFamiliarize\nwith\nmethods\nto \noptimize\nHOIs\nMay\n4\n-\n28\nCommunity\nbonding\nperiod\n\u25cf\nTalk\nto\nand\nlearn\nfrom\nother \npeople\nand\ntheir\ninterests. \n\u25cf\nDiligently\nstudy\nany\nadditional \nresources\nrelevant.\nMay\n15\n-\nJune\n1\nUniversity\nExams\n\u25cf\nFocus\non\nCollege\nexaminations\nMay\n29\n-\nJune\n12 \n[\nWeek\n1\n-\nWeek\n2\n]\nCoding\nbegins\n\u25cf\nUse\nthe\nresearch\ndone\nin \npre-selection\nphase\nand\nwork\nto \nachieve\nmaximum\noptimization\nJune\n13\n-\nJune\n19 \n[\nWeek\n3\n]\nMilestone\n#1\n\u25cf\nDiscuss\nwith\nmentors\nthe\nscope", "doc_id": "71a8e6a4-91b2-4e1a-af35-4071e6a42851", "embedding": null, "doc_hash": "88d037a375647389216e05213b03c85be9477357cba6666c09d211b860af7f22", "extra_info": null, "node_info": {"start": 52196, "end": 52863}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "8c78592c-8ab2-4c55-a1cd-72ae44c03cca", "3": "bf7aed18-be1b-4ffd-83bf-1010523c0ff9"}, "__type__": "1"}, "bf7aed18-be1b-4ffd-83bf-1010523c0ff9": {"text": "\noptimize\nHOIs\nMay\n4\n-\n28\nCommunity\nbonding\nperiod\n\u25cf\nTalk\nto\nand\nlearn\nfrom\nother \npeople\nand\ntheir\ninterests. \n\u25cf\nDiligently\nstudy\nany\nadditional \nresources\nrelevant.\nMay\n15\n-\nJune\n1\nUniversity\nExams\n\u25cf\nFocus\non\nCollege\nexaminations\nMay\n29\n-\nJune\n12 \n[\nWeek\n1\n-\nWeek\n2\n]\nCoding\nbegins\n\u25cf\nUse\nthe\nresearch\ndone\nin \npre-selection\nphase\nand\nwork\nto \nachieve\nmaximum\noptimization\nJune\n13\n-\nJune\n19 \n[\nWeek\n3\n]\nMilestone\n#1\n\u25cf\nDiscuss\nwith\nmentors\nthe\nscope \nof\nfurther\noptimization \n\u25cf\nFinish\n(1)\noptimization\nof\nHOIs\nJune\n20\n-\nJune\n26", "doc_id": "bf7aed18-be1b-4ffd-83bf-1010523c0ff9", "embedding": null, "doc_hash": "e8e04c0da1727f2f5e88828e2b7bc6aad7d4c7ced075c40add00f4321838af0a", "extra_info": null, "node_info": {"start": 52944, "end": 53471}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "71a8e6a4-91b2-4e1a-af35-4071e6a42851", "3": "0581fc00-e934-4c0a-a7f8-3738c8957341"}, "__type__": "1"}, "0581fc00-e934-4c0a-a7f8-3738c8957341": {"text": "\npeople\nand\ntheir\ninterests. \n\u25cf\nDiligently\nstudy\nany\nadditional \nresources\nrelevant.\nMay\n15\n-\nJune\n1\nUniversity\nExams\n\u25cf\nFocus\non\nCollege\nexaminations\nMay\n29\n-\nJune\n12 \n[\nWeek\n1\n-\nWeek\n2\n]\nCoding\nbegins\n\u25cf\nUse\nthe\nresearch\ndone\nin \npre-selection\nphase\nand\nwork\nto \nachieve\nmaximum\noptimization\nJune\n13\n-\nJune\n19 \n[\nWeek\n3\n]\nMilestone\n#1\n\u25cf\nDiscuss\nwith\nmentors\nthe\nscope \nof\nfurther\noptimization \n\u25cf\nFinish\n(1)\noptimization\nof\nHOIs\nJune\n20\n-\nJune\n26 \n[\nWeek\n4\n]\nMilestone\n#2\n\u25cf\nResearch\nabout\nmerging\nNumPy \nand\nJax\nimplementations \n\u25cf\nFinish\n(2)\nmerging\nthe\ntwo", "doc_id": "0581fc00-e934-4c0a-a7f8-3738c8957341", "embedding": null, "doc_hash": "4121b8863c02efefe70937db115df414546358f8625030cf111b8f766568437d", "extra_info": null, "node_info": {"start": 53477, "end": 54033}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "bf7aed18-be1b-4ffd-83bf-1010523c0ff9", "3": "be2661ba-fd24-4c48-b0f4-b6e9e43d0449"}, "__type__": "1"}, "be2661ba-fd24-4c48-b0f4-b6e9e43d0449": {"text": "\n[\nWeek\n1\n-\nWeek\n2\n]\nCoding\nbegins\n\u25cf\nUse\nthe\nresearch\ndone\nin \npre-selection\nphase\nand\nwork\nto \nachieve\nmaximum\noptimization\nJune\n13\n-\nJune\n19 \n[\nWeek\n3\n]\nMilestone\n#1\n\u25cf\nDiscuss\nwith\nmentors\nthe\nscope \nof\nfurther\noptimization \n\u25cf\nFinish\n(1)\noptimization\nof\nHOIs\nJune\n20\n-\nJune\n26 \n[\nWeek\n4\n]\nMilestone\n#2\n\u25cf\nResearch\nabout\nmerging\nNumPy \nand\nJax\nimplementations \n\u25cf\nFinish\n(2)\nmerging\nthe\ntwo \nimplementations\nJune\n27\n-\nJuly\n3 \n[\nWeek\n5\n]\nMilestone\n#3\n\u25cf\nComplete\n(3)\nsimulate_hoi \nfunction\nJuly\n4\n-\nJuly\n10", "doc_id": "be2661ba-fd24-4c48-b0f4-b6e9e43d0449", "embedding": null, "doc_hash": "8e49363a5410c8eef0cf1aa1b46d949e62047ceb8c65aef6e324a6e969985b21", "extra_info": null, "node_info": {"start": 54090, "end": 54593}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "0581fc00-e934-4c0a-a7f8-3738c8957341", "3": "0c2545b6-8740-40fd-b8db-870c8a3f14bb"}, "__type__": "1"}, "0c2545b6-8740-40fd-b8db-870c8a3f14bb": {"text": "\nachieve\nmaximum\noptimization\nJune\n13\n-\nJune\n19 \n[\nWeek\n3\n]\nMilestone\n#1\n\u25cf\nDiscuss\nwith\nmentors\nthe\nscope \nof\nfurther\noptimization \n\u25cf\nFinish\n(1)\noptimization\nof\nHOIs\nJune\n20\n-\nJune\n26 \n[\nWeek\n4\n]\nMilestone\n#2\n\u25cf\nResearch\nabout\nmerging\nNumPy \nand\nJax\nimplementations \n\u25cf\nFinish\n(2)\nmerging\nthe\ntwo \nimplementations\nJune\n27\n-\nJuly\n3 \n[\nWeek\n5\n]\nMilestone\n#3\n\u25cf\nComplete\n(3)\nsimulate_hoi \nfunction\nJuly\n4\n-\nJuly\n10 \n[\nWeek\n6\n]\nMilestone\n#4\n[Mid\n-\nterm\nevaluation]\n\u25cf\nDiscuss\nwith\nmentors\nthe\nmore \npreferred\nof\nXGI\nand\nHyperNetX", "doc_id": "0c2545b6-8740-40fd-b8db-870c8a3f14bb", "embedding": null, "doc_hash": "38462fc7cf438749dce70f41513d5e3032ded018451d7205371fc603fd93e6e5", "extra_info": null, "node_info": {"start": 54576, "end": 55097}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "be2661ba-fd24-4c48-b0f4-b6e9e43d0449", "3": "72692f76-a6cf-4a10-b77b-257c697543b8"}, "__type__": "1"}, "72692f76-a6cf-4a10-b77b-257c697543b8": {"text": "\nof\nfurther\noptimization \n\u25cf\nFinish\n(1)\noptimization\nof\nHOIs\nJune\n20\n-\nJune\n26 \n[\nWeek\n4\n]\nMilestone\n#2\n\u25cf\nResearch\nabout\nmerging\nNumPy \nand\nJax\nimplementations \n\u25cf\nFinish\n(2)\nmerging\nthe\ntwo \nimplementations\nJune\n27\n-\nJuly\n3 \n[\nWeek\n5\n]\nMilestone\n#3\n\u25cf\nComplete\n(3)\nsimulate_hoi \nfunction\nJuly\n4\n-\nJuly\n10 \n[\nWeek\n6\n]\nMilestone\n#4\n[Mid\n-\nterm\nevaluation]\n\u25cf\nDiscuss\nwith\nmentors\nthe\nmore \npreferred\nof\nXGI\nand\nHyperNetX \n\u25cf\nWrite\nthe\ncode\nfor\nplotting\nthe \nHOIs\nJuly\n11\n-\nJuly\n24", "doc_id": "72692f76-a6cf-4a10-b77b-257c697543b8", "embedding": null, "doc_hash": "5b4e40b73d0c58038efe10ca9be573f6b5a33d1f455763d4615b572404950cb6", "extra_info": null, "node_info": {"start": 55091, "end": 55565}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "0c2545b6-8740-40fd-b8db-870c8a3f14bb", "3": "2e2b3abf-c21c-4f13-ac2e-f3907ca8da40"}, "__type__": "1"}, "2e2b3abf-c21c-4f13-ac2e-f3907ca8da40": {"text": "\nand\nJax\nimplementations \n\u25cf\nFinish\n(2)\nmerging\nthe\ntwo \nimplementations\nJune\n27\n-\nJuly\n3 \n[\nWeek\n5\n]\nMilestone\n#3\n\u25cf\nComplete\n(3)\nsimulate_hoi \nfunction\nJuly\n4\n-\nJuly\n10 \n[\nWeek\n6\n]\nMilestone\n#4\n[Mid\n-\nterm\nevaluation]\n\u25cf\nDiscuss\nwith\nmentors\nthe\nmore \npreferred\nof\nXGI\nand\nHyperNetX \n\u25cf\nWrite\nthe\ncode\nfor\nplotting\nthe \nHOIs\nJuly\n11\n-\nJuly\n24 \n[\nWeek\n7\nand\nWeek\n8\n]\n\u25cf\nUnderstand\nFrites\u2019\nrequirements \nfor\nintegration\n\u25cf\nMake\nchanges\nto\nthe\ncode\nas\nper \nFrites\u2019\nformat", "doc_id": "2e2b3abf-c21c-4f13-ac2e-f3907ca8da40", "embedding": null, "doc_hash": "e5dfa958ec45a3fa012ed830922b42602e4d224a38813aa9b54a33662ca95da3", "extra_info": null, "node_info": {"start": 55640, "end": 56104}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "72692f76-a6cf-4a10-b77b-257c697543b8", "3": "ebe8fbab-207b-4c07-8cab-e26ebf613926"}, "__type__": "1"}, "ebe8fbab-207b-4c07-8cab-e26ebf613926": {"text": "\nfunction\nJuly\n4\n-\nJuly\n10 \n[\nWeek\n6\n]\nMilestone\n#4\n[Mid\n-\nterm\nevaluation]\n\u25cf\nDiscuss\nwith\nmentors\nthe\nmore \npreferred\nof\nXGI\nand\nHyperNetX \n\u25cf\nWrite\nthe\ncode\nfor\nplotting\nthe \nHOIs\nJuly\n11\n-\nJuly\n24 \n[\nWeek\n7\nand\nWeek\n8\n]\n\u25cf\nUnderstand\nFrites\u2019\nrequirements \nfor\nintegration\n\u25cf\nMake\nchanges\nto\nthe\ncode\nas\nper \nFrites\u2019\nformat \n\u25cf\nCreate\na\npull\nrequest\nJuly\n25\n-\nJuly\n31 \n[\nWeek\n9\n]\n\u25cf\nMake\nchanges\nif\nany, \ncommented\non\nthe\nFrites\u2019\nPR \n\u25cf\nPR\nshould\nget\nmerged\nAugust\n1\n-\nAugust\n14", "doc_id": "ebe8fbab-207b-4c07-8cab-e26ebf613926", "embedding": null, "doc_hash": "d6509c94c1fa554f0f63f7f7ad021a17b2390fe16f7eead382032d685f95d8ec", "extra_info": null, "node_info": {"start": 56122, "end": 56596}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "2e2b3abf-c21c-4f13-ac2e-f3907ca8da40", "3": "e1c2a299-0d27-48ab-90d1-0e7ebaf39460"}, "__type__": "1"}, "e1c2a299-0d27-48ab-90d1-0e7ebaf39460": {"text": "\n\u25cf\nWrite\nthe\ncode\nfor\nplotting\nthe \nHOIs\nJuly\n11\n-\nJuly\n24 \n[\nWeek\n7\nand\nWeek\n8\n]\n\u25cf\nUnderstand\nFrites\u2019\nrequirements \nfor\nintegration\n\u25cf\nMake\nchanges\nto\nthe\ncode\nas\nper \nFrites\u2019\nformat \n\u25cf\nCreate\na\npull\nrequest\nJuly\n25\n-\nJuly\n31 \n[\nWeek\n9\n]\n\u25cf\nMake\nchanges\nif\nany, \ncommented\non\nthe\nFrites\u2019\nPR \n\u25cf\nPR\nshould\nget\nmerged\nAugust\n1\n-\nAugust\n14 \n[\nWeek\n10\nand\nWeek\n11\n]\nMilestone\n#5\n\u25cf\nStart\nwith\nthe\ndocumentation\nof \nthe\nproject\nand\nunit\ntests \n\u25cf\nFinish\nwith\na\nuser-friendly ,", "doc_id": "e1c2a299-0d27-48ab-90d1-0e7ebaf39460", "embedding": null, "doc_hash": "6f7d54a2a2e7c210eff38f0b0f3671923548edc515ac004fabd20695e4dceb57", "extra_info": null, "node_info": {"start": 56586, "end": 57053}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "ebe8fbab-207b-4c07-8cab-e26ebf613926", "3": "6103f75a-b5ed-4b74-9904-52f1958f7d69"}, "__type__": "1"}, "6103f75a-b5ed-4b74-9904-52f1958f7d69": {"text": "\nfor\nintegration\n\u25cf\nMake\nchanges\nto\nthe\ncode\nas\nper \nFrites\u2019\nformat \n\u25cf\nCreate\na\npull\nrequest\nJuly\n25\n-\nJuly\n31 \n[\nWeek\n9\n]\n\u25cf\nMake\nchanges\nif\nany, \ncommented\non\nthe\nFrites\u2019\nPR \n\u25cf\nPR\nshould\nget\nmerged\nAugust\n1\n-\nAugust\n14 \n[\nWeek\n10\nand\nWeek\n11\n]\nMilestone\n#5\n\u25cf\nStart\nwith\nthe\ndocumentation\nof \nthe\nproject\nand\nunit\ntests \n\u25cf\nFinish\nwith\na\nuser-friendly , \neasy-to-comprehend\nreadme\nAugust\n15\n-\nAugust\n21 \n[\nWeek\n12\n]\nBuffer\nof\none\nweek\n\u25cf\nComplete\nany\npreviously \nmentioned\ntasks\nin\ncase\nof\na", "doc_id": "6103f75a-b5ed-4b74-9904-52f1958f7d69", "embedding": null, "doc_hash": "cedd7ff1265e59322d3c4b508fc81af906ab51013a2be4f322c3b7cddf658b36", "extra_info": null, "node_info": {"start": 57038, "end": 57526}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "e1c2a299-0d27-48ab-90d1-0e7ebaf39460", "3": "0eba9a57-7685-476c-9a68-b896b092bdb3"}, "__type__": "1"}, "0eba9a57-7685-476c-9a68-b896b092bdb3": {"text": "\ncommented\non\nthe\nFrites\u2019\nPR \n\u25cf\nPR\nshould\nget\nmerged\nAugust\n1\n-\nAugust\n14 \n[\nWeek\n10\nand\nWeek\n11\n]\nMilestone\n#5\n\u25cf\nStart\nwith\nthe\ndocumentation\nof \nthe\nproject\nand\nunit\ntests \n\u25cf\nFinish\nwith\na\nuser-friendly , \neasy-to-comprehend\nreadme\nAugust\n15\n-\nAugust\n21 \n[\nWeek\n12\n]\nBuffer\nof\none\nweek\n\u25cf\nComplete\nany\npreviously \nmentioned\ntasks\nin\ncase\nof\na \nbacklog\nAugust\n22\n-\nAugust\n28 \n[\nWeek\n13\n]\nProject\nSubmission\n\u25cf\nMake\nimprovisations\nif\nany, \nsuggested\nby\nmentors", "doc_id": "0eba9a57-7685-476c-9a68-b896b092bdb3", "embedding": null, "doc_hash": "9052cdb04c95c72edca9a954562f920796c3e35aeafae00d807f32722f5c1ed1", "extra_info": null, "node_info": {"start": 57534, "end": 57992}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "6103f75a-b5ed-4b74-9904-52f1958f7d69", "3": "bf8f1752-9480-4d34-ba53-abbd87a5e788"}, "__type__": "1"}, "bf8f1752-9480-4d34-ba53-abbd87a5e788": {"text": "\n[\nWeek\n10\nand\nWeek\n11\n]\nMilestone\n#5\n\u25cf\nStart\nwith\nthe\ndocumentation\nof \nthe\nproject\nand\nunit\ntests \n\u25cf\nFinish\nwith\na\nuser-friendly , \neasy-to-comprehend\nreadme\nAugust\n15\n-\nAugust\n21 \n[\nWeek\n12\n]\nBuffer\nof\none\nweek\n\u25cf\nComplete\nany\npreviously", "doc_id": "bf8f1752-9480-4d34-ba53-abbd87a5e788", "embedding": null, "doc_hash": "e6713ea0e4e1527d48b091b900664e8fc7e579261ea043956cb89816df310ddf", "extra_info": null, "node_info": {"start": 57953, "end": 58192}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "0eba9a57-7685-476c-9a68-b896b092bdb3", "3": "0b8a211f-84ff-487c-8097-605021b609de"}, "__type__": "1"}, "0b8a211f-84ff-487c-8097-605021b609de": {"text": "\nmentioned\ntasks\nin\ncase\nof\na \nbacklog\nAugust\n22\n-\nAugust\n28 \n[\nWeek\n13\n]\nProject\nSubmission\n\u25cf\nMake\nimprovisations\nif\nany, \nsuggested\nby\nmentors", "doc_id": "0b8a211f-84ff-487c-8097-605021b609de", "embedding": null, "doc_hash": "5cdeaeb60db11e55a34fc629ebb836abb553e483e0f8ce23599c15473791eca6", "extra_info": null, "node_info": {"start": 58568, "end": 58712}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "bf8f1752-9480-4d34-ba53-abbd87a5e788", "3": "808fb9de-29e5-4b3b-bd44-955ac259fac5"}, "__type__": "1"}, "808fb9de-29e5-4b3b-bd44-955ac259fac5": {"text": "\nmentioned\ntasks\nin\ncase\nof\na \nbacklog\nAugust\n22\n-\nAugust\n28 \n[\nWeek\n13\n]\nProject\nSubmission\n\u25cf\nMake\nimprovisations\nif\nany, \nsuggested\nby\nmentors", "doc_id": "808fb9de-29e5-4b3b-bd44-955ac259fac5", "embedding": null, "doc_hash": "5cdeaeb60db11e55a34fc629ebb836abb553e483e0f8ce23599c15473791eca6", "extra_info": null, "node_info": {"start": 58572, "end": 58716}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "0b8a211f-84ff-487c-8097-605021b609de", "3": "73bc13fa-3b49-434c-b612-842f6362b5c2"}, "__type__": "1"}, "73bc13fa-3b49-434c-b612-842f6362b5c2": {"text": "\n\u25cf\nSubmit\nthe\nproject\n4.\nCandidate\nDetails\n4.1\nWhy\nam\nI\nmotivated\nby\nthis\nproject?\nWhat\nmotivates\nme\nthe\nmost\nis\nthe\nproblem\nstatement\nitself.\nOptimizing\ncodes\nand\ndata\nanalysis\nis\nsomething\nI\nam\nvery\nfond\nof.\nHence,\nthe\nidea\nof\noptimization\nusing\nparallel\ncomputations\nand\nother\nmethods\nafter\nresearching\nabout\npros\nand\ncons\nof\neach\npiqued\nmy\ninterest.\nAlso,\nit\nhas\nbeen\nproven\nthat\nhigher-order\ninteractions\nare\ninherent\nproperties\nof\ncortical\ndynamics\nand\nsuggest\na\nsimple\nsolution\nto\novercome\nthe\napparent\nformidable\ncomplexity\npreviously\nthought\nto\nbe\nintrinsic\nto\nthose\ninteractions.\nThis\nmakes\nthe\nproject\neven\nmore\nimportant.\nAdditionally , I have always admired open", "doc_id": "73bc13fa-3b49-434c-b612-842f6362b5c2", "embedding": null, "doc_hash": "e9a983ab372aa7235e5dd9117803269e13c142cef44e53f3f06b68a35d17b2e8", "extra_info": null, "node_info": {"start": 58858, "end": 59533}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "808fb9de-29e5-4b3b-bd44-955ac259fac5", "3": "5382058e-510b-4f65-b630-d3d29020c2ed"}, "__type__": "1"}, "5382058e-510b-4f65-b630-d3d29020c2ed": {"text": ", I have always admired open source communities and wanted to contribute to them ever since I came across the idea of free and open source software (FOSS). 4.2 Why am I a good candidate for this project? \u25cf I have a good amount of experience in python, specifically NumPy. Hence, I will be able to adapt to the project\u2019s codebase and make contributions easily. \u25cf I understand that I need to be proficient in using Jax. Being a keen and quick learner, I feel I can adapt to using newer libraries fast and with ease. \u25cf I am disciplined and hence, can be counted on to start a project and finish it perfectly before its deadline. 4.3 Past experiences I am a second year (sophomore) undergraduate student pursuing a Bachelor of Technology degree in Computer Engineering in VJTI, Mumbai. I have experience in Python, C++, ROS, web development and computer vision. I am an active member of Society of Robotics and Automation (SRA), a club in my university. We conduct workshops,", "doc_id": "5382058e-510b-4f65-b630-d3d29020c2ed", "embedding": null, "doc_hash": "0aa12f3417a436f47f3d4f4c565072018f4a7b0ffa7f96e0dde52917763bd449", "extra_info": null, "node_info": {"start": 59511, "end": 60482}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "73bc13fa-3b49-434c-b612-842f6362b5c2", "3": "d787129c-ad2c-4fc4-816d-548231b08182"}, "__type__": "1"}, "d787129c-ad2c-4fc4-816d-548231b08182": {"text": "a good amount of experience in python, specifically NumPy. Hence, I will be able to adapt to the project\u2019s codebase and make contributions easily. \u25cf I understand that I need to be proficient in using Jax. Being a keen and quick learner, I feel I can adapt to using newer libraries fast and with ease. \u25cf I am disciplined and hence, can be counted on to start a project and finish it perfectly before its deadline. 4.3 Past experiences I am a second year (sophomore) undergraduate student pursuing a Bachelor of Technology degree in Computer Engineering in VJTI, Mumbai. I have experience in Python, C++, ROS, web development and computer vision. I am an active member of Society of Robotics and Automation (SRA), a club in my university. We conduct workshops, seminars, competitions focusing on Robotics, Machine Learning and Computer Vision. These are some of my projects and contributions: \u25cf SLAM - OpenCV - Navigation [Sept 2022 - Nov 2022] 1. A simulation of a Bot", "doc_id": "d787129c-ad2c-4fc4-816d-548231b08182", "embedding": null, "doc_hash": "bc23e8386f5f3ebdf5e2f1602e350e3b84e95ed2e14c8b0b42fdcd9edd33bcfe", "extra_info": null, "node_info": {"start": 59878, "end": 60845}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "5382058e-510b-4f65-b630-d3d29020c2ed", "3": "a635f1e9-6091-43bb-b86c-c83251d8db8f"}, "__type__": "1"}, "a635f1e9-6091-43bb-b86c-c83251d8db8f": {"text": "a keen and quick learner, I feel I can adapt to using newer libraries fast and with ease. \u25cf I am disciplined and hence, can be counted on to start a project and finish it perfectly before its deadline. 4.3 Past experiences I am a second year (sophomore) undergraduate student pursuing a Bachelor of Technology degree in Computer Engineering in VJTI, Mumbai. I have experience in Python, C++, ROS, web development and computer vision. I am an active member of Society of Robotics and Automation (SRA), a club in my university. We conduct workshops, seminars, competitions focusing on Robotics, Machine Learning and Computer Vision. These are some of my projects and contributions: \u25cf SLAM - OpenCV - Navigation [Sept 2022 - Nov 2022] 1. A simulation of a Bot in Gazebo and RViz which creates a map of its environment and navigates through it while avoiding obstacles . 2. Detected surroundings using 2 sensors,(1) kinect, a depth camera and a", "doc_id": "a635f1e9-6091-43bb-b86c-c83251d8db8f", "embedding": null, "doc_hash": "96531dc04964a94f70a069c8f252155e9679e3a5f018a6cde4ec01ecc00c65c3", "extra_info": null, "node_info": {"start": 60846, "end": 61786}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "d787129c-ad2c-4fc4-816d-548231b08182", "3": "c5b215a2-3850-4f1b-86c5-e536d0f3a78b"}, "__type__": "1"}, "c5b215a2-3850-4f1b-86c5-e536d0f3a78b": {"text": "4.3 Past experiences I am a second year (sophomore) undergraduate student pursuing a Bachelor of Technology degree in Computer Engineering in VJTI, Mumbai. I have experience in Python, C++, ROS, web development and computer vision. I am an active member of Society of Robotics and Automation (SRA), a club in my university. We conduct workshops, seminars, competitions focusing on Robotics, Machine Learning and Computer Vision. These are some of my projects and contributions: \u25cf SLAM - OpenCV - Navigation [Sept 2022 - Nov 2022] 1. A simulation of a Bot in Gazebo and RViz which creates a map of its environment and navigates through it while avoiding obstacles . 2. Detected surroundings using 2 sensors,(1) kinect, a depth camera and a (2) lidar sensor. 3. Data obtained from the lidar (distance of obstacle detected) was used to create a binary map ie. The spaces where the lidar rays couldn\u2019t reach were marked as 1", "doc_id": "c5b215a2-3850-4f1b-86c5-e536d0f3a78b", "embedding": null, "doc_hash": "a34a843e9a153c49591192fc5604e4fd53d288749bd2cbcf811916ecebde65f7", "extra_info": null, "node_info": {"start": 61797, "end": 62717}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "a635f1e9-6091-43bb-b86c-c83251d8db8f", "3": "1984ba9a-f84a-4750-b772-5783cef48a52"}, "__type__": "1"}, "1984ba9a-f84a-4750-b772-5783cef48a52": {"text": "and computer vision. I am an active member of Society of Robotics and Automation (SRA), a club in my university. We conduct workshops, seminars, competitions focusing on Robotics, Machine Learning and Computer Vision. These are some of my projects and contributions: \u25cf SLAM - OpenCV - Navigation [Sept 2022 - Nov 2022] 1. A simulation of a Bot in Gazebo and RViz which creates a map of its environment and navigates through it while avoiding obstacles . 2. Detected surroundings using 2 sensors,(1) kinect, a depth camera and a (2) lidar sensor. 3. Data obtained from the lidar (distance of obstacle detected) was used to create a binary map ie. The spaces where the lidar rays couldn\u2019t reach were marked as 1 denoting non-accessible regions which was then converted to a yaml file (human-readable format of the map). 4. Implemented navigation using odometry, goal pose and the map generated. \u25cf Blob detection using opencv in C++", "doc_id": "1984ba9a-f84a-4750-b772-5783cef48a52", "embedding": null, "doc_hash": "e5c2b4f95180f1ee2b5bf1c02d75d44d3423a988fd5b4b4399a863645a71168b", "extra_info": null, "node_info": {"start": 62748, "end": 63677}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "c5b215a2-3850-4f1b-86c5-e536d0f3a78b", "3": "19110383-7ae2-45be-865f-b1559f09f475"}, "__type__": "1"}, "19110383-7ae2-45be-865f-b1559f09f475": {"text": "some of my projects and contributions: \u25cf SLAM - OpenCV - Navigation [Sept 2022 - Nov 2022] 1. A simulation of a Bot in Gazebo and RViz which creates a map of its environment and navigates through it while avoiding obstacles . 2. Detected surroundings using 2 sensors,(1) kinect, a depth camera and a (2) lidar sensor. 3. Data obtained from the lidar (distance of obstacle detected) was used to create a binary map ie. The spaces where the lidar rays couldn\u2019t reach were marked as 1 denoting non-accessible regions which was then converted to a yaml file (human-readable format of the map). 4. Implemented navigation using odometry, goal pose and the map generated. \u25cf Blob detection using opencv in C++ [Mar 2023] Detection of the region of an image in which some properties like intensity or color are approximately constant and drawing contours around it for identification. Demo of detection \u25cf E-Yantra Robotics Competition - IIT Bombay", "doc_id": "19110383-7ae2-45be-865f-b1559f09f475", "embedding": null, "doc_hash": "c9d7b41e5cb3d00dd7774a8096111772f0975c341a28e70d334fbbf0948bf1cf", "extra_info": null, "node_info": {"start": 63685, "end": 64623}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "1984ba9a-f84a-4750-b772-5783cef48a52", "3": "e08861cb-d87f-4133-b68c-f469d0cdf8ee"}, "__type__": "1"}, "e08861cb-d87f-4133-b68c-f469d0cdf8ee": {"text": "through it while avoiding obstacles . 2. Detected surroundings using 2 sensors,(1) kinect, a depth camera and a (2) lidar sensor. 3. Data obtained from the lidar (distance of obstacle detected) was used to create a binary map ie. The spaces where the lidar rays couldn\u2019t reach were marked as 1 denoting non-accessible regions which was then converted to a yaml file (human-readable format of the map). 4. Implemented navigation using odometry, goal pose and the map generated. \u25cf Blob detection using opencv in C++ [Mar 2023] Detection of the region of an image in which some properties like intensity or color are approximately constant and drawing contours around it for identification. Demo of detection \u25cf E-Yantra Robotics Competition - IIT Bombay [Sept 2023 - Jan 2023] Took part in the robotics competition, E-yantra organized by IIT-Bombay under the theme Krishi Bot. Our team was selected among the top 10 teams from over 250 nationally .", "doc_id": "e08861cb-d87f-4133-b68c-f469d0cdf8ee", "embedding": null, "doc_hash": "32334cb9374068351d6eaedea52dc037622263989ae53a793c7bfbf25321bba9", "extra_info": null, "node_info": {"start": 64576, "end": 65521}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "19110383-7ae2-45be-865f-b1559f09f475", "3": "e56ec3b5-321e-4825-81d0-ab894e33618c"}, "__type__": "1"}, "e56ec3b5-321e-4825-81d0-ab894e33618c": {"text": "detected) was used to create a binary map ie. The spaces where the lidar rays couldn\u2019t reach were marked as 1 denoting non-accessible regions which was then converted to a yaml file (human-readable format of the map). 4. Implemented navigation using odometry, goal pose and the map generated. \u25cf Blob detection using opencv in C++ [Mar 2023] Detection of the region of an image in which some properties like intensity or color are approximately constant and drawing contours around it for identification. Demo of detection \u25cf E-Yantra Robotics Competition - IIT Bombay [Sept 2023 - Jan 2023] Took part in the robotics competition, E-yantra organized by IIT-Bombay under the theme Krishi Bot. Our team was selected among the top 10 teams from over 250 nationally . 1. Implemented path-planning techniques for accurate navigation of a robot in a greenhouse. 2. Accurately detected fruits of different colours via Image Processing techniques like Convolution and Filtering. 3. Estimated correctly", "doc_id": "e56ec3b5-321e-4825-81d0-ab894e33618c", "embedding": null, "doc_hash": "614f0caab9ea17c1e711b0872eb0629abf1ebf0867093364d8832dcff5007afd", "extra_info": null, "node_info": {"start": 65515, "end": 66506}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "e08861cb-d87f-4133-b68c-f469d0cdf8ee", "3": "ac687ab7-3ba6-48dc-89a4-6d0d7e3a66c8"}, "__type__": "1"}, "ac687ab7-3ba6-48dc-89a4-6d0d7e3a66c8": {"text": "4. Implemented navigation using odometry, goal pose and the map generated. \u25cf Blob detection using opencv in C++ [Mar 2023] Detection of the region of an image in which some properties like intensity or color are approximately constant and drawing contours around it for identification. Demo of detection \u25cf E-Yantra Robotics Competition - IIT Bombay [Sept 2023 - Jan 2023] Took part in the robotics competition, E-yantra organized by IIT-Bombay under the theme Krishi Bot. Our team was selected among the top 10 teams from over 250 nationally . 1. Implemented path-planning techniques for accurate navigation of a robot in a greenhouse. 2. Accurately detected fruits of different colours via Image Processing techniques like Convolution and Filtering. 3. Estimated correctly the depth and coordinates of the centroid of detected fruits to pick them efficiently. 4. Segregated red and yellow fruits using robotic arm manipulation. 4.4 When will I be available to run this project? \u25cf Once coding", "doc_id": "ac687ab7-3ba6-48dc-89a4-6d0d7e3a66c8", "embedding": null, "doc_hash": "91236120fd96d479b217e3109acdeb1b0b8e0dbda470090013201cdcdc990124", "extra_info": null, "node_info": {"start": 66489, "end": 67481}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "e56ec3b5-321e-4825-81d0-ab894e33618c", "3": "b5bb3178-3c4d-4d79-97af-a601919e8b3c"}, "__type__": "1"}, "b5bb3178-3c4d-4d79-97af-a601919e8b3c": {"text": "and drawing contours around it for identification. Demo of detection \u25cf E-Yantra Robotics Competition - IIT Bombay [Sept 2023 - Jan 2023] Took part in the robotics competition, E-yantra organized by IIT-Bombay under the theme Krishi Bot. Our team was selected among the top 10 teams from over 250 nationally . 1. Implemented path-planning techniques for accurate navigation of a robot in a greenhouse. 2. Accurately detected fruits of different colours via Image Processing techniques like Convolution and Filtering. 3. Estimated correctly the depth and coordinates of the centroid of detected fruits to pick them efficiently. 4. Segregated red and yellow fruits using robotic arm manipulation. 4.4 When will I be available to run this project? \u25cf Once coding begins, I will work dedicatedly for at least 4-5 hours on weekdays (and 6-8 on weekends ) until the completion of the project. \u25cf After the submission of my proposal (on or before April 4), I will start", "doc_id": "b5bb3178-3c4d-4d79-97af-a601919e8b3c", "embedding": null, "doc_hash": "0b7c7f826f02210633c3e3fe5247961d6e2c927f651739f7c3c68ed2c64d0eaa", "extra_info": null, "node_info": {"start": 67497, "end": 68456}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "ac687ab7-3ba6-48dc-89a4-6d0d7e3a66c8", "3": "b2af3f46-faa2-437c-acea-8a12551add2c"}, "__type__": "1"}, "b2af3f46-faa2-437c-acea-8a12551add2c": {"text": "organized by IIT-Bombay under the theme Krishi Bot. Our team was selected among the top 10 teams from over 250 nationally . 1. Implemented path-planning techniques for accurate navigation of a robot in a greenhouse. 2. Accurately detected fruits of different colours via Image Processing techniques like Convolution and Filtering. 3. Estimated correctly the depth and coordinates of the centroid of detected fruits to pick them efficiently. 4. Segregated red and yellow fruits using robotic arm manipulation. 4.4 When will I be available to run this project? \u25cf Once coding begins, I will work dedicatedly for at least 4-5 hours on weekdays (and 6-8 on weekends ) until the completion of the project. \u25cf After the submission of my proposal (on or before April 4), I will start researching on optimization techniques and go through tutorials of XGI and HyperNetX (so that, I am prepared better at the time of implementation) \u25cf When the coding period begins (May 29), I have my end semesters which", "doc_id": "b2af3f46-faa2-437c-acea-8a12551add2c", "embedding": null, "doc_hash": "9f44b5795f5cb516de2548982b7a838f663ea3349947c51d4b0000a25b4ddba6", "extra_info": null, "node_info": {"start": 68449, "end": 69442}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "b5bb3178-3c4d-4d79-97af-a601919e8b3c", "3": "f26418f9-06f7-47b6-8d59-5f4fb23a13ee"}, "__type__": "1"}, "f26418f9-06f7-47b6-8d59-5f4fb23a13ee": {"text": "2. Accurately detected fruits of different colours via Image Processing techniques like Convolution and Filtering. 3. Estimated correctly the depth and coordinates of the centroid of detected fruits to pick them efficiently. 4. Segregated red and yellow fruits using robotic arm manipulation. 4.4 When will I be available to run this project? \u25cf Once coding begins, I will work dedicatedly for at least 4-5 hours on weekdays (and 6-8 on weekends ) until the completion of the project. \u25cf After the submission of my proposal (on or before April 4), I will start researching on optimization techniques and go through tutorials of XGI and HyperNetX (so that, I am prepared better at the time of implementation) \u25cf When the coding period begins (May 29), I have my end semesters which will last until June 1. \u25cf After June 1, I promise to work more to compensate for the three days I would not have worked on due to my exams (May 29,30 and June 1).", "doc_id": "f26418f9-06f7-47b6-8d59-5f4fb23a13ee", "embedding": null, "doc_hash": "57dda612d9ed7dda357e66c03508c419e6167678cb6eec8b68efac92c1728bf2", "extra_info": null, "node_info": {"start": 69312, "end": 70252}, "relationships": {"1": "12ae1ab6-3e5a-48e5-bf06-1017ca69372e", "2": "b2af3f46-faa2-437c-acea-8a12551add2c"}, "__type__": "1"}}, "ref_doc_info": {"12ae1ab6-3e5a-48e5-bf06-1017ca69372e": {"doc_hash": "6b4c8cf042745a5eb2149c7130ae1e7cb46a537662a7833dc015484271902e07"}, "1bce21cc-6292-486f-b552-aa583fe1ae6e": {"doc_hash": "2d0aca42d8fda6e9df96eec597161751e4b886bb43d41a9c69992f48cad4ce35"}, "827f06d0-137b-4ddb-9ad8-2ba188209398": {"doc_hash": "1e2157e487dd7b6379ccca97413da79da5718fb523214cce5e0e5fee3f2580b8"}, "e162b64c-29fa-4a2a-86c9-b6bd3fc7575d": {"doc_hash": "a4c02707d121333c02d56975ad80056dea7e68ab3df45b324b24fdadf4471425"}, "d635ea55-a1c9-4bb3-84a4-530cf2f92c37": {"doc_hash": "b0f2fed833716d7a06739f2becb4aa58a264aa56bf712f6139f53455616d8c4f"}, "e16f4b91-966c-4ba7-93c0-2c66dafbaf01": {"doc_hash": "9e1e203d356e08433889e604b710e49806253520095fc0e201a93ae7dcb94d51"}, "99adb257-9a82-495e-8767-98455ad07f1f": {"doc_hash": "cbb116eb6a3b223a990bec949426a91bf696678dda12101dfb8fd221b9819fda"}, "ee759e11-d017-46a2-a634-00e5823a9768": {"doc_hash": "6a9e683c5e55b72b2081609c3e2fe804f103c9698bde773f4421cfebad068203"}, "d1a56696-a130-4c57-9765-49e55bb82d77": {"doc_hash": "92c0550a19efdc3d8ee443ee071a32eb181a05ed28420d6c303cc20181978eed"}, "42927124-7cd0-46f7-81e2-2e4e6a6093b9": {"doc_hash": "e251bc0fb9c8b2861a09b617d4df408507780075be6d3b578af5617eab4960ee"}, "cb01e739-b50f-4a19-ae93-f5e8f3928ff9": {"doc_hash": "35df26efbb8500111240d90ccda4c86d9a3043d947c3a3483f70c0ba19813b0e"}, "214e3571-64dd-4b3b-bcf2-bfe87b052dca": {"doc_hash": "87584bf8acf55f777e28fe3acabda5ca275d49874f06e58a4c42aaf8d5ddf4c3"}, "ddda3c00-63d6-444a-accc-6c5829cb8b25": {"doc_hash": "402c822ab308b28e86dc7d42465f2ddcbf0262add0cf69e66f824110fcea4421"}, "94a7b568-ce3c-46f2-9fd7-1bb361b5a96f": {"doc_hash": "b170c5a04833a06f2f20a9d4808cf4caa1e735b7b33b3b08b7ca34070a3bb494"}, "e3710436-e0b6-49de-94f3-dc99d687ee29": {"doc_hash": "4cb1a21a1a5a9acd311267d084e59f4a172652d46f90e087e677309c775514e5"}, "dbeb0e92-bf8f-45cc-a403-f75cc856b76b": {"doc_hash": "47f80256ca63159d47b9ab483302e201facc3acd7e7b8f0776ed8bfe732410c9"}, "66d62401-d2e4-4a91-8852-48a67e463731": {"doc_hash": "36444d55f6a041ca04b4a9d2a9f25e10a3eeb390e11bf8064f9912664bdffdc6"}, "29d3af5c-2481-4742-8354-89641027b9fd": {"doc_hash": "9f187d861bbd08643c38a9c934e7e53d7d444c5654e885630bf4ad542b223d57"}, "1956f39b-642b-4791-a2cd-a71e69f9118a": {"doc_hash": "33c37de8c8ef29dd5b16922521994a4a296e4bbc93e495bb2693848fac2e89c8"}, "4e497f64-4b7b-45fd-b7a3-5092d0311430": {"doc_hash": "960e4464308f041d11b6fceea2be074f14fabd74d5770587e99f6f70d611e72f"}, "371d1e90-3f53-44df-9856-1b02e4f948fe": {"doc_hash": "7e2e7b1b8476f024590d4b2a4be53fa4bf4ca0eba71acb39bcfa00bf5844e22d"}, "c8762864-03ec-4fd8-8cf8-fd5fe9b5c591": {"doc_hash": "abb557a1748621cc73cfb11c51545999d5af5dba8e5c8a5ad5d04c594587c12d"}, "07a4a574-4fea-4c85-83f0-2dbb6e9ff97a": {"doc_hash": "4f3483fe3523915ba326478df0d49ca5a8be111092c1b498173329b84bccc5d7"}, "f627a822-8162-4d90-b3d1-dbc42861a43f": {"doc_hash": "246ddd3114d640a52e941693e36482421c8884df90e9f6a2883da4a33287e238"}, "e704e61b-747f-4863-95dc-17332d8d40c6": {"doc_hash": "5f306e83415705bc85be829fcf85073cb2bccfd9f3c59206a5a29c0cc16cac0e"}, "dc45cb06-0d54-4f47-a5f3-0347a42f7e01": {"doc_hash": "3aebfb07dbeaecfa93b0e600d4a59a772dbdb1f489d65e070022f4e5a2789f23"}, "8dd41955-2532-48dd-832a-dff5d755e0ce": {"doc_hash": "83dece7913cf929b57c38cdab395d630e69b94de5c1394c8700388774df4ad08"}, "9741174c-6633-4d61-99db-80ed23bf6dc5": {"doc_hash": "910686dda07f0b3ae826716f1726805792bf146a1ba693e5a46486bef7adb1e1"}, "e9f18049-f1ef-4b64-93b3-50575e34cafb": {"doc_hash": "837b26e986f8d9d777f3889dc18e7acb5c0d55da92b38cf9cedc56a0fd092939"}, "fde0fbd4-1866-433e-9d7a-a7aa904b038b": {"doc_hash": "89247c4a4c1352268b4958df91e789023dd347bc1f8b06629f201333751c7c11"}, "e3e20d8d-48e7-4deb-b194-fe2d8e01a463": {"doc_hash": "33ca6b9066dfb90a848601d925a6734e18c6358d6cd0f794cd072ce1a346f7ec"}, "5b8b2298-809f-4c6f-97d8-e6ad1e588be2": {"doc_hash": "501e0f69381c008e20263f218bc51ca279cd0a4495b7eeb110978752f92d2f47"}, "14a17423-13f0-4c7b-b557-141645ae59cf": {"doc_hash": "833983f1a6436ee668e84cf9fdeb9c9757f9a5bab2421af103fd9e9681942d58"}, "09713ad0-2cca-4e8d-a2d2-974cb8e356fe": {"doc_hash": "48062555dd8f2557ea9d659021ae9d3275cf13dd9b75afc6c3151882f7a281cb"}, "e479e673-2a0f-456e-aeb6-dd1cf188203c": {"doc_hash": "b33c959a4a1d628a083ca5ac942c8000a48a43e9635f8e4136373e7873d5ae3f"}, "81efe060-3e53-4e1e-bcdb-6b9aff005be7": {"doc_hash": "2195d8b4cfd8ae75c3cadea6be1b4c816016aeee744750495bafc877ecef05b8"}, "5738e669-dbd5-4035-aca1-baeaba4bcec9": {"doc_hash": "0029e8d47fae6c86a0640c10f668dc95720d8a6a1ab9091906dc7ca99f6731a5"}, "f2da7778-7ac7-48e6-8124-0c298d652330": {"doc_hash": "83b5adb3250b1da85975045912a87536576c22cd42fc3ceec48987630e62ebef"}, "6d5169ed-f5e9-43b7-8c75-b56259949947": {"doc_hash": "ab1435f23b65b248e85a1045a59fc19acb2318c34835ca1059009dc534071d83"}, "c694ab14-5d44-471d-b5ef-97a83fcd5d30": {"doc_hash": "cf04268f11cc68b7147af71a3b5abb5b3eb2b0e868157f0a6438072890ffa081"}, "65fd0866-608c-4e90-96a5-46f4c9120cc2": {"doc_hash": "a380a67ef353d659bf1f567b0798a44bf82c9cd334ffa25cdb14bda0e0d83c62"}, "b32875b6-44da-419b-b329-acde6729f7fb": {"doc_hash": "c6becb529fbe1e8a28fbac2a6587e0fb1bcf00d5c9f24aaf97e12672f8d7bce0"}, "4c94d296-be9d-4882-897b-f1c2e160594f": {"doc_hash": "62b229301dfd8ef4415b126a8ec38627fd2a2151fd314f42ccf1393cc8e931b0"}, "262cf7a1-114f-41b9-8605-1de677babe5b": {"doc_hash": "56ec6deb37575534c20697fb2174d8a574c20dfc23344b1cf7e4aacfb4d6b461"}, "809a1279-2d99-4487-8e4e-a0b66ac0aa75": {"doc_hash": "a46e37a29698f1be641a08265997491d6e1dc3232851c4fb9469b31a89bb83e8"}, "b07b0a20-8c4b-4b10-944f-6d278c3a73d3": {"doc_hash": "45a258cbbd564274b6d16dc12880010db250c6bda174ac8ab2fda984501db435"}, "fc793b9c-85bb-4e80-9577-2a9ed02b9487": {"doc_hash": "72614a9ac41ef519f853ad61d61237f9f75c875f078ce111b7477fad85299741"}, "8ec91488-f51b-47e5-844e-66ee93580447": {"doc_hash": "9802beca8ceda65cb95d527e513d071c31ed90e7963ab14301095e3bbb9c7ea2"}, "b37a9554-fc95-4c11-a1aa-61375bad250b": {"doc_hash": "5f432a1271cfaaef278a4c051c3536e9ccce5729a08d75ea039e5871ba2601a7"}, "6d30bdfa-f603-4428-be3f-d27fb323be36": {"doc_hash": "f1e449f1a1d3c5d0e7fba720eae52c2ec641e5db7a6aa32ddf6e1e3e768d2020"}, "6f112c29-d5ab-4c63-b201-01b9f3a7f354": {"doc_hash": "01f3b647ba879f0cabe523b704d6f121a99525f6066b38829afdb81c184f8c74"}, "2981ef25-c99b-411a-acf0-c94a8ecdc71f": {"doc_hash": "b6145986219c0ec56ba164e6b19253e5b402280151ec89c4092c4c9e68d77545"}, "9fe20c72-4216-4dd9-ad13-d554fb6764dd": {"doc_hash": "39dff425136ee6e53f19d503bcd0e7639904e65f4e9486ae024087f2fb4b2953"}, "7c82a23b-db71-4f6a-b3d0-e28139fde880": {"doc_hash": "9a32e7c1095b0db58f65f94ca1d822fda22289ce3881ea53dd34421e9e1f42e2"}, "bc73a9ad-9412-4e11-957f-8b7f34056979": {"doc_hash": "05ec8aad1824a5ad47c068ff464a6dd0ed422afcb20886157de4a7932bdcf827"}, "de5a1729-c464-45ac-80f5-cbd8583f0878": {"doc_hash": "de2f0c6c1aa3d72c205a4d273278c6ab59290ebc29de0006da025c6a0d22045f"}, "51baf38e-b5c2-438a-a541-cdf1e36abd24": {"doc_hash": "bb493a7d0646566b6d30d1bb31f1cba023b351b3f5ac39a05c71304849ccd44c"}, "bd7e5557-7704-48f1-bcca-193a8c573fd6": {"doc_hash": "427c10161f534ad9674328d4a5ef15a5279cdacf0046e31230841e28b22d84e8"}, "c376ecb7-3ec8-4607-acc4-0599366f85bf": {"doc_hash": "0f9f0374dea8988a748a549e1f3e5dc301d90144f1c9960e7d75c349712e2279"}, "fbb0bc3a-e161-48b5-8101-a4e6a93a1399": {"doc_hash": "2440b132882d7f55c2593889b127b42bd5334d43130197dbb3d4fc4b0b58132f"}, "61e90ff3-a68e-42d9-8470-eb822a05dce3": {"doc_hash": "b0c5949beda381cd301d1596f5686202817348f16f5fc9c8bac5c4e6e0213822"}, "0861d760-e8a9-47ea-a2b9-3856c5958f9b": {"doc_hash": "6df678cf75b0ff7746bad600a6ea26dfe4b46c3bb96b8f79227bf4ceb65fe244"}, "22632d94-c8cb-4c02-a811-1d0ddbeda6b9": {"doc_hash": "69a44c1f70a3a264be18a63f66950979ce24aa52bae2a59363dc4d7cdad317ae"}, "99ef7f4a-3e1b-4f21-adce-7e9d7b4f1185": {"doc_hash": "5acd7013a50315be3ecb06f8aea80aa64c050072999b2be06ee3e337b9e7d956"}, "5e7613fe-7d60-401c-a80e-9991dc3e55f6": {"doc_hash": "9a4fb46780da1fa3e3225d41dca5d6ff1f295e8f8e8981ea824cd3649574ed58"}, "943626f0-5f75-4025-ac64-ab4d3e0b240f": {"doc_hash": "1f5f126694e527f970ce1825136e1071fb68d8a4304f2d2b76a283358a38b070"}, "10b7ee5f-2341-40e4-af56-47c6aace71ff": {"doc_hash": "a586cecf747ac4e72b0684bcebdbefecb4267c063ece05176d3eabafdf78b389"}, "43f9205c-dfd9-4d3e-81ff-55d3579b0847": {"doc_hash": "5b491435084cb6aac142e508ea98e415558bb9677c3c9e7a78d799fe2e32fefa"}, "e25e0f29-b1b0-49ae-87ca-0bfd99804aac": {"doc_hash": "46b90199327ae8a4b7af52979cc838e9a62a6494a323fec6ae4bf21087b3f3e1"}, "2cb73adf-a6dc-4c31-ac56-3303670570f3": {"doc_hash": "efe3690fe8f767ffc8ae63a28ae1274c7fd2d5df7243863a4bac70582f4e007c"}, "89095b03-f168-4478-8a18-7c4c4ded862c": {"doc_hash": "180cf57da4b271be2cf910cef2b23009f5e820a4ce73ba013cbdde7954fb56f8"}, "713e9567-730f-464b-9f2a-7ad04f61d5e1": {"doc_hash": "f1928154ac4516f08ac7516ea3523603a5ab72df7c1c1f320a1cb320493e4a87"}, "6b6cf7eb-1b7d-482d-be97-5a9f3fe85b64": {"doc_hash": "cde43893504b707c0d13b123ccc7f9d3fbc45fba079d9f1677935f1e77ea190e"}, "f1f9231a-56af-4079-87e8-e18971490cf2": {"doc_hash": "068bafa785a6efa045254de353c6da6c53317b319e17c5af742c5cfb120d5dc8"}, "8c78592c-8ab2-4c55-a1cd-72ae44c03cca": {"doc_hash": "8a0f9e7870b3e2a1074a28662d5f3a99f3ebcf74cc08f69a54265eeba3cb2ad2"}, "71a8e6a4-91b2-4e1a-af35-4071e6a42851": {"doc_hash": "88d037a375647389216e05213b03c85be9477357cba6666c09d211b860af7f22"}, "bf7aed18-be1b-4ffd-83bf-1010523c0ff9": {"doc_hash": "e8e04c0da1727f2f5e88828e2b7bc6aad7d4c7ced075c40add00f4321838af0a"}, "0581fc00-e934-4c0a-a7f8-3738c8957341": {"doc_hash": "4121b8863c02efefe70937db115df414546358f8625030cf111b8f766568437d"}, "be2661ba-fd24-4c48-b0f4-b6e9e43d0449": {"doc_hash": "8e49363a5410c8eef0cf1aa1b46d949e62047ceb8c65aef6e324a6e969985b21"}, "0c2545b6-8740-40fd-b8db-870c8a3f14bb": {"doc_hash": "38462fc7cf438749dce70f41513d5e3032ded018451d7205371fc603fd93e6e5"}, "72692f76-a6cf-4a10-b77b-257c697543b8": {"doc_hash": "5b4e40b73d0c58038efe10ca9be573f6b5a33d1f455763d4615b572404950cb6"}, "2e2b3abf-c21c-4f13-ac2e-f3907ca8da40": {"doc_hash": "e5dfa958ec45a3fa012ed830922b42602e4d224a38813aa9b54a33662ca95da3"}, "ebe8fbab-207b-4c07-8cab-e26ebf613926": {"doc_hash": "d6509c94c1fa554f0f63f7f7ad021a17b2390fe16f7eead382032d685f95d8ec"}, "e1c2a299-0d27-48ab-90d1-0e7ebaf39460": {"doc_hash": "6f7d54a2a2e7c210eff38f0b0f3671923548edc515ac004fabd20695e4dceb57"}, "6103f75a-b5ed-4b74-9904-52f1958f7d69": {"doc_hash": "cedd7ff1265e59322d3c4b508fc81af906ab51013a2be4f322c3b7cddf658b36"}, "0eba9a57-7685-476c-9a68-b896b092bdb3": {"doc_hash": "9052cdb04c95c72edca9a954562f920796c3e35aeafae00d807f32722f5c1ed1"}, "bf8f1752-9480-4d34-ba53-abbd87a5e788": {"doc_hash": "e6713ea0e4e1527d48b091b900664e8fc7e579261ea043956cb89816df310ddf"}, "0b8a211f-84ff-487c-8097-605021b609de": {"doc_hash": "5cdeaeb60db11e55a34fc629ebb836abb553e483e0f8ce23599c15473791eca6"}, "808fb9de-29e5-4b3b-bd44-955ac259fac5": {"doc_hash": "5cdeaeb60db11e55a34fc629ebb836abb553e483e0f8ce23599c15473791eca6"}, "73bc13fa-3b49-434c-b612-842f6362b5c2": {"doc_hash": "e9a983ab372aa7235e5dd9117803269e13c142cef44e53f3f06b68a35d17b2e8"}, "5382058e-510b-4f65-b630-d3d29020c2ed": {"doc_hash": "0aa12f3417a436f47f3d4f4c565072018f4a7b0ffa7f96e0dde52917763bd449"}, "d787129c-ad2c-4fc4-816d-548231b08182": {"doc_hash": "bc23e8386f5f3ebdf5e2f1602e350e3b84e95ed2e14c8b0b42fdcd9edd33bcfe"}, "a635f1e9-6091-43bb-b86c-c83251d8db8f": {"doc_hash": "96531dc04964a94f70a069c8f252155e9679e3a5f018a6cde4ec01ecc00c65c3"}, "c5b215a2-3850-4f1b-86c5-e536d0f3a78b": {"doc_hash": "a34a843e9a153c49591192fc5604e4fd53d288749bd2cbcf811916ecebde65f7"}, "1984ba9a-f84a-4750-b772-5783cef48a52": {"doc_hash": "e5c2b4f95180f1ee2b5bf1c02d75d44d3423a988fd5b4b4399a863645a71168b"}, "19110383-7ae2-45be-865f-b1559f09f475": {"doc_hash": "c9d7b41e5cb3d00dd7774a8096111772f0975c341a28e70d334fbbf0948bf1cf"}, "e08861cb-d87f-4133-b68c-f469d0cdf8ee": {"doc_hash": "32334cb9374068351d6eaedea52dc037622263989ae53a793c7bfbf25321bba9"}, "e56ec3b5-321e-4825-81d0-ab894e33618c": {"doc_hash": "614f0caab9ea17c1e711b0872eb0629abf1ebf0867093364d8832dcff5007afd"}, "ac687ab7-3ba6-48dc-89a4-6d0d7e3a66c8": {"doc_hash": "91236120fd96d479b217e3109acdeb1b0b8e0dbda470090013201cdcdc990124"}, "b5bb3178-3c4d-4d79-97af-a601919e8b3c": {"doc_hash": "0b7c7f826f02210633c3e3fe5247961d6e2c927f651739f7c3c68ed2c64d0eaa"}, "b2af3f46-faa2-437c-acea-8a12551add2c": {"doc_hash": "9f44b5795f5cb516de2548982b7a838f663ea3349947c51d4b0000a25b4ddba6"}, "f26418f9-06f7-47b6-8d59-5f4fb23a13ee": {"doc_hash": "57dda612d9ed7dda357e66c03508c419e6167678cb6eec8b68efac92c1728bf2"}}}}